\documentclass[12pt,letterpaper,reqno]{article}

% \usepackage{mathtools}
\usepackage{epsfig}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{indentfirst}
\usepackage{xspace}
\usepackage{multirow}
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{verbatim}
\usepackage[letterpaper,margin=1in,headheight=15pt]{geometry}
\usepackage{mathpazo}
\usepackage{tikz-cd}
\usepackage{booktabs}
\usepackage{framed}
\usepackage{float}
\usepackage{thmtools}
\usepackage{dashrule}
\usepackage[missing=]{gitinfo2}
\usepackage{fancyhdr}
\usepackage{enumerate}
\usepackage{graphicx}
\usepackage{mathrsfs}
\usepackage{calligra}
\usepackage[titletoc,title]{appendix}
\usepackage{caption}
\usepackage{subcaption}

\definecolor{darkblue}{rgb}{0.1,0.1,0.7}
\definecolor{darkred}{rgb}{0.5,0.1,0.1}
\definecolor{darkgreen}{rgb}{0.0,0.42,0.06}
\hypersetup{colorlinks=true,urlcolor=darkred,linkcolor=darkblue,citecolor=darkred}
\definecolor{shadecolor}{rgb}{0.85,0.85,0.85}

% Bibliography formatting
\usepackage[bibstyle=authoryear-comp,labeldate=false,defernumbers=true,maxnames=20,uniquename=init,dashed=false,backend=biber,sorting=none]{biblatex}

\DeclareNameAlias{sortname}{first-last}

\DeclareFieldFormat{url}{\url{#1}}
\DeclareFieldFormat[article]{pages}{#1}
\DeclareFieldFormat[inproceedings]{pages}{\lowercase{pp.}#1}
\DeclareFieldFormat[incollection]{pages}{\lowercase{pp.}#1}
\DeclareFieldFormat[article]{volume}{\textbf{#1}}
\DeclareFieldFormat[article]{number}{(#1)}
\DeclareFieldFormat[article]{title}{\MakeCapital{#1}}
\DeclareFieldFormat[inproceedings]{title}{#1}
\DeclareFieldFormat{shorthandwidth}{#1}

% Don't use "In:" in bibliography. Omit urls from journal articles.
\DeclareBibliographyDriver{article}{%
  \usebibmacro{bibindex}%
  \usebibmacro{begentry}%
  \usebibmacro{author/editor}%
  \setunit{\labelnamepunct}\newblock
  \MakeSentenceCase{\usebibmacro{title}}%
  \newunit
  \printlist{language}%
  \newunit\newblock
  \usebibmacro{byauthor}%
  \newunit\newblock
  \usebibmacro{byeditor+others}%
  \newunit\newblock
  \printfield{version}%
  \newunit\newblock
%  \usebibmacro{in:}%
  \usebibmacro{journal+issuetitle}%
  \newunit\newblock
  \printfield{note}%
  \setunit{\bibpagespunct}%
  \printfield{pages}
  \newunit\newblock
  \usebibmacro{eprint}
  \newunit\newblock
  \printfield{addendum}%
  \newunit\newblock
  \usebibmacro{pageref}%
  \usebibmacro{finentry}}

% Remove dot between volume and number in journal articles.
\renewbibmacro*{journal+issuetitle}{%
  \usebibmacro{journal}%
  \setunit*{\addspace}%
  \iffieldundef{series}
    {}
    {\newunit
     \printfield{series}%
     \setunit{\addspace}}%
  \printfield{volume}%
%  \setunit*{\adddot}%
  \printfield{number}%
  \setunit{\addcomma\space}%
  \printfield{eid}%
  \setunit{\addspace}%
  \usebibmacro{issue+date}%
  \newunit\newblock
  \usebibmacro{issue}%
  \newunit}


% Bibliography categories
\def\makebibcategory#1#2{\DeclareBibliographyCategory{#1}\defbibheading{#1}{\section*{#2}}}
\makebibcategory{books}{Books}
\makebibcategory{papers}{Refereed research papers}
\makebibcategory{chapters}{Book chapters}
\makebibcategory{conferences}{Papers in conference proceedings}
\makebibcategory{techreports}{Unpublished working papers}
\makebibcategory{bookreviews}{Book reviews}
\makebibcategory{editorials}{Editorials}
\makebibcategory{phd}{PhD thesis}
\makebibcategory{subpapers}{Submitted papers}
\makebibcategory{curpapers}{Current projects}

\setlength{\bibitemsep}{2.65pt}
\setlength{\bibhang}{.8cm}
\renewcommand{\bibfont}{\small}

\renewcommand*{\bibitem}{\addtocounter{papers}{1}\item \mbox{}\hskip-0.85cm\hbox to 0.85cm{\hfill\arabic{papers}.~~}}
\defbibenvironment{bibliography}
{\list{}
  {\setlength{\leftmargin}{\bibhang}%
   \setlength{\itemsep}{\bibitemsep}%
   \setlength{\parsep}{\bibparsep}}}
{\endlist}
{\bibitem}

\newenvironment{publications}{\section{\LARGE Publications}\label{papersstart}\vspace*{0.2cm}\small
\titlespacing{\section}{0pt}{1.5ex}{1ex}\itemsep=0.00cm
}{\label{papersend}\addtocounter{sumpapers}{-1}\refstepcounter{sumpapers}\label{sumpapers}}

\def\printbib#1{\printbibliography[category=#1,heading=#1]\lastref{sumpapers}}

% Counters for keeping track of papers
\newcounter{papers}\setcounter{papers}{0}
\newcounter{sumpapers}\setcounter{sumpapers}{0}
\def\lastref#1{\addtocounter{#1}{\value{papers}}\setcounter{papers}{0}}

% theorem environments
\declaretheoremstyle[spaceabove=0.25cm,spacebelow=0.25cm,notefont=\normalfont\bfseries, notebraces={(}{)}]{theorem}
\declaretheoremstyle[spaceabove=0.25cm,spacebelow=0.25cm,bodyfont=\normalfont,notefont=\normalfont\bfseries, notebraces={(}{)}]{noital}
\declaretheoremstyle[spaceabove=0.25cm,spacebelow=0.25cm,bodyfont=\normalfont\color{darkgreen},notefont=\normalfont\bfseries, notebraces={(}{)}]{green}
\declaretheoremstyle[spaceabove=0.25cm,spacebelow=0.25cm,bodyfont=\normalfont,notefont=\normalfont\bfseries,qed=$\qedsymbol$,notebraces={(}{)}]{proofstyle}

\declaretheorem[name=Theorem,numberwithin=section,style=theorem]{thm}
\declaretheorem[name=Proposition,sibling=thm,style=theorem]{prop}
\declaretheorem[name=Corollary,sibling=thm,style=theorem]{cor}
\declaretheorem[name=Lemma,sibling=thm,style=theorem]{lem}
\declaretheorem[name=Definition,sibling=thm,style=noital]{defn}
\declaretheorem[name=Example,sibling=thm,style=noital]{example}
\declaretheorem[name=Exercise,numberwithin=section,style=green]{exercise}
\declaretheorem[name=Proof,style=proofstyle,numbered=no]{pf}
\declaretheorem[name=Solution,style=proofstyle,numbered=no]{solution}
\declaretheorem[name=Remark,style=proofstyle,numbered=no]{remark}
\declaretheorem[name=Remarks,style=proofstyle,numbered=no]{remarks}
\numberwithin{equation}{section}


% macros for convenience
\newcommand{\tops}{\texorpdfstring}

\newcommand{\nid}{\noindent}

\newcommand{\fa}{{\mathfrak a}}
\newcommand{\fp}{{\mathfrak p}}
\newcommand{\fk}{{\mathfrak k}}
\newcommand{\fg}{{\mathfrak g}}
\newcommand{\fh}{{\mathfrak h}}
\newcommand{\fn}{{\mathfrak n}}
\newcommand{\fq}{{\mathfrak q}}
\newcommand{\fm}{{\mathfrak m}}
\newcommand{\fr}{{\mathfrak r}}
\newcommand{\fu}{{\mathfrak u}}
\newcommand{\fG}{{\mathfrak G}}
\newcommand{\bh}{{\bf h}}

\newcommand{\cC}{\ensuremath{\mathcal C}}
\newcommand{\cG}{\ensuremath{\mathcal G}}
\newcommand{\cB}{\ensuremath{\mathcal B}}
\newcommand{\cL}{\ensuremath{\mathcal L}}
\newcommand{\cS}{\ensuremath{\mathcal S}}
\newcommand{\cF}{\ensuremath{\mathcal F}}
\newcommand{\cK}{\ensuremath{\mathcal K}}
\newcommand{\cZ}{\ensuremath{\mathcal Z}}
\newcommand{\cM}{\ensuremath{\mathcal M}}
\newcommand{\cN}{\ensuremath{\mathcal N}}
\newcommand{\cO}{\ensuremath{\mathcal O}}
\newcommand{\cH}{\ensuremath{\mathcal H}}
\newcommand{\cX}{\ensuremath{\mathcal X}}
\newcommand{\cY}{\ensuremath{\mathcal Y}}
\newcommand{\cA}{\ensuremath{\mathcal A}}
\newcommand{\cI}{\ensuremath{\mathcal I}}

\newcommand{\R}{\ensuremath{\mathbb R}}
\newcommand{\C}{\ensuremath{\mathbb C}}
\newcommand{\PP}{\ensuremath{\mathbb P}}
\newcommand{\Z}{\ensuremath{\mathbb Z}}
\newcommand{\Q}{\ensuremath{\mathbb Q}}
\newcommand{\A}{\ensuremath{\mathbb A}}
\newcommand{\bbH}{\ensuremath{\mathbb H}}
\newcommand{\bbI}{\ensuremath{\mathbb I}}
\newcommand{\bS}{\ensuremath{\mathbb S}}

\newcommand{\half}{\ensuremath{\frac{1}{2}}}
\newcommand{\qtr}{\ensuremath{\frac{1}{4}}}
\newcommand{\bq}{{\mathbf q}}
\newcommand{\N}{{\mathcal N}}
\newcommand{\F}{{\mathcal F}}
\newcommand{\HH}{{\mathcal H}}
\newcommand{\LL}{{\mathcal L}}
\newcommand{\RR}{{\mathcal R}}
\newcommand{\V}{{\mathcal V}}
\newcommand{\dirac}{\!\!\not\!\partial}
\newcommand{\Dirac}{\!\!\not\!\!D}
\newcommand{\cE}{{\mathcal E}}
\newcommand{\vs}{\not\!v}
\newcommand{\kahler}{K\"ahler\xspace}
\newcommand{\kq}{/\!\!/}
\newcommand{\kql}[1]{/\!\!/\!\!_#1\,}
\newcommand{\hk}{hyperk\"ahler\xspace}
\newcommand{\Hk}{Hyperk\"ahler\xspace}
\newcommand{\hkq}{/\!\!/\!\!/\!\!/}
\newcommand{\hkql}[1]{/\!\!/\!\!/\!\!/\!\!_#1\,}
\newcommand{\del}{\ensuremath{\partial}}
\newcommand{\delbar}{\ensuremath{\overline{\partial}}}
\newcommand{\bl}{{\bf L}}
\newcommand{\J}{{\mathrm j}}
\newcommand{\K}{{\mathrm k}}
\newcommand{\e}{{\mathrm e}}
\newcommand\bid{{\mathbf 1}}
\newcommand{\de}{\mathrm{d}}
\newcommand{\ab}{\mathrm{ab}}
\newcommand{\vol}{\mathrm{vol}}
\renewcommand{\sf}{\mathrm{sf}}
\newcommand{\inst}{\mathrm{inst}}
\newcommand{\eff}{\mathrm{eff}}
\newcommand{\dR}{\mathrm{dR}}
\newcommand{\closed}{\mathrm{closed}}
\newcommand{\exact}{\mathrm{exact}}
\newcommand{\zv}{{\bf 0}}
\newcommand{\bbf}{{\bf F}}

\newcommand{\abs}[1]{\lvert#1\rvert}
\newcommand{\norm}[1]{\lVert#1\rVert}
\newcommand{\IP}[1]{\langle#1\rangle}
\newcommand{\DIP}[1]{\langle\!\langle#1\rangle\!\rangle}
\newcommand{\dwrt}[1]{\frac{\partial}{\partial#1}}
\newcommand{\eps}{\epsilon}
\newcommand{\simarrow}{\xrightarrow\sim}

\newcommand{\mmaref}[1]{}

\newcommand{\ti}[1]{\textit{#1}}
\newcommand{\tb}[1]{\textbf{#1}}
\newcommand{\lo}{\text{\calligra o}\,}
\newcommand{\dd}{\ensuremath{\mathscr{D}}}
\newcommand{\bu}{{\bf u}}
\newcommand{\bv}{{\bf v}}
\newcommand{\bw}{{\bf w}}
\newcommand{\bx}{{\bf x}}
\newcommand{\by}{{\bf y}}
\newcommand{\bz}{{\bf z}}
\newcommand{\ba}{{\bf a}}
\newcommand{\bb}{{\bf b}}
\newcommand{\bbr}{{\bf r}}
\newcommand{\bff}{{\bf f}}
\newcommand{\bgg}{{\bf g}}
\newcommand{\bt}{{\bf t}}
\newcommand{\bn}{{\bf n}}
\newcommand{\ii}{{\bf {\hat{i}}}}
\newcommand{\jj}{{\bf {\hat{j}}}}
\newcommand{\kk}{{\bf {\hat{k}}}}
\newcommand{\ut}{{\bf {\hat{t}}}}
\newcommand{\un}{{\bf {\hat{n}}}}
\newcommand{\ub}{{\bf {\hat{b}}}}


\DeclareMathOperator{\ad}{ad}
\DeclareMathOperator{\im}{Im}
\DeclareMathOperator{\re}{Re}
\DeclareMathOperator{\Tr}{Tr}
\DeclareMathOperator{\End}{End}
\DeclareMathOperator{\Hom}{Hom}
\DeclareMathOperator{\Aut}{Aut}
\DeclareMathOperator{\Sym}{Sym}
\DeclareMathOperator{\Lie}{Lie}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\Bun}{Bun}
\DeclareMathOperator{\Vect}{Vect}
\DeclareMathOperator{\Span}{Span}
\DeclareMathOperator{\grad}{grad}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\ind}{ind}
\DeclareMathOperator{\coker}{coker}
\DeclareMathOperator{\Jac}{Jac}
\DeclareMathOperator{\Hol}{Hol}
\DeclareMathOperator{\gr}{gr}

\newcommand{\insfig}[2]{

\medskip
\noindent
\begin{minipage}{\linewidth}

\makebox[\linewidth]{\includegraphics[keepaspectratio=true,scale=#2]{figures/#1-crop.pdf}}

\end{minipage}
\medskip

}


% \newcommand{\insfig}[2]{\begin{figure}[htbp] \centering \includegraphics[scale=#2]{figures/#1-crop.pdf} \label{fig:#1} \end{figure}}
% syntax: \insfig{name}{0.5}{caption}

\newcommand{\fixme}[1]{{\color{orange}{[#1]}}}
\newcommand{\currentposition}{{\color{blue} \noindent\makebox[\linewidth]{\hdashrule{\paperwidth}{1pt}{3mm}}}}

% \mathtoolsset{showonlyrefs}

\bibliography{mvc}

\begin{document}
\pagestyle{fancy}
\lhead{{\tiny \color{gray} \tt \gitAuthorIsoDate}}
\chead{\tiny \ti{Multivariable Calculus, GSMST Spring 2020}}
\rhead{{\tiny \color{gray} \tt \gitAbbrevHash}}
\renewcommand{\headrulewidth}{0.5pt}


\begin{center}
\tb{Multivariable Calculus} \\
Anderson Trimm \\
Gwinnett School of Mathematics, Science and Technology \\
\end{center}

{These are the notes for the Spring Semester 2020
course in Multivariable Calculus at GSMST. They will continually be updated throughout the course. The latest PDF can always be accessed
at \small \url{https://github.com/atrimm/mvc/blob/master/Course%20Notes/multivariable_calculus_2020.pdf.}

\tableofcontents
\renewcommand{\listtheoremname}{Quick reference}
\listoftheorems[onlynamed]

\newpage

%\setcounter{page}{1}

\section{Curves}
In this section we study functions with one input and multiple outputs.

\subsection{Vector-valued functions}
\subsubsection{Definitions}
Suppose a particle moves in the plane along the following curve $C$:
	\begin{center}
		\includegraphics[scale=0.5]{figures_mvc/plane_curve}
	\end{center}
Since the curve fails the vertical line test, $C$ cannot be described as the graph of a function $y=f(x)$. Note however that the x- and y-coords of the particle are functions of time
\begin{align*}
	x=f(t), \hspace{0.5cm} y=g(t)
\end{align*}
so the curve $C$ can be described as the image of function ${\bf r}:I \to \mathbb{R}^2$ defined by 
\begin{align*}
	\bbr(t)=(f(t),g(t)),
\end{align*}
where $I=[a,b]$ is an interval in $\R$. \fixme{Add mapping diagram.}

\begin{defn}[Vector-valued function]
Let $U \subseteq \R$. A mapping $\bbr:U \to \mathbb{R}^n$ called a \emph{vector-valued function}. The value of $\bbr$ at $t \in U$ can be written as
\begin{align*}
	\bbr(t)=(r_1(t),r_2(t),\dots,r_n(t))
\end{align*}
where the $n$ functions $r_i:U \to \R$, $i=1,\dots,n$ are called the \emph{component functions} of $\bbr$.	
\end{defn}
Unless specified otherwise, we will take the domain $U$ of a vector-valued function to be the largest domain on which all of the component functions are defined.
\begin{example}
Consider the vector-valued function $\bbr:U \to \mathbb{R}^3$ defined by
	\begin{align*}
		\bbr(t)=(t^3,\ln(3-t),\sqrt{t}).
	\end{align*}
The component functions of $\bbr(t)$ are 
\begin{align*}
	r_1(t)=t^3, \hspace{0.5cm} r_2(t)=\ln(3-t), \hspace{0.5cm} r_3(t)=\sqrt{t}.
\end{align*}
The domains of each of these functions, respectively, are 
\begin{align*}
	U_1=\R, \hspace{0.5cm} U_2=(-\infty,3), \hspace{0.5cm} U_3=[0,\infty),
\end{align*}	
so the domain $U$ of $\bbr(t)$ is 
\begin{align*}
	U=U_1 \cap U_2 \cap U_3=[0,3).
\end{align*} 
\end{example}

\begin{exercise}
	Consider the vector-valued function $\bbr:U \to \mathbb{R}^3$ defined by
	\begin{align*}
		\bbr(t)=\left(\frac{t-2}{t+2},\sin t, \ln(9-t^2)\right).
	\end{align*}
What is the domain $U$ of the function?
\end{exercise}
{\color{red}\begin{solution}
	The component functions of $\bbr(t)$ are 
	\begin{align*}
		r_1=\frac{t-2}{t+2}, \hspace{0.5cm} r_2=\sin t, \hspace{0.5cm} r_3=\ln(9-t^2).
	\end{align*}
	The domains of $r_1(t)$ and $r_2(t)$ are given, respectively, by
	\begin{align*}
		U_1=(-\infty,2) \cup (2,\infty), \hspace{0.5cm} U_2=\R.
	\end{align*}
	To find the domain of $r_3(t)$, we need to solve the inequality
	\begin{align*}
		9-t^2>0. \\
	\end{align*}
	The graph of the function $y=9-x^2$ is a concave-down parabola with $y$-intercept 9 and $x$-intercepts $\pm 3$. 
	
	\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.3]{figures_mvc/parab_down}
	\end{center}
	\caption{Graph of $y=9-x^2$.}
\end{figure}
	We have $y>0$ where the graph is above the $x$-axis, so $y>0$ when $-3<x<3$. The domain of $r_3(t)$ is therefore
	\begin{align*}
		U_3=(-3,3).
	\end{align*}
	The domain of $\bbr(t)$ is then
	\begin{align*}
		U=U_1 \cap U_2 \cap U_3=(-3,-2)\cup (-2,3).
	\end{align*}
\end{solution}}

\subsubsection{Review: limits of single-variable functions}
Before considering limits of vector-valued functions, let's review the definition for a real-valued function $y=f(x)$ of a single real variable $x$.

To motivate the definition, consider the function
\begin{align*}
	f(x)=\begin{cases}
		2x-1, \ \text{ if } x \neq 3 \\
		6, \hspace{1.0cm} \text{ if } x = 3 \\
	\end{cases}
\end{align*}
whose graph is shown in the figure below.

\begin{figure}[h]\label{fig:lim_def}
	\begin{center}
		\includegraphics[scale=0.7]{figures_mvc/graph_limit_defn}
	\end{center}
	\caption{Graph of the function $y=f(x)$ in the example above.}
\end{figure}
From the graph, we see that when $x$ is close to 3 but not equal to 3, then $f(x)$ is close to 5, and so $\lim_{x \to 3}f(x)=5$.

To obtain more detailed information about how $f(x)$ varies when $x$ is close to 3, we ask the following question: 

\emph{How close to 3 does $x$ have to be so that $f(x)$ differs from 5 by less than $0.1$?}

The distance from $x$ to $3$ is $|x-3|$ and the distance from $f(x)$ to 5 is $|f(x)-5|$, so our problem is to find a number $\delta$ such that 
\begin{align*}
	|f(x)-5|<0.1 \hspace{0.5cm} \text{ if } \hspace{0.5cm} 0<|x-3|<\delta.
\end{align*}
If $x \neq 3$, then 
\begin{align*}
	|f(x)-5|=|(2x-1)-5|=|2x-6|=2|x-3|
\end{align*}
so we see that by taking $\delta=\frac{1}{2}(0.1)=0.05$, we have $|f(x)-5|<2(0.05)=0.1$. Thus, an answer to the problem is given by $\delta=0.05$; that is, if $x$ is within a distance of $0.05$ from 3, then $f(x)$ will be within a distance of $0.1$ from 5.

If we change the number $0.1$ in our problem to the smaller number $0.01$, then by using the same method we find that $f(x)$ will differ from 5 by less than $0.01$ provided that $x$ differs from 3 by less than $\frac{1}{2}(0.01)=0.005$; that is,
\begin{align*}
	|f(x)-5|<0.01 \hspace{0.5cm} \text{ if } \hspace{0.5cm} 0<|x-3|<0.005.
\end{align*}
Similarly,
\begin{align*}
	|f(x)-5|<0.001 \hspace{0.5cm} \text{ if } \hspace{0.5cm} 0<|x-3|<0.0005.
\end{align*}
Think of the numbers $0.1, 0.01, 0.001$ above as \emph{error tolerances} that we might allow. That is, when challenged with an error tolerance, it is our task to find a corresponding $\delta$ so that whenever $x$ is within a distance of $\delta$ from 3, $f(x)\approx 5$, within the given error tolerance. 

Now for 5 to be the precise limit of $f(x)$ as $x$ approaches 3, we must not only be able to bring the difference between $f(x)$ and 5 below each of these numbers; we must be able to bring it below \emph{any} positive number. And, by exactly the same reasoning, we can. That is, if $\epsilon$ is any positive number, then by choosing $\delta=\frac{\epsilon
}{2}$, we find
\begin{align}\label{eq:review_limit_example}
	|f(x)-5|<\epsilon \hspace{0.5cm} \text{ if } \hspace{0.5cm} 0<|x-3|<\delta=\frac{\epsilon}{2}.
\end{align}
This is a precise way of saying that $f(x)$ is close to 5 when $x$ is close to 3, because Equation \eqref{eq:review_limit_example} says that we can make the values of $f(x)$ within an arbitrary distance $\epsilon$ from 5 by taking the values of $x$ within a distance $\frac{\epsilon}{2}$ from 3 (but $x \neq 3$).

Note that Equation \eqref{eq:review_limit_example} can be rewritten as follows:
\begin{align*}
	\text{ if } \hspace{0.5cm} 3-\delta<x<3+\delta \hspace{0.2cm} (x \neq 3) \hspace{0.5cm} \text{ then } \hspace{0.5cm} 5-\epsilon<f(x)<5+\epsilon
\end{align*}
as illustrated in the figure above. This says that by taking the values of $x$ ($x \neq 3$) to lie in the interval $(3-\delta,3+\delta)$ we can make the values of $f(x)$ lie in the interval $(5-\epsilon,5+\epsilon)$.

Following the reasoning in this example,  the precise definition of a limit is the following.

\begin{defn}[Limit of a single-variable function]\label{def:limit_of_a_single-variable_function}
	Let $(a,b)$ be an open interval containing the point $x_0$ and let $f(x)$ be a real-valued function defined on this interval, except possibly at $x_0$ itself. A number $L$ is called the \emph{limit of $f(x)$ as $x$ approaches $x_0$} if for every $\epsilon>0$ there exists a $\delta>0$ such that $|f(x)-L|<\epsilon$ whenever $0<|x-x_0|<\delta$. If such an $L$ exists, we write
	\begin{align*}
		\lim_{x \to x_0}f(x)=L.
	\end{align*}
\end{defn}

\begin{thm}[Uniqueness of limits]\label{thm:uniqueness_of_limits}
	If $f(x)$ has a limit $L$ at $x_0$, then the limit is unique.
\end{thm}

\begin{pf}
Suppose that $\lim_{x \to x_0}f(x)=L$ and $\lim_{x \to x_0}f(x)=L'$. Then, given any $\epsilon>0$ there exist positive numbers $\delta_1$ and $\delta_2$ such that 
\begin{align*}
	|f(x)-L|<\frac{\epsilon}{2} \hspace{0.5cm} \text{ if } \hspace{0.5cm} |x-x_0|<\delta_1
\end{align*} 	
and
\begin{align*}
	|f(x)-L'|<\frac{\epsilon}{2} \hspace{0.5cm} \text{ if } \hspace{0.5cm} |x-x_0|<\delta_2.
\end{align*} 
Then by taking $|x-x_0|<\delta=\min\{\delta_1,\delta_2\}$, we have
\begin{align*}
	|L-L'|=|L-L'+f(x)-f(x)|=|L-f(x)+f(x)-L|\leq |f(x)-L|+|f(x)-L'|<\frac{\epsilon}{2}+\frac{\epsilon}{2}=\epsilon.
\end{align*}
For this to be true for all $\epsilon>0$, we must have $L-L'=0$, or $L=L'$.
\end{pf}


\begin{exercise}
Use Definition \ref{def:limit_of_a_single-variable_function} to prove that $\lim_{x \to 3}(4x-5)=7$.
\end{exercise}

{\color{red} \begin{solution}
Let $\epsilon>0$. For all $x \neq 3$, 
\begin{align*}
	|f(x)-7|=|(4x-5)-7|=|4x-12|=4|x-3|.
\end{align*} 
By taking $\delta=\frac{\epsilon}{4}$, we have $0<|x-3|<\frac{\epsilon}{4}$ and therefore
\begin{align*}
	|f(x)-7|=4|x-3|<4\cdot \frac{\epsilon}{4}=\epsilon,
\end{align*}	
which proves that $\lim_{x \to 3}(4x-5)=7$.
\end{solution}}

\begin{example}
We now use Definition \ref{def:limit_of_a_single-variable_function} to prove that $\lim_{x \to 3}x^2=9$.	

Let $\epsilon>0$. For all $x \neq 3$, we have
\begin{align*}
	|f(x)-9|=|x^2-9|=|(x+3)(x-3)|=|x+3||x-3|.
\end{align*} 
Notice that if we can find a positive number $C$ such that $|x+3|<C$, then
\begin{align*}
	|x+3||x-3|<C|x-3|
\end{align*}
and we can make $C|x-3|<\epsilon$ by taking $|x-3|<\frac{\epsilon}{C}=\delta$. We can find such a number $C$ if we restrict $x$ to lie in some interval centered at 3. Since we are only interested in values of $x$ that are close to 3, this is exactly what we want. Let's assume that $|x-3|<\alpha$ for some positive number $\alpha$, say $\alpha=1$ (it does not matter what number we take here). Then we have
\begin{align*}
	x-3<1 \hspace{0.5cm} \text{ or }  \hspace{0.5cm} -x+3<1.
\end{align*}
The first inequality says $x<4$ and the second says $2<x$, so $|x-3|<1$ implies that 
\begin{align*}
	2<x<4.
\end{align*}
Adding 3 to both sides of this inequality gives 
\begin{align*}
	5<x+3<7,
\end{align*}
and therefore $|x+3|<|7|=7=C$. But now there are two restrictions on $|x-3|$, namely
\begin{align*}
	|x-3|<1 \hspace{0.5cm} \text{ and } \hspace{0.5cm} |x-3|<\frac{\epsilon}{C}=\frac{\epsilon}{7}.
\end{align*}
To make sure that both of these inequalities are satisfied, we take $\delta=\min\{1,\frac{\epsilon}{7}\}$. Since $0<|x-3|<\delta$ implies $|x^2-9|<\epsilon$, this proves that $\lim_{x \to 3}x^2=9$.
\end{example}
The previous example shows that it is not always easy to prove that a function has a particular limit using Definition \ref{def:limit_of_a_single-variable_function}. In fact, if we had considered a more complicated function such as 
\begin{align*}
	f(x)=\frac{6x^2-8x+9}{2x^2-1}
\end{align*}
then proving that $\lim_{x \to 1}f(x)=7$ using Definition \ref{def:limit_of_a_single-variable_function} would require a great deal of ingenuity. Instead, we prove the following theorems, which makes evaluating limits much easier. The proofs of these theorems follow from the following properties of the absolute value function.

\begin{lem}[Properties of the absolute value function]\label{lem:triangle_inequality}
The absolute value function $f(x)=|x|$ has the following properties
\begin{enumerate}[(1)]
	\item $|x|\geq 0$ for all $x \in \R$, and $|x|=0$ if and only if $x=0$.
	\item $|xy|=|x| \ |y|$ for all $x,y \in \R$.
	\item For all $x,y \in \R$, 
	\begin{align*}
		|x+y| \leq |x|+|y|.
	\end{align*}
\end{enumerate}	
The third property is called the \emph{triangle inequality}.
\end{lem}

\begin{pf}
\begin{enumerate}[(1)]
	\item This is immediate from the definition of $|x|$.
	\item If either $x=0$ or $y=0$, then $xy=0$ so by property (1) $|xy|=0=|x||y|$. Suppose now that neither $x$ nor $y$ are zero. If $x,y>0$ then $xy>0$, so  $|xy|=xy=|x| \ |y|$. If $x,y<0$, then $xy>0$, so $|xy|=xy=(-x)(-y)=|x|\ |y|$. If $x>0$ and $y<0$, then $xy<0$, so $|xy|=-xy=x(-y)=|x| \ |y|$. If $x<0$ and $y>0$ then $xy<0$, so $|xy|=-xy=(-x)y=|x| \ |y|$.
	\item For any $x,y \in \R$ we have
\begin{align*}
	|x+y|^2=(x+y)^2&=x^2+y^2+2xy \\
	&=|x|^2+|y|^2+2xy \\
	&\leq |x|^2+|y|^2+2|x||y| \\
	&=(|x|+|y|)^2.
\end{align*}	
Since both sides are nonnegative, this implies that 
\begin{align*}
	|x+y| \leq |x|+|y|.
\end{align*}
\end{enumerate}
\end{pf}



\begin{thm}[Limit laws for single-variable functions]\label{thm:limit_laws_for_single-variable_functions}
Suppose $f(x)$ and $g(x)$ are defined on the same open set containing $x_0$, and that 
\begin{align*}
	\lim_{x \to x_0}f(x)=L \hspace{0.5cm} \text{ and } \hspace{0.5cm} \lim_{x \to x_0}g(x)=M.
\end{align*}
Then
	\begin{enumerate}[(i)]
		\item $\lim_{x \to x_0}c=c$ for any constant $c \in \R$.
		\item $\lim_{x \to x_0}x=x_0$.
		\item $\lim_{x \to x_0} cf(x)=cL$ for any $c \in \R$;
		\item $\lim_{x \to x_0}(f(x)+ g(x))=L+M$;
		\item $\lim_{x \to x_0}(f(x)g(x))=LM$;
		\item $\lim_{x \to x_0}=\frac{f(x)}{g(x)}=\frac{L}{M}$ whenever $M \neq 0$.
	\end{enumerate}
\end{thm}

\begin{pf}
\begin{enumerate}[(i)]
	\item Let $\epsilon>0$. Since $|c-c|=0$, $|c-c|<\epsilon$ whenever $|x-x_0|<\delta$ for any positive number $\delta$.
	\item Given $\epsilon>0$, by taking $\delta=\epsilon$ we have $|x-x_0|<\epsilon$ whenever $|x-x_0|<\delta=\epsilon$.
	\item Since $\lim_{x \to x_0}f(x)=L$, given $\epsilon>0$ there exists a corresponding $\delta>0$ such that $|f(x)-L|<\epsilon$ whenever $0<|x-x_0|<\delta$. Then $|cf(x)-cL|=|c||f(x)-L|<\epsilon$ whenever $0<|x-x_0|<\frac{\epsilon}{|c|}$.
	\item We have
	\begin{align*}
		|f(x)+g(x)-(L+M)|=|(f(x)-L)+(g(x)-M)| \leq |f(x)-L|+|g(x)-M|
	\end{align*}
	by the Triangle Inequality (Lemma \ref{lem:triangle_inequality}). Since $\lim_{x \to x_0}f(x)=L$ and $\lim_{x \to x_0}g(x)=M$, given $\epsilon>0$ there exist positive numbers $\delta_1$ and $\delta_2$ such that 
	\begin{align*}
		|f(x)-L|<\frac{\epsilon}{2} \hspace{0.5cm} \text{ if } \hspace{0.5cm} |x-x_0|<\delta_1
	\end{align*} 
	and 
	\begin{align*}
		|g(x)-M|<\frac{\epsilon}{2} \hspace{0.5cm} \text{ if } \hspace{0.5cm} |x-x_0|<\delta_2.
	\end{align*} 
	By taking $|x-x_0|<\delta=\min\{\delta_1,\delta_2\}$, we have 
	\begin{align*}
		|f(x)+g(x)-(L+M)|\leq |f(x)-L|+|g(x)-M|<\frac{\epsilon}{2}+\frac{\epsilon}{2}=\epsilon,
	\end{align*}
	which proves that $\lim_{x \to x_0}(f(x)+g(x))=L+M$.
	\item First, note that
		\begin{align*}
			f(x)g(x)-LM&=(f(x)-L)(g(x)-M)+L(g(x)-M)+M(f(x)-L).
		\end{align*} 
		Let $\epsilon>0$. Since $\lim_{x \to x_0}f(x)=L$ there exists $\delta_1>0$ such that $|f(x)-L|<\sqrt{\epsilon}$ whenever $|x-x_0|<\delta_1$. Since $\lim_{x \to x_0}g(x)=M$ there exists $\delta_2>0$ such that $|g(x)-M|<\sqrt{\epsilon}$ whenever $|x-x_0|<\delta_2$. Then, whenever $|x-x_0|<\delta=\min\{\delta_1,\delta_2\}$, we have
		\begin{align*}
			|(f(x)-L)(g(x)-M)|=|f(x)-L||g(x)-M|<(\sqrt{\epsilon})^2=\epsilon
		\end{align*}
		which shows that $\lim_{x-x_0}(f(x)-L)(g(x)-M)=0$. By (iii), 
		\begin{align*}
			\lim_{x \to x_0}L(g(x)-M)=L\lim_{x \to x_0}(g(x)-M)=L\cdot0=0,
		\end{align*}
		 and 
		\begin{align*}
			\lim_{x \to x_0}M(f(x)-L)=M\lim_{x \to x_0}(f(x)-L)=M\cdot0=0.
		\end{align*}
		Applying (iv),
		\begin{align*}
			\lim_{x \to x_0}(f(x)g(x)-LM)&=\lim_{x \to x_0}(f(x)-L)(g(x)-M)+\lim_{x \to x_0}L(g(x)-M)+\lim_{x \to x_0}M(f(x)-L) \\
			&=0+0+0 \\
			&=0,
		\end{align*}
		and therefore
		\begin{align*}
			\lim_{x \to x_0}f(x)g(x)=LM.
		\end{align*}
	\item First, note that since $|M|>0$ and $\lim_{x \to x_0}g(x)=M$, there exists $\delta_1>0$ such that $|g(x)|>\frac{1}{2}|M|$ whenever $|x-x_0|<\delta_1$ \fixme{Draw a picture.}. Let $\epsilon>0$. Choose $\delta_2>0$ such that $|x-x_0|<\delta_2$ implies that $|g(x)-M|<\frac{1}{2}|M|^2\epsilon$. Then, for $|x-x_0|<\delta = \min\{\delta_1,\delta_2\}$, we have
	\begin{align*}
		|\frac{1}{g(x)}-\frac{1}{M}|&=|\frac{M-g(x)}{Mg(x)}|\\
		&=\frac{|g(x)-M|}{|Mg(x)|} \\
		&<\frac{\frac{1}{2}|M|^2\epsilon}{\frac{1}{2}|M|^2} \\
		&=\epsilon,	
	\end{align*}
	and therefore $\lim_{x \to x_0}\frac{1}{g(x)}=\frac{1}{M}$. It then follows from (v) that
	\begin{align*}
		\lim_{x \to x_0}\frac{f(x)}{g(x)}&=\lim_{x \to x_0}f(x) \lim_{x \to x_0}\frac{1}{g(x)} \\
		&=\frac{L}{M}.
	\end{align*}
\end{enumerate}	
\end{pf}
Using Theorem \ref{thm:limit_laws_for_single-variable_functions}, it is much easier to prove the limits in the examples above. For instance
\begin{align*}
	\lim_{x \to 3}(4x-5)&=(\lim_{x \to 3}4)(\lim_{x \to 3}x)+(\lim_{x \to 3}(-5)) \\
	&=4(3)+(-5) \\
	&=12-5 \\
	&=7,
\end{align*}
and 
\begin{align*}
	\lim_{x \to 3}x^2=(\lim_{x \to 3}x)(\lim_{x \to 3}x)=(3)(3)=9.
\end{align*}
Note that, in both of these examples, the function $f(x)$ is actually defined at $x_0$ and $\lim_{x \to x_0}f(x)=f(x_0)$; that is, the limit of $f(x)$ as $x$ approaches $x_0$ is equal to the value of $f(x)$ at $x_0$.

\begin{defn}[Continuity]
	Let $f(x)$ be defined on an open interval $(a,b)$ containing a point $x_0$. We say that $f(x)$ is \emph{continuous at $x_0$} if $\lim_{x \to x_0}f(x)=f(x_0)$. We then say that $f(x)$ is \emph{continuous on $(a,b)$} if $f(x)$ is continuous at every point in $(a,b)$.
\end{defn}
The limit laws in Theorem \ref{thm:limit_laws_for_single-variable_functions} imply the following

\begin{thm}[New continuous functions from old]\label{thm:new_continuous_functions_from_old}
	Let $f(x)$ and $g(x)$ be defined on the same open interval containing $x_0$. If $f(x)$ and $g(x)$ are continuous at $x_0$, then so are
	\begin{enumerate}[(i)]
		\item $cf(x)$
		\item $f(x)+g(x)$
		\item $f(x)g(x)$
		\item $f(x)/g(x)$ 
	\end{enumerate}
\end{thm}

\begin{example}[Examples of Continuous Functions]\hspace{15cm}
\begin{itemize}
	\item Polynomials are continuous on $\R$;
	\item Rational functions are continuous wherever they are defined;
	\item The absolute value function $f(x)=|x|$ is continuous;
\end{itemize}
Trig functions, and exponential and logarithmic functions are all also continuous wherever they are defined.	
\end{example}


\begin{exercise}
Prove that $f(x)=|x|$ is continuous on $\R$.	
\end{exercise}

{\color{red} \begin{solution}
 	If $x>0$, then $f(x)=x$ which is continuous since it is a polynomial. The same is true for $x<0$ since then $f(x)=-x$. By taking $\delta=\epsilon$, $|f(x)-0|=||x||=|x|<\epsilon$ whenever $|x|<\delta=\epsilon$, so $\lim_{x \to 0}f(x)=0=f(0)$, which shows that $f(x)$ is also continuous at $x=0$. Thus, $f(x)$ is continuous on $\R$.
 \end{solution}}

\begin{thm}[A composition of continuous functions is continuous]\label{thm:a_composition_of_continuous_functions_is_continuous}
	Suppose $f(x)$ is defined on an open interval containing $x_0$ and  $g(x)$ is defined on an open interval containing $f(x_0)$. If $f$ is continuous at $x_0$ and $g(x)$ is continuous at $f(x_0)$, then $(g \circ f)(x)$ is continuous at $x_0$.
\end{thm}

\begin{pf}
Let $\epsilon>0$. Since $g$ is continuous at $f(x_0)$, corresponding to $\epsilon$ there exists $\eta>0$ such that $|g(f(x))-g(f(x_0))|<\epsilon$ whenever $|f(x)-f(x_0)|<\eta$. Since $f$ is continuous at $x_0$, corresponding to $\eta$ there exists $\delta>0$ such that $|f(x)-f(x_0)|<\eta$ whenever $|x-x_0|<\delta$. This shows that $|g(f(x))-g(f(x_0))|<\epsilon$ whenever $|x-x_0|<\delta$, proving that $(g \circ f)(x)$ is continuous at $x_0$.
\end{pf}

\begin{example}
Consider the function $f(x)=e^{x^2}$. We can view $f(x)$ as the composition $(h \circ g)(x)$, where $h(x)=e^x$ and $g(x)=x^2$. Since $h(x)$ and $g(x)$ are continuous on $\R$, by Theorem \ref{thm:a_composition_of_continuous_functions_is_continuous} so is $f(x)$.
\end{example}

\subsubsection{Limits of vector-valued functions}
Throughout this section, let $I=(a,b)$ denote an open interval in $\R$ containing a point $t_0$, and let $\bbr(t)$ be a vector-valued function defined on $I$, except perhaps at $t_0$ itself. 
\begin{defn}[Limit of a vector-valued function]
	A fixed vector $\bl \in \mathbb{R}^n$ is said to be the \emph{limit as $\bbr(t)$ approaches $t_0$} if for every $\epsilon >0$ there exists a corresponding $\delta > 0$ such that
	\begin{align*}
		0 < |t-t_0|<\delta \implies ||\bbr(t)-{\bf L}||<\epsilon.
	\end{align*}
	If $\bl$ exists, we write $\lim_{t \to t_0}\bbr(t)=\bl$. 
\end{defn}
We will now show that the limit of a vector-valued function can be computed in terms of the limits of its component functions. We will need the following lemma.

\begin{lem}\label{lem:useful_vector_inequalities}
Let $\bx=(x_1,x_2,\dots,x_n)$ and $\by=(y_1,y_2,\dots,y_n)$ be vectors in $\R^n$. Then
\begin{align*}
	|x_i-y_i| \leq ||\bx-\by|| \leq \sum_{i=1}^3|x_i-y_i|
\end{align*}	
for all $i=1,2,\dots,n$.
\end{lem}

\begin{pf}
For any fixed index $i$, we have
\begin{align*}
	||\bx-\by||^2&=\sum_{j=1}^n(x_j-y_j)^2 \\
	&=(x_i-y_i)^2+\underbrace{\sum_{j \neq i}(x_j-y_j)^2}_{\geq 0} \\
	&\geq (x_i-y_i)^2.
\end{align*}	
Since both sides are nonnegative, this implies that 
\begin{align*}
	||\bx-\by||\geq \sqrt{(x_i-y_i)^2}=|x_i-y_i|,
\end{align*}
so the first inequality holds. 

To see that the second inequality holds, note that 
\begin{align*}
	\left(\sum_{i=1}^n|x_i-y_i|\right)^2&=\sum_{i=1}^n|x_i-y_i|^2+\underbrace{2\sum_{1 \leq i<j \leq n}|x_i-y_i||x_j-y_j|}_{\geq 0} \\
	&\geq \sum_{i=1}^n|x_i-y_i|^2 \\
	&= \sum_{i=1}^n(x_i-y_i)^2 \\
	&=||\bx-\by||^2.
\end{align*}
Since both sides are nonnegative, this implies that 
\begin{align*}
	\sum_{i=1}^n|x_i-y_i| \geq ||\bx-\by||,
\end{align*}
so the second inequality holds.
\end{pf}

\begin{exercise}
Verify that	
\begin{align*}
	\left(\sum_{i=1}^n|x_i-y_i|\right)^2&=\sum_{i=1}^n|x_i-y_i|^2+2\sum_{1 \leq i<j \leq n}|x_i-y_i||x_j-y_j|
\end{align*}
for $n=3$ by explicitly writing out both sides.
\end{exercise}


\begin{thm}[Limit of a vector-valued function]\label{thm:limit_of_a_vector-valued_function}
Let $\bbr:I\to \mathbb{R}^n$ be a vector-valued function. Then
	\begin{align}\label{eq:lim_defn_for_vv_f}
		\lim_{t\to t_0}{\bf r}(t)=(\lim_{t\to t_0}r_1(t),\lim_{t\to t_0}r_2(t),\lim_{t\to t_0}r_3(t)).
	\end{align}	
\end{thm}

\begin{pf}
Let $\bl=(L_1,L_2,\dots,L_n)$ be a fixed vector in $\R^n$. We will prove that $\lim_{t \to t_0}\bbr(t)=\bl$ if and only if $\lim_{t \to t_0}r_i(t)=L_i$ for all $i=1,\dots,n$; that is, both sides of Equation \eqref{eq:lim_defn_for_vv_f} are either undefined, or they are both equal to $\bl$ and hence to each other.

($\implies$) First, suppose that $\lim_{t \to t_0}\bbr(t)=\bl$. Then, given $\epsilon>0$, there exists $\delta>0$ such that $||\bbr(t)-\bl||<\epsilon$ whenever $0<|t-t_0|<\delta$. By Lemma \ref{lem:useful_vector_inequalities}, for each $i=1,\dots,n$
\begin{align*}
	|r_i(t)-L_i|<||\bbr(t)-\bl||
\end{align*}
so we have $|r_i(t)-L_i|<\epsilon$ for each $i=1,\dots,n$ whenever $0<|t-t_0|<\delta$. Thus, $\lim_{t \to t_0}\bbr(t)=\bl$ implies that $\lim_{t \to t_0}r_i(t)=L_i$ for all $i=1,\dots,n$.

($\impliedby$) Now suppose that $\lim_{t \to t_0}r_i(t)=L_i$ for all $i=1,\dots,n$. Given $\epsilon>0$, there exist positive numbers $\delta_1,\delta_2,\dots,\delta_n$ such that $|r_i(t)-L_i|<\frac{\epsilon}{n}$ whenever $0<|t-t_0|<\delta_i$. By Lemma \ref{lem:useful_vector_inequalities}, 
\begin{align*}
	||\bbr(t)-\bl||<\sum_{i=1}^n|r_i(t)-L_i|,
\end{align*}
so by taking $\delta=\min\{\delta_1,\delta_2,\dots,\delta_n\}$, we have 
  \begin{align*}
	||\bbr(t)-\bl||<\sum_{i=1}^n|r_i(t)-L_i|<\epsilon
\end{align*}
whenever $|t-t_0|<\delta$. Thus, $\lim_{t \to t_0}r_i(t)=L_i$ for all $i=1,\dots,n$ implies that $\lim_{t \to t_0}\bbr(t)=\bl$.
\end{pf}

\begin{cor}[Uniqueness of the limit of a vector-valued function]
	If $\lim_{t \to t_0}\bbr(t)=\bl$, then the limit is unique.
\end{cor}

\begin{pf}
	Since the limits $\lim_{t \to t_0}r_i(t)=L_i$ are unique (if they exist) by Theorem \ref{thm:uniqueness_of_limits}, it follows immediately from Theorem \ref{thm:limit_of_a_vector-valued_function} that $\lim_{t \to t_0}\bbr(t)=\bl$ is unique if it exists.
\end{pf}


\begin{example}
Let $\bbr(t)=(1+t^3,te^{-t},\frac{\sin t}{t})$. Since
\begin{align*}
	\lim_{t \to 0}(1+t^3)&=1, \\
	\lim_{t \to 0}te^{-t}&=\lim_{t \to 0}t \lim_{t \to 0}e^{-t}=0 \cdot 1=0, \\
	\lim_{t \to 0}\frac{\sin t}{t}&=\lim_{t \to 0}\cos t=1 \hspace{0.5cm}\text{( by L'Hospital's rule)}
\end{align*}	
by Theorem \ref{thm:limit_of_a_vector-valued_function}
\begin{align*}
	\lim_{t \to 0}\bbr(t)&=\left(\lim_{t \to 0}(1+t^3),\lim_{t \to 0}te^{-t},\lim_{t \to 0}\frac{\sin t}{t}\right) \\
	&=(1,0,1).
\end{align*}
\end{example}

\begin{exercise}
Find $\lim_{t \to 1}\bbr(t)$, where $\bbr(t)=\left(\frac{t^2-t}{t-1},\sqrt{t+8},\frac{\sin(\pi t)}{\ln(t)}\right)$, if it exists.	
\end{exercise}

{\color{red} \begin{solution}
 	Since
 	\begin{align*}
 		\lim_{t \to 1}\frac{t^2-t}{t-1}&=\lim_{t \to 1}\frac{t(t-1)}{t-1}=\lim_{t \to 1}t=1, \\
 		\lim_{t \to 1}\sqrt{t+8}&=\sqrt{1+8}=\sqrt{9}=3, \\
 		\lim_{t \to 1}\frac{\sin(\pi t)}{\ln(t)}&=\lim_{t \to 1}\frac{\pi \cos(\pi t)}{\frac{1}{t}}=\lim_{t \to 1}\pi t\cos(\pi t)=\pi(1)\cos(\pi)=-\pi,
 	\end{align*}
 	by Theorem \ref{thm:limit_of_a_vector-valued_function}
 	\begin{align*}
 		\lim_{t \to 1}\bbr(t)&=\left(\lim_{t \to 1}\frac{t^2-t}{t-1},\lim_{t \to 1}\sqrt{t+8},\lim_{t \to 1}\frac{\sin(\pi t)}{\ln(t)}\right) \\
 		&=(1,3,-\pi).
 	\end{align*}
 \end{solution}}

\begin{thm}[Limit laws for vector-valued functions]\label{thm:limit_laws_for_vector-valued_functions}
	Let $\bu, \bv$ be vector valued functions into $\R^n$ defined on the same open interval containing $t_0$ and let $c \in \R$ be a constant. Then
	\begin{enumerate}[(i)]
		\item $\lim_{t \to t_0}(c_1,c_2,\dots,c_n)=(c_1,c_2,\dots,c_n)$ if $(c_1,c_2,\dots,c_n)$ is a constant vector in $\R^n$.
		\item $\lim_{t \to t_0}c\bu(t)=c\lim_{t \to t_0}\bu(t)$
		\item $\lim_{t \to t_0}[\bu(t)+\bv(t)]=\lim_{t \to t_0}\bu(t)+\lim_{t \to t_0}\bv(t)$
		\item $\lim_{t \to t_0}[\bu(t)\cdot\bv(t)]=\lim_{t \to t_0}\bu(t)\cdot\lim_{t \to t_0}\bv(t)$
		\item $\lim_{t \to t_0}[\bu(t)\times\bv(t)]=\lim_{t \to t_0}\bu(t)\times\lim_{t \to t_0}\bv(t)$ (for $n=3$)
	\end{enumerate}
\end{thm}

\begin{pf}
The proof of each of these follows by applying Theorems \ref{thm:limit_laws_for_single-variable_functions} and \ref{thm:limit_of_a_vector-valued_function}.
\begin{enumerate}[(i)]
	\item If $(c_1,c_2,\dots,c_n)$ is a constant vector in $\R^n$, then
		\begin{align*}
			\lim_{t \to t_0}(c_1,c_2,\dots,c_n)=(\lim_{t \to t_0} c_1,\lim_{t \to t_0} c_2,\dots,\lim_{t \to t_0} c_n)=(c_1,c_2, \dots, c_n).
		\end{align*}
	\item If $c \in \R$ is a constant, then
	\begin{align*}
		\lim_{t \to t_0}c\bu(t)&=\lim_{t \to t_0}c(u_1(t),u_2(t),\dots,u_n(t)) \\
		&=\lim_{t \to t_0}(cu_1(t),cu_2(t),\dots,cu_n(t)) \\
		&=(\lim_{t \to t_0}cu_1(t),\lim_{t \to t_0}cu_2(t),\dots,\lim_{t \to t_0}cu_n(t)) \\
		&=(c\lim_{t \to t_0}u_1(t),c\lim_{t \to t_0}u_2(t),\dots,c\lim_{t \to t_0}u_n(t)) \\
		&=c(\lim_{t \to t_0}u_1(t),\lim_{t \to t_0}u_2(t),\dots,\lim_{t \to t_0}u_n(t)) \\
		&=c\lim_{t \to t_0}(u_1(t),u_2(t),\dots,u_n(t)) \\
		&=c\lim_{t \to t_0}\bu(t).
	\end{align*}
	\item If $\bu(t),\bv(t)$ are vector-valued functions into $\R^n$, then
	\begin{align*}
		\lim_{t \to t_0}[\bu(t)+\bv(t)]&=\lim_{t \to t_0}[(u_1(t),\dots,u_n(t))+(v_1(t),\dots,v_n(t))] \\
		&=\lim_{t \to t_0}(u_1(t)+v_1(t),\dots,u_n(t)+v_n(t)) \\
		&=(\lim_{t \to t_0}(u_1(t)+v_1(t)),\dots,\lim_{t \to t_0}(u_n(t)+v_n(t))) \\
		&=(\lim_{t \to t_0}u_1(t)+\lim_{t \to t_0}v_1(t),\dots,\lim_{t \to t_0}u_n(t)+\lim_{t \to t_0}v_n(t)) \\
		&=(\lim_{t \to t_0}u_1(t),\lim_{t \to t_0}u_2(t),\lim_{t \to t_0}u_3(t))+(\lim_{t \to t_0}v_1(t),\lim_{t \to t_0}v_2(t),\lim_{t \to t_0}v_3(t)) \\
		&=\lim_{t \to t_0}(u_1(t),u_2(t),u_3(t))+\lim_{t \to t_0}(v_1(t),v_2(t),v_3(t)) \\
		&=\lim_{t \to t_0}\bu(t)+\lim_{t \to t_0}\bv(t).
	\end{align*}
	\item If $\bu(t),\bv(t)$ are vector-valued functions into $\R^n$, then
	\begin{align*}
		\lim_{t \to t_0}[\bu(t)\cdot\bv(t)]&=\lim_{t \to t_0} \sum_{i=1}^n u_i(t)v_i(t)\\
		&=\sum_{i=1}^n \lim_{t \to t_0} u_i(t)v_i(t)\\
		&=\sum_{i=1}^n \lim_{t \to t_0} u_i(t) \lim_{t \to t_0} v_i(t)\\
		&=\lim_{t \to t_0} \bu(t) \cdot \lim_{t \to t_0} \bv(t). 
	\end{align*}
	\item If $\bu,\bv$ are vector-valued functions into $\R^3$, then
	\begin{align*}
		&\lim_{t \to t_0}[\bu(t)\times\bv(t)]=\lim_{t \to t_0}(u_2(t)v_3(t)-u_3(t)v_2(t),-u_1(t)v_3(t)+u_3(t)v_1(t),u_1(t)v_2(t)-u_2(t)v_1(t)) \\
		&=(\lim_{t \to t_0}(u_2(t)v_3(t)-u_3(t)v_2(t)),\lim_{t \to t_0}(-u_1(t)v_3(t)+u_3(t)v_1(t)),\lim_{t \to t_0}(u_1(t)v_2(t)-u_2(t)v_1(t))) \\
		&=(\lim_{t \to t_0}u_2(t)\lim_{t \to t_0}v_3(t)-\lim_{t \to t_0}u_3(t)\lim_{t \to t_0}v_2(t),-\lim_{t \to t_0}u_1(t)\lim_{t \to t_0}v_3(t)+\lim_{t \to t_0}u_3(t)\lim_{t \to t_0}v_1(t), \\
		& \hspace{10cm}\lim_{t \to t_0}u_1(t)\lim_{t \to t_0}v_2(t)-\lim_{t \to t_0}u_2(t)\lim_{t \to t_0}v_1(t)) \\
		&=\lim_{t \to t_0}\bu(t)\times\lim_{t \to t_0}\bv(t).
	\end{align*}
\end{enumerate}
\end{pf}

\fixme{Add examples.}

\begin{defn}[Continuity]
	Let $\bbr(t)$ be defined on an open interval $(a,b)$ containing a point $t_0$. We say that $\bbr(t)$ is \emph{continuous at $t_0$} if $\lim_{t \to t_0}\bbr(t)=\bbr(t_0)$. We then say that $\bbr(t)$ is \emph{continuous on $(a,b)$} if $\bbr(t)$ is continuous at every point in $(a,b)$.
\end{defn}

\begin{thm}[Continuity of vector-valued functions]
	A vector-valued function $\bbr(t)=(r_1(t),\dots,r_n(t))$ is continuous at $t_0$ if and only if its component functions are all continuous at $t_0$.
\end{thm}

\begin{pf}
This follows immediately from Theorem \ref{thm:limit_of_a_vector-valued_function}.	
\end{pf}

\begin{example}
The vector-valued function $\bbr(t)=(\cos t, \sin t, t)$ is continuous on $\R$ since its component functions are each continuous on $\R$.	
\end{example}

\begin{thm}[New continuous vector-valued functions from old]
Let $\bu$ and $\bv$ be two vector-valued functions on $\R^n$ which are continuous at $t_0$ and let $c$ be a constant. Then the following functions are also continuous at $t_0$:
\begin{enumerate}[(i)]
	\item $c\bu(t)$
	\item $\bu(t)+\bv(t)$
	\item $\bu(t) \cdot \bv(t)$
	\item $\bu(t) \times \bv(t)$ (for $n=3$)
\end{enumerate}	
\end{thm}

\begin{pf}
	The proof follows immediately from Theorem \ref{thm:limit_laws_for_vector-valued_functions}. 
\end{pf}

The following theorem will be very useful to us in the next section.

\begin{thm}[Continuity of composite function]
	Let $\bbr:\R \to \R^n$ be a continuous vector-valued function and $\varphi:\R \to \R$ a continuous real-valued function. Then the composite function $\tilde{\bbr}=\bbr \circ \varphi:\R \to \R^n$ is continuous.
\end{thm}

\begin{pf}
Since $\bbr(t)$ is continuous, given $\epsilon>0$ there exists $\eta>0$ such that $||\bbr(\varphi(t))-\bbr(\varphi(t_0))||<\epsilon$ whenever $|\varphi(t)-\varphi(t_0)|<\eta$. Since $\varphi(t)$ is continuous, corresponding to $\eta$ there exists $\delta>0$ such that $|\varphi(t)-\varphi(t_0)|<\eta$ whenever $|t-t_0|<\delta$. Thus, given $\epsilon>0$, there exists $\delta>0$ such that $||\bbr(\varphi(t))-\bbr(\varphi(t_0))||<\epsilon$ whenever $|t-t_0|<\delta$.
\end{pf}

\fixme{Add example.}

\subsubsection{Derivatives of vector-valued functions}
\begin{defn}[Derivative of a vector-valued function]
	The \emph{derivative} of a vector-valued function $\bbr(t)$ is the limit
	\begin{align*}
		\bbr'(t)=\lim_{h \to 0}\frac{\bbr(t+h)-\bbr(t)}{h}.
	\end{align*}
	The function $\bbr$ is said to be \emph{differentiable at $t_0$} if $\bbr'(t_0)$ exists, and $\bbr$ is said to be \emph{differentiable on $(a,b)$} if $\bbr'(t)$ exists for all $t \in (a,b)$.
\end{defn}
Geometrically, $\bbr'(t_0)$ is the \emph{tangent vector} to the curve $\bbr$ at $\bbr(t)$.

\begin{figure}[h]
	\begin{center}
	\includegraphics[scale=0.4]{figures_mvc/tangent_vector_secant_vector}
\end{center}
\caption{The derivative $\bbr'(t)$ is the tangent vector to the curve $\bbr$ at $\bbr(t)$.}
\end{figure}
The next theorem shows that we can compute the derivative of a vector-valued function in terms of the derivatives of its component functions.

\begin{thm}[Derivative of a vector-valued function]\label{thm:derivative_of_a_vector-valued_function}
	The derivative of a vector-valued function $\bbr(t)=(r_1(t),r_2(t),r_3(t))$ is given by 
	\begin{align*}
		\bbr'(t)=(r_1'(t),r_2'(t),r_3'(t)).
	\end{align*}
\end{thm}

\begin{pf}
By Theorem \ref{thm:limit_of_a_vector-valued_function}
\begin{align*}
	\bbr'(t)&=\lim_{h \to 0}\frac{\bbr(t+h)-\bbr(t)}{h} \\
	&=\lim_{h \to 0}\frac{(r_1(t+h),r_2(t+h),r_3(t+h))-(r_1(t),r_2(t),r_3(t))}{h} \\
	&=\lim_{h \to 0}\frac{(r_1(t+h)-r_1(t),r_2(t+h)-r_2(t),r_3(t+h)-r_3(t))}{h} \\
	&=\lim_{h \to 0}\left(\frac{r_1(t+h)-r_1(t)}{h},\frac{r_2(t+h)-r_2(t)}{h},\frac{r_3(t+h)-r_3(t)}{h}\right) \\
	&=\left(\lim_{h \to 0}\frac{r_1(t+h)-r_1(t)}{h},\lim_{h \to 0}\frac{r_2(t+h)-r_2(t)}{h},\lim_{h \to 0}\frac{r_3(t+h)-r_3(t)}{h}\right) \\
	&=(r_1'(t),r_2'(t),r_3'(t)).
\end{align*}	
\end{pf}

\fixme{Add examples.}

\begin{thm}[Differentiation formulas]
	Let $\bu,\bv$ be differentiable vector-valued functions into $\R^n$, $c$ a constant, and $\varphi:\mathbb{R} \to \mathbb{R}$ a real-valued function. Then
\begin{enumerate}[(1)]
		\item $[\bu(t)+\bv(t)]'=\bu'(t)+\bv'(t)$
		\item $[c\bu(t)]'=c\bu'(t)$
		\item $[\varphi(t)\bu(t)]'=\varphi'(t)\bu(t)+\varphi(t)\bu'(t)$
		\item $[\bu(t)\cdot \bv(t)]'=\bu'(t)\cdot \bv(t)+\bu(t) \cdot \bv'(t)$
		\item $[\bu(t)\times \bv(t)]'=\bu'(t)\times \bv(t)+\bu(t) \times \bv'(t)$ (for $n=3$)
		\item $[\bu(\varphi(t))]'=\varphi'(t)\bu'(\varphi(t))$
	\end{enumerate}	
\end{thm}

\begin{pf}
The proof follows immediately from Theorem \ref{thm:derivative_of_a_vector-valued_function} and the corresponding properties for real-valued functions.
\end{pf}


\begin{defn}[Higher derivatives]
	\begin{enumerate}[(a)]
		\item The \emph{second derivative}, $\bbr''$, of a vector-valued function $\bbr$ is the derivative of $\bbr'$: $\bbr''=(\bbr')'$. Thus,
\begin{align*}
	\bbr''(t)=(f''(t), g''(t), h''(t))
\end{align*}
Similarly, for $k$ a positive integer, the $k$th derivative of $\bbr$ is given by the formula
\begin{align*}
	\bbr^{(k)}(t)=(f^{(k)}(t), g^{(k)}(t), h^{(k)}(t)).
\end{align*}
\item A vector-valued function is said to be \emph{of class $\mathscr{C}^k$} if its first $k$ derivatives exist and are continuous and \emph{of class $\mathscr{C}^\infty$} if all of its derivatives exist. Functions in the class $\mathscr{C}^\infty$ are also called \emph{smooth}.
	\end{enumerate}
\end{defn}

\subsection{Parametrized Curves}
We will now focus on a special class of vector-valued functions, which model the motion of a particle through space. Our interest will primarily be in the geometry of the particle's trajectory.

\begin{defn}[Parametrized curve]
	Let $I$ be an interval. A \emph{parametrized curve} is a smooth mapping $\bbr:I \to \mathbb{R}^n$. For $n=2$, a curve is also called a \emph{plane curve} while for $n=3$ it is also called a \emph{space curve}. The variable $t$ is called the \emph{parameter}. The image $\bbr(I) \subseteq \R^n$ is called the \emph{trace} of the curve $\bbr$. \footnote{The \emph{image of $I$ under $\bbr$} is the set $\bbr(I)=\{\bbr(t):t \in I\}$.}
\end{defn}

\begin{remark}
Every interval in $\R$ is of one of the following forms:
\begin{align*}
	(-\infty,b), (-\infty,b], (a,b), [a,b), (a,b], [a,b],[a,\infty), (a,\infty).
\end{align*}
If $I$ is an interval containing boundary points, such as $[a,b]$, then we define $f'(a)$ as the right-hand limit
\begin{align*}
	f'(a)=\lim_{h \to 0^+}\frac{f(a+h)-f(a)}{h}
\end{align*}
and, $f'(b)$ as the left-hand limit
\begin{align*}
	f'(b)=\lim_{h \to 0^-}\frac{f(b+h)-f(b)}{h}.
\end{align*}
\end{remark}


\begin{example}
The graph of any smooth function $y=f(x)$ can be written as a parametrized curve by defining
\begin{align*}
	\bbr:\R &\to \R^2 \\
	\bbr(t)&=(t,f(t)).
\end{align*}
For example, the function $y=x^2$ can be written the parametrized curve $\bbr(t)=(t,t^2)$ for all $-\infty < t < \infty$.	The trace of a plane curve can be plotted in \emph{Mathematica} as shown below:

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.5]{figures_mvc/parab_param_plot}
	\end{center}
	\caption{The trace of the plane curve $\bbr(t)=(t,t^2)$.}
\end{figure} 

The particle moves down the parabola from the upper left starting at $t=-\infty$, reaches the origin at $t=0$, and then continues up the parabola to the upper right for all $t>0$.
\end{example}

\begin{exercise}
Sketch the trace of the plane curve $\bbr(t)=(t^2-2t,t+1)$, $-\infty < t < \infty$ in by making a table of the coordinates $(x(t),y(t))$ for integer values of $t$ from $-2 \leq t \leq 4$. Compare your sketch with the curve produced in \emph{Mathematica} using the ``ParametricPlot" command.	
\end{exercise}
{\color{red}
\begin{solution}
	The curve is a parabola, which we can confirm by eliminating $t$ as follows. First, solve for $t$ in terms of $y$ to obtain
\begin{align*}
	y=t+1 \implies y-1=t.
\end{align*}
Substituting into $x(t)$ then gives $x$ in terms of $y$:
\begin{align*}
	x=t^2-2t=(y-1)^2-2(y-1)=y^2-4y+3=(y-2)^2-1.
\end{align*}
which is the equation of a parabola in vertex form, with vertex at $(x,y)=(-1,2)$. 

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.5]{figures_mvc/sideways_parab_mma}
	\end{center}
	\caption{The trace of the plane curve $\bbr(t)=(t^2-2t,t+1)$ from $-2 \leq t \leq 4$.}
\end{figure}

The particle travels upwards along the parabola from $t=-\infty$, reaches the vertex at $t=1$, and then continues upward to the right for $t>0$.
\end{solution}}



\begin{example}\label{ex:unit_circ}
Consider the following three plane curves 
\begin{enumerate}[(1)]
	\item $\bbr_1(t)=(\cos t, \sin t), 0 \leq t \leq 2\pi$, 
	\item $\bbr_2(t)=(-\sin 2t, \cos 2t), 0 \leq t \leq 2\pi$,
	\item $\bbr_3(t)=(\cos(-t), \sin(-t)), 0 \leq t \leq 2\pi$.
\end{enumerate}	
For all three curves, $x(t)^2+y(t)^2=1$, so the trace of each curve is the unit circle. However, the curves are different. The reader can easily verify the following by making a table for each curve and sketching the trace:
\begin{enumerate}[(1)]
	\item In $\bbr_1$, the particle begins at $(x,y)=(1,0)$ at $t=0$ and completes one full circle, moving in the counterclockwise direction.
	\item In $\bbr_2$, the particle begins at $(x,y)=(0,1)$ at $t=0$ and completes \emph{two} full circles, moving in the counterclockwise direction.
	\item In $\bbr_3$, the particle begins at $(x,y)=(1,0)$ at $t=0$ and completes one full circle, moving in the \emph{clockwise} direction.
\end{enumerate}
\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.4]{figures_mvc/circ_param_plot_mma}
	\end{center}
	\caption{The trace of the curves $\bbr_1,\bbr_2,\bbr_3$.}
\end{figure}
\end{example}
The previous example shows that a parametrized curve is more than just the trace: it is the trace together with a choice of how to traverse the trace of curve.

\begin{example}
Consider now the trace of the plane curve $\bbr(t)=(t^3,t^2)$, $-\infty<t<\infty$.

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.4]{figures_mvc/cusp_mma}
	\end{center}
\end{figure}
Since the component functions are smooth, the reader may be surprised by the cusp at the origin. Solving for $y$ in terms of $x$ by eliminating $t$, we find that $y=x^{2/3}$, which is indeed not differentiable at the origin. Note that $\bbr'(t)=(3t^2,2t)\neq (0,0)$ everywhere except the origin, where the tangent vector vanishes.
\end{example}
 
\begin{defn}[Regular curve]
	Let $\bbr:I \to \R^n$ be a parametrized curve.
	\begin{enumerate}[(a)]
		\item A point where $\bbr'(t)={\bf 0}$ is called a \emph{singular point}, while a point where $\bbr'(t) \neq {\bf 0}$ is called a \emph{regular point}.
		\item A \emph{regular curve} is a curve with no singular points; that is, it is a curve for whice $\bbr'(t) \neq {\bf 0}$ for all $t \in I$.
	\end{enumerate}
\end{defn}
In our study of the differential geometry of curves, we will assume the curve has a tangent vector at every point. Thus, from now on we will assume all curves are regular.

\subsection{Reparametrizations}
Recall the three regular curves from Example \ref{ex:unit_circ}:
\begin{enumerate}[(1)]
	\item $\bbr_1(t)=(\cos t, \sin t), 0 \leq t \leq 2\pi$, 
	\item $\bbr_2(t)=(-\sin 2t, \cos 2t), 0 \leq t \leq 2\pi$,
	\item $\bbr_3(t)=(\cos(-t), \sin(-t)), 0 \leq t \leq 2\pi$.
\end{enumerate}	
We have noticed that all three curves have exactly the same trace; namely, the unit circle. If we are only interested in the geometry of the trace of the curve, then we should view all parametrized curves with the same trace as equivalent. We now formalize this idea.

First, notice that if we define the function
\begin{align*}
	\varphi:[0,2\pi] \to [0,2\pi]
\end{align*}
by 
\begin{align*}
	\varphi(t)=2t+\frac{\pi}{2}
\end{align*}
then we see that $\bbr_2$ is equal to the composition $\bbr_2=\bbr_1 \circ \varphi$, since for all $t \in [0,2\pi]$
\begin{align*}
	\bbr_1(\varphi(t))&=(\cos(2t+\frac{\pi}{2}),\sin(2t+\frac{\pi}{2})) \\
	&=(\cos(2t)\underbrace{\cos(\frac{\pi}{2})}_{=0}-\sin(2t)\underbrace{\sin(\frac{\pi}{2})}_{=1}, \sin(2t)\underbrace{\cos(\frac{\pi}{2})}_{=0}+\cos(2t)\underbrace{\sin(\frac{\pi}{2})}_{=1}) \\
	&=(-\sin(2t),\cos(2t)) \\
	&=\bbr_2(t).
\end{align*}

\fixme{Speed vs time interval.} To understand this relationship, recall that a parametrized curve $\bbr(t)$ is a function which gives the position of the particle at time $t$, with respect to a given clock. If $\varphi$ denotes the time with respect to a different clock, then $\bbr(\varphi)$ gives the position of the particle at time $\varphi$. The particles follow the same trajectory, but are at different positions at different times if the two clocks are not synchronized. In this example, the clocks are related by $\varphi=2t+\frac{\pi}{2}$; that is, the $\varphi$-clock is $\frac{\pi}{2}$ seconds ahead of the $t$-clock (since $\varphi=\frac{\pi}{2}$ when $t=0$), and runs half as fast (since if the time interval between two successive ticks of the $t$-clock is $\Delta t=1$ s, then the time interval between two successive ticks of the $\varphi$-clock is  $\Delta \varphi=2\Delta t=2$ s; that is, if the $t$-clock ticks once every second, then the $\varphi$-clock ticks once every two seconds). Thus, if $\bbr_1(t)$ describes a single trip around the unit circle in the counterclockwise sense at unit speed, then, with respect to the $t$-clock, $\bbr_1(\varphi)=\bbr_2(t)$ describes a particle that is already at $(0,1)$ when $t=0$ and completes two trips around the circle at double speed in $2\pi$ seconds.

\begin{exercise}\label{ex:orient_reve}
Verify that by defining $\varphi:[0,2\pi] \to [0,2\pi]$ by $\varphi(t)=2\pi-t$, then $\bbr_3=\bbr_1 \circ \varphi$. Interpret this as above.	
\end{exercise}

{\color{red}
\begin{solution}
We see that $\bbr_1(\varphi(t))=(\cos(2\pi-t),\sin(2\pi-t))=(\cos(-t),\sin(-t))=\bbr_3(t)$ for all $t$. The $\varphi$-clock is related to the $t$-clock by ``time-reversal"; that is, the clocks run at the same speed, but the $\varphi$ clock runs backwards with respect to the $t$-clock, since $\varphi(t)$ is a decreasing function of $t$ with $\varphi(0)=2\pi$ and $\varphi(2\pi)=0$.	
\end{solution}
}
\begin{defn}[Reparametrization]
	Let $\bbr:I \to \mathbb{R}^n$ be a regular curve. A \emph{reparametrization} of $\bbr$ is a function of the form $\widetilde{\bbr}=\bbr \circ \varphi:\tilde{I} \to \mathbb{R}^n$, where $\tilde{I}$ is an interval and $\varphi:\tilde{I} \to I$ is a smooth bijection with nowhere vanishing derivative ($\varphi'(t) \neq 0$ for all $t \in \tilde{I}$). \footnote{While in each of the examples above we had $\varphi:\tilde{I} \to I$ with $\tilde{I}=I$, these intervals need not be the same. For instance, in Example \ref{ex:orient_reve}, we could have instead taken $\varphi:[0,2\pi] \to [-2\pi,0]$ where $\varphi(t)=-t$.}
\end{defn}

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.5]{figures_mvc/reparametrization}
	\end{center}
\end{figure}

\begin{remark}
Note that the hypotheses on $\varphi$ are all required to ensure that $\widetilde{\bbr}=\bbr \circ \varphi$ has the same trace as $\bbr$:
\begin{itemize}
	\item The requirement that $\varphi$ is smooth ensures that $\widetilde{\bbr}$ is smooth, since the composition of smooth functions is smooth.
	\item The requirement that $\varphi$ is a bijection is also essential. If $\varphi$ is not surjective, then the trace of $\widetilde{\bbr}$ will only be a proper subset of the trace of $\bbr$. If $\varphi$ is not injective, then $\widetilde{\bbr}$ will have self-intersections at points where $\bbr$ does not (since if $\varphi(t_1)=\varphi(t_2)$ for $t_1 \neq t_2$, then even if $\bbr(t_1) \neq \bbr(t_2)$, we will have $\widetilde{\bbr}(\varphi(t_1))=\widetilde{\bbr}(\varphi(t_2))$). \fixme{Maybe say this better or give an example.}
	\item The requirement that $\varphi'(t) \neq 0$ for all $t$ ensures that $\widetilde{\bbr}(t)$ is regular, since if $\bbr(t)$ is regular and $\varphi'(t) \neq 0$, then by the chain rule
	\begin{align*}
		\widetilde{\bbr}'(t)=\varphi'(t)\bbr'(t) \neq 0.
	\end{align*}
\end{itemize}
\fixme{Give examples or an exercise in which each of these separately fail.}
\end{remark}

\begin{prop}[Reparametrized curves are equivalent]
The relation $\widetilde{\bbr} \sim \bbr$ if $\widetilde{\bbr}$ is a reparametrization of $\bbr$ is an equivalence relation. 	
\end{prop}

\begin{pf}
	\begin{enumerate}[(1)]
		\item (Reflexivity) Let $\bbr:I \to \R^n$ be a parametrized curve. Take $\varphi=id_I:T \to I$ to be the identity map on $I$. This is a smooth bijection, and since $id_I(t)=t$, $id_I'(t)=1 \neq 0$ for all $t \in I$. Since $\bbr=\bbr \circ id_I$, $\bbr \sim \bbr$. Thus, $\sim$ is reflexive.
		\item (Symmetry) Suppose $\bbr:I \to \R^n$ and $\widetilde{\bbr}:\tilde{I} \to \R^n$ are parametrized curves with $\widetilde{\bbr} \sim \bbr$. Then there exists a smooth bijection $\varphi: \tilde{I} \to I$ with $\varphi'(t) \neq 0$ for all $t \in \tilde{I}$. It follows from the Inverse Function Theorem that $\varphi$ has a smooth inverse, $\varphi^{-1} :I \to \tilde{I}$, where $(\varphi^{-1})'(t)=1/\varphi'(t)$ Since $\varphi'(t)$ is never zero, neither is $(\varphi^{-1})'(t)$. \footnote{The \emph{Inverse Function Theorem} states that if $f:\R \to \R$ is continuously differentiable with $f'(a) \neq 0$ then $f$ is invertible in a neighborhood of $a$, the inverse is continuously differentiable, and the derivative of the inverse function at $b=f(a)$ is the reciprocal of the derivative of $f$ at $a$. Applying this to the $k$-th derivative, it follows as a corollary that we can replace ``continuously differentiable" everywhere in the theorem above by ``smooth". \fixme{Omit?} The \emph{Gluing Lemma} then allows us to patch together the inverse on each neighborhood into an inverse defined on the entire interval $I$.} This proves that $\widetilde{\bbr} \sim \bbr$ implies that $\bbr \sim \widetilde{\bbr}$. Thus, $\sim$ is symmetric.
		\item (Transitivity) Let
		\begin{align*}
			\bbr_1:I_1 &\to \R^n, \\
			\bbr_2:I_2 &\to \R^n, \\
			\bbr_3:I_3 &\to \R^n, \\
		\end{align*}
		be parametrized curves and suppose $\bbr_1 \sim \bbr_2$ and $\bbr_2 \sim \bbr_3$. Then there exist smooth bijections 
		\begin{align*}
			\varphi:I_2 &\to I_1, \\
			\psi:I_3 &\to I_2
		\end{align*} 
		with nowhere vanishing first derivatives such that
		\begin{align*}
			\bbr_2&=\bbr_1 \circ \varphi, \\
			\bbr_3&=\bbr_2 \circ \psi
		\end{align*}
		Then $\varphi \circ \psi:I_3 \to I_1$ is a smooth bijection with nowhere vanishing derivative such that
		\begin{align*}
			\bbr_3=\bbr_1 \circ \varphi \circ \psi.
		\end{align*}
		Thus, $\bbr_1 \sim \bbr_3$.
	\end{enumerate}
	This shows that $\sim$ is reflexive, symmetric, and transitive, and is therefore an equivalence relation.
\end{pf}
\begin{defn}[Curve]
	The we call the equivalence class
	\begin{align*}
		[\bbr]\equiv \{\widetilde{\bbr}:\widetilde{\bbr}=\bbr \circ \varphi \text{ for some } \varphi\}
	\end{align*} 
 a \emph{curve} in $\R^n$. Any parametrized curve $\widetilde{\bbr}(t)$ in $[\bbr]$ is said to be a \emph{representative} of the equivalence class $[\bbr]$. \fixme{Show that if two curves have the same trace, then they are equivalent.}
\end{defn}
Let $\bbr(t)$ be a parametrized curve and let $\widetilde{\bbr}=\bbr \circ \varphi$ be a reparametrization of $\bbr(t)$. Since $\varphi'(t)$ is nowhere 0, $\varphi$ must be either monotonically increasing ($\varphi'>0$) or monotonically decreasing ($\varphi'<0$) on all of $\tilde{I}$.

\begin{defn}[Oriented curves]
A reparametrization $\widetilde{\bbr}=\bbr \circ \varphi$ is said to be \emph{orientation-preserving} if $\varphi'>0$ and \emph{orientation-reversing} if $\varphi'<0$. Thus, each curve $[\bbr]$ is partitioned into two subsets
\begin{align*}
	[\bbr]_+&=\{\widetilde{\bbr}:\widetilde{\bbr}=\bbr \circ \varphi \text{ with } \varphi'>0\}, \\
	[\bbr]_-&=\{\widetilde{\bbr}:\widetilde{\bbr}=\bbr \circ \varphi \text{ with } \varphi'<0\}. \\
\end{align*}
Each subset is called an \emph{oriented curve}. A choice of orientation of a curve $[\bbr]$ is a choice of one of these two subsets.
\end{defn}

\begin{example}
Consider again three parametrized curves from Example \ref{ex:unit_circ} and :
\begin{enumerate}[(1)]
	\item $\bbr_1(t)=(\cos t, \sin t), 0 \leq t \leq 2\pi$, 
	\item $\bbr_2(t)=(-\sin 2t, \cos 2t), 0 \leq t \leq 2\pi$,
	\item $\bbr_3(t)=(\cos(-t), \sin(-t)), 0 \leq t \leq 2\pi$.
\end{enumerate}	
We have seen that $\bbr_2=\bbr_1 \circ \varphi$ where $\varphi(t)=2t+\frac{\pi}{2}$. Since $\varphi'(t)=2>0$, these two curves have the same orientation (i.e., they are representatives of the same oriented curve). We also saw that $\bbr_3=\bbr_1 \circ \psi$ where $\psi(t)=2\pi-t$. Since $\psi'(t)=-1<0$, these two curves have opposite orientations.
\end{example}
\fixme{Add exercises.}

\subsection{Arc Length}
We have just seen that a given curve can be parametrized in many ways. Out of these many options, there is a natural choice for the parameter $t$, namely, the \emph{arc length} measured from any point $\bbr_0$ on the curve. This is because the arc length is an \emph{invariant} of the curve, which is independent of the parametrization. For a curve given by the graph of a function $y=f(x)$, the arc length from $a$ to $b$ is given by
\begin{align}\label{eq:arc_leng_f_x}
	s=\int_a^b\sqrt{1+(f'(x))^2}dx.
\end{align}
Writing the function as a parametrized curve $\bbr(t)=(t,f(t))$, we have $\bbr'(t)=(1,f'(t))$ and $||\bbr'(t)||=\sqrt{1+(f'(t))^2}$, so we can write Equation \eqref{eq:arc_leng_f_x} as
\begin{align}\label{eq:arc_length_gen}
	s=\int_a^b||\bbr'(t)||dt.
\end{align}
\fixme{Add example.}
How do we compute the arc length if $\bbr(t)$ is not the graph of a function? If $\bbr(t)$ is not the graph of a function, it turns out that Equation \eqref{eq:arc_length_gen} is still valid. In this case, we obtain the formula as the limit of a sequence of polygonal approximations of the curve (the proof is given in Appendix \ref{app:arc_length}). 

\begin{defn}{Arc length}\label{def:arc_length}
Let $\bbr:[a,b] \to \R^n$ be a regular curve. We define the \emph{arc length} between the points $\bbr(a)$ and $\bbr(b)$ on the curve by
\begin{align*}
	s=\int_a^b||\bbr'(t)||dt.
\end{align*}	
\end{defn}

\begin{example}\label{ex:unit_circl_ex}
We now compute the arc length along the portion of the unit circle from $(1,0)$ to $(0,1)$. If we use the parametrization
\begin{align*}
	\bbr_1(t)=(\cos t,\sin t), 0 \leq t \leq \frac{\pi}{2},
\end{align*}	
then we have
\begin{align*}
	\bbr_1'(t)&=(-\sin t,\cos t), \\
	||\bbr_1'(t)||&=\sqrt{(-\sin t)^2+(\cos t)^2}=\sqrt{1}=1.
\end{align*}
Equation \eqref{eq:arc_length_gen} then gives
\begin{align*}
	s=\int_0^{\frac{\pi}{2}}||\bbr_1'(t)||dt=\int_0^{\frac{\pi}{2}}dt=\frac{\pi}{2}.
\end{align*}
\end{example}

\begin{exercise}
Use the parametrization $\bbr_2(t)=(\cos(2t),\sin(2t)), 0 \leq t \leq \frac{\pi}{4}$ to compute the arc length of the same portion of the unit circle as in Example \ref{ex:unit_circl_ex}. Verify that you get the same answer.	
\end{exercise}

{\color{red}
\begin{solution}
	Using the parametrization $\bbr_2(t)=(\cos(2t),\sin(2t))$, $0 \leq t \leq \frac{\pi}{4}$, we have
	\begin{align*}
		\bbr_2'(t)&=(-2\sin(2t),2\cos(2t)), \\
		||\bbr_2'(t)||&=\sqrt{4\sin^2(2t)+4\cos^2(2t)}=\sqrt{4(\sin^2(2t)+\cos^2(2t))}=\sqrt{4}=2
	\end{align*} 
	and therefore
	\begin{align*}
		s=\int_0^{\frac{\pi}{4}}||\bbr_2'(t)||dt=2\int_0^{\frac{\pi}{4}}dt=2\cdot \frac{\pi}{4}=\frac{\pi}{2}.
	\end{align*}
\end{solution}}

\begin{exercise}
A \emph{logarithmic spiral} is a plane curve of the form $\bbr(t)=c(e^{\lambda t}\cos t,e^{\lambda t}\sin t)$, $t \in \mathbb{R}$ where $c,\lambda \in \mathbb{R}$ and $c \neq 0$. Below is the restriction of $\bbr(t)$ to $[0,\infty)$ with $\lambda <0$.	

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.5]{figures_mvc/log_spiral}
	\end{center}
\end{figure}
Use an improper integral to prove that such a restriction has finite arc length even though it makes infinitely many loops around the origin.
\end{exercise}

{\color{red}
\begin{solution}
	We have
	\begin{align*}
		\bbr'(t)&=c(\lambda e^{\lambda t}\cos t-e^{\lambda t}\sin t,\lambda e^{\lambda t}\sin t+e^{\lambda t}\cos t) \\
		&=ce^{\lambda t}(\lambda \cos t-\sin t, \lambda \sin t+\cos t)
	\end{align*}
	and therefore
	\begin{align*}
		||\bbr'(t)||&=|c|e^{\lambda t}\sqrt{(\lambda \cos t-\sin t)^2+(\lambda \sin t+\cos t)^2} \\
		&=|c|e^{\lambda t}\sqrt{\lambda^2\cos^2 t+\sin^2 t-2\lambda \sin t \cos t+\lambda^2\sin^2 t+ \cos ^2 t+2\lambda \sin t\cos t} \\
		&=|c|e^{\lambda t}\sqrt{\lambda^2+1}.
	\end{align*}
	The arc length is then given by the integral
	\begin{align*}
		s=\int_0^\infty ||\bbr'(t)||dt=|c|\sqrt{\lambda^2+1}\int_0^\infty e^{-|\lambda|t}dt.
	\end{align*}
	Substituting
	\begin{align*}
		u=-|\lambda|t, \ du=-|\lambda|dt,
	\end{align*}
	this becomes
	\begin{align*}
		s&=-\frac{|c|\sqrt{\lambda^2+1}}{|\lambda|}\int_0^{-\infty}e^{u}du \\
		&=-\frac{|c|\sqrt{\lambda^2+1}}{|\lambda|}\lim_{k \to -\infty}(e^k-1) \\
		&=-\frac{|c|\sqrt{\lambda^2+1}}{|\lambda|}(0-1) \\
		&=\frac{|c|\sqrt{\lambda^2+1}}{|\lambda|}.
	\end{align*}
\end{solution}}

\begin{prop}[Invariance of arc length]
	The arc length is independent of parametrization.
\end{prop}

\begin{pf}
Let $\widetilde{\bbr}=\bbr \circ \varphi$ be a reparametrization of $\bbr$. Then since
\begin{align*}
	\widetilde{\bbr}'(t)&=[\bbr(\varphi(t))]'=\varphi'(t)\bbr'(\varphi(t)),
\end{align*}
we have
\begin{align*}
	s&=\int_{t_0}^{t_1}||\widetilde{\bbr}'(t)||dt \\
	&=\int_{t_0}^{t_1}||\varphi'(t)\bbr'(\varphi(t))||dt \\
	&=\int_{t_0}^{t_1}||\bbr'(\varphi(t))|| \ |\varphi'(t)|dt \\
\end{align*}	
If $\varphi'(t)>0$, then $|\varphi'(t)|=\varphi'(t)$ and by substituting
\begin{align*}
	u=\varphi(t), \ du=\varphi'(t)dt
\end{align*}
we obtain
\begin{align*}
	s=\int_{\varphi(t_0)}^{\varphi(t_1)}||\bbr'(u)||du.
\end{align*}
If $\varphi'(t)<0$, then $|\varphi'(t)|=-\varphi'(t)$ and the same substitution gives
\begin{align*}
	s=-\int_{\varphi(t_0)}^{\varphi(t_1)}||\bbr'(u)||du=\int_{\varphi(t_0)}^{\varphi(t_1)}||\bbr'(u)||du.
\end{align*}
\fixme{Include figure?}
\end{pf}

\begin{prop}[Any regular curve can be parametrized by arc length]
	Any regular curve $\bbr:I \to \R^n$ can be parametrized by arc length.
\end{prop}

\begin{pf}
Choose $t_0 \in I$ and consider the arc length function $s:I \to \R$ defined by
\begin{align*}
	s(t)=\int_{t_0}^t||\bbr'(u)||du. 
\end{align*}	
Let $\tilde{I}=s(I)$ denote the image of $I$ under $s$. By the Fundamental Theorem of Calculus, $s'(t)=||\bbr'(t)|| \neq 0$ (since the curve is regular), so by the Inverse Function Theorem $s$ has an inverse $\varphi:\tilde{I} \to I$, which is also a smooth bijection with a nowhere-vanishing derivative. Then $\widetilde{\bbr}=\bbr \circ \varphi$ is parametrized by arc length, since $\bbr(\varphi(s))$ is the position of a point along the curve at the time when it achieves arc length $s$ measured from $t_0$.
\end{pf}

\begin{example}\label{ex:helix_param_by_arc_length}
Consider the helix $\bbr(t)=(\cos t, \sin t, t)$, $t \in \R$. 
\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.5]{figures_mvc/helix_fig}
	\end{center}
\end{figure}

 Let us reparametrize the helix with respect to the arc length measured from $(1,0,0)$ in the direction of increasing $t$. Since $\bbr(0)=(1,0,0)$, following the proof above we define
\begin{align*}
	s(t)=\int_0^t||\bbr'(u)||du.
\end{align*}
Since $\bbr'(u)=(-\sin u,\cos u,1)$, we have $||\bbr'(u)||=\sqrt{2}$ and therefore
\begin{align*}
	s(t)&=\int_0^t||\bbr'(u)||du \\
	&=\sqrt{2}\int_0^t du \\
	&=\sqrt{2}t.
\end{align*}
The inverse function is then easily obtained:
\begin{align*}
	\varphi(s)=\frac{s}{\sqrt{2}}
\end{align*}
and 
\begin{align*}
	\bbr(\varphi(s))=\left(\cos\left(\frac{s}{\sqrt{2}}\right),\sin\left(\frac{s}{\sqrt{2}}\right),\frac{s}{\sqrt{2}}\right).
\end{align*}
\end{example}

\begin{example}
Let's reparametrzie the plane curve $\bbr(t)=(\cos(3t),\sin(2t))$ with respect to arc length measured from $(1,0)$ in the direction of increasing $t$. Since
	\begin{align*}
		\bbr'(t)&=(-3\sin(3t),2\cos(2t)) \\
		||\bbr'(t)||&=\sqrt{9\sin^2(3t)+4^2\cos(2t)},
	\end{align*}
	the arc length function is given by
	\begin{align*}
		s(t)=\int_0^t\sqrt{9\sin^2(3t)+4\cos^2(2t)}dt
	\end{align*}
	This integral cannot be evaluated in terms of elementary functions. \fixme{Explain what this means.} This example illustrates that, while our proof gave an explicit method to parametrize any curve by arc length, in practice it is usually not computationally reasonable to implement. However, we will use the fact that every curve can be parametrized by arc length for theoretical purposes.
\end{example}

\begin{prop}
	A curve parametrized by arc length is a \emph{unit speed curve}; that is, $||\bbr'(t)||=1$ for all $t \in I$.
\end{prop}

\begin{proof}
	If $\bbr$ is parametrized by arc length, then by the Fundamental Theorem of Calculus
	\begin{align*}
		s'(t)=\frac{d}{dt}\int_{t_0}^t||\bbr'(u)||du=||\bbr'(t)||=1.
	\end{align*}
	Conversely, suppose $||\bbr'(t)||=1$ for all $t$. Then
	\begin{align*}
		s(t)=\int_{t_0}^t||\bbr'(u)||du=\int_{t_0}^tdu=t-t_0
	\end{align*}
	so $t$ is equal to the arc length accumulated from the point $t_0$.
\end{proof}

\begin{exercise}
Verify that the helix parametrized by arc length in Example \ref{ex:helix_param_by_arc_length} is a unit speed curve.	
\end{exercise}

{\color{red}
\begin{solution}
We have $\bbr'(s)=\frac{1}{\sqrt{2}}(-\sin(\frac{s}{\sqrt{2}}), \cos(\frac{s}{\sqrt{2}}),1)$ and therefore 
\begin{align*}
	||\bbr'(s)||&=\frac{1}{\sqrt{2}}\sqrt{\sin^2(\frac{s}{\sqrt{2}})+\cos^2(\frac{s}{\sqrt{2}})+1} \\
	&=\frac{1}{\sqrt{2}}\sqrt{2} \\
	&=1.
\end{align*}	
\end{solution}

}
\subsection{Curvature}
In this section, we will quantify how sharply a curve ``bends" at each point. This will lead us to define a function called the \emph{curvature function} for the curve.

\subsection{Curvature of a unit speed curve}
We begin by considering curves parametrized by arc length. To define the curvature function, we will need the following lemma.
\begin{lem}\label{lem:some_dot_products}
Let $\bu, \bv:I \to \R^n$ be a pair of curves.
\begin{enumerate}[(a)]
	\item If $\bu$ has constant nonzero length (that is, if $||\bu(t)||=c>0$ for all $t \in I$), then $\bu'(t)$ is orthogonal to $\bu(t)$ for all $t \in I$.
	\item If $\bu(t)$ is orthogonal to $\bv(t)$ for all $t \in I$, then
	\begin{align*}
		\bu'(t) \cdot \bv(t)=-\bu(t) \cdot \bv'(t)=0
	\end{align*}
	for all $t \in I$.
\end{enumerate}	
\end{lem}

\begin{proof}
	\begin{enumerate}[(1)]
		\item Suppose $||\bu(t)||=c$ for all $t$. Differentiating both sides, gives $||\bu(t)||'=0$. That is,
		\begin{align*}
			0&=||\bu(t)||' \\
			&=\sqrt{\bu(t) \cdot \bu(t)}' \\
			&=\frac{2\bu'(t) \cdot \bu(t)}{2\sqrt{\bu(t) \cdot \bu(t)}} \\
			&=\frac{\bu'(t) \cdot \bu(t)}{||\bu(t)||} \\
			&=\frac{\bu'(t) \cdot \bu(t)}{c} \\
		\end{align*}
		and therefore $\bu'(t) \cdot \bu(t)=0$ for all $t$.
		\item Suppose $\bu(t) \cdot \bv(t)=0$ for all $t$. Differentiating both sides, we obtain
		\begin{align*}
			0&=\bu'(t) \cdot \bv(t)+\bu(t)+\bv'(t)
		\end{align*}
		and therefore
		\begin{align*}
			\bu'(t) \cdot \bv(t)=-\bu(t)+\bv'(t)
		\end{align*}
		for all $t$.
	\end{enumerate}
\end{proof}

Note that both of these hypotheses of Lemma \ref{lem:some_dot_products} are true for an orthonormal set of vectors $\{\bu,\bv\}$.

Let $\bbr:I \to \R^n$ be a curve parametrized by arc length. Since $\bbr'(s)$ has unit length, by part (a) of Lemma \ref{lem:some_dot_products}, $\bbr''(s)$ is orthogonal to $\bbr'(s)$. Thus, $||\bbr''(s)||$ measures the rate at which the curve is pulling away from the tangent line at $\bbr(s)$.

\begin{defn}[Curvature]\label{def:curvature}
	Let $\bbr:I \to \R^n$ be a curve parametrized by arc length $s \in I$. Define the \emph{curvature function} $\kappa:I \to [0,\infty)$ by $\kappa(s)=||\bbr''(s)||$. The number $\kappa(s)$ is called the \emph{curvature} of the curve $\bbr$ at $s$.
	\end{defn}

\begin{example}\label{ex:line_circle}
\begin{enumerate}[(a)]
	\item If $\bbr$ is a straight line, then $\bbr(s)=\bbr'(s_0)s+\bbr(s_0)$, where $\bbr(s_0), \bbr'(s_0)$ are constant vectors and we have $\kappa(s)=\bbr''(s)\equiv 0$. Conversely, if $\kappa=||\bbr''(s)||\equiv 0$, then integrating twice gives $\bbr(s)=\bbr'(s_0)s+\bbr(s_0)$, so the curve is a straight line.

\item If $\bbr(s)=(R\cos(\frac{s}{R}),R\sin(\frac{s}{R}))$ is a circle of radius $R$, then
\begin{align*}
	\bbr''(s)=(-\frac{1}{R}\cos(\frac{s}{R}),-\frac{1}{R}\sin(\frac{s}{R}))
\end{align*}
and therefore
\begin{align*}
	\kappa(s)=||\bbr''(s)||=\frac{1}{R}.
\end{align*}
\end{enumerate}	
\end{example}

\begin{defn}[Unit normal vector]
At points where $\kappa(s) \neq 0$, the vector
\begin{align*}
	\mathbf{\hat{n}}(s)=\frac{\bbr''(s)}{||\bbr''(s)||}
\end{align*}
is a unit vector orthogonal to $\bbr'(s)$. This is called the \emph{unit normal vector} to $\bbr$ at $s$.	
\end{defn}

\subsection{Osculating Plane}
Let $\bbr(s)$ be a unit-speed curve. Consider a point $s_0$ where $\kappa(s_0) \neq 0$. Then, for sufficiently small $h=s-s_0$, we can approximate $\bbr(s)$ by its second-order Taylor polynomial:
\begin{align*}
	\bbr(s_0+h)&=\bbr(s_0)+h\bbr'(s_0)+\frac{h^2}{2}\bbr''(s_0)+\mathbf{E}(h),  \\
	\bbr(s_0+h)&=\bbr(s_0)+h\mathbf{\hat{t}}+\frac{h^2}{2}\kappa(s_0)\un(s_0)+\mathbf{E}(h),  \\
\end{align*}
where $\lim_{h \to 0}\frac{||\mathbf{E}(h)||}{h^2}=0$. Thus, sufficiently near $\bbr(s_0)$, the trace of a curve lies in the plane spanned by $\{\ut(s_0),\un(s_0)\}$, called the \emph{osculating plane at $\bbr(s_0)$}. With respect to the coordinate $\bbr(s_0+h)-\bbr(s_0)$ centered at $\bbr(s_0)$, the trace of the curve in the osculating plane is given by 
\begin{align*}
	\{(h,\frac{\kappa(s_0)}{2}h^2):-\epsilon < h < \epsilon\} \subseteq \R^2,
\end{align*}
which is a parabola $y=\frac{\kappa(s_0)}{2}x^2$ whose vertex is at the origin and whose concavity is $y''=\kappa(s_0)$.

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.5]{figures_mvc/parab_curvature}
	\end{center}
	\caption{The trace of $\bbr$ is approximated near $\bbr(s_0)$ by the parabola with concavity $\kappa(s_0)$ in the osculating plane.}
\end{figure}

The trace of the curve is also well approximated by a certain circle in the osculated plane. 

\begin{defn}[Osculating circle]
	The \emph{osculating circle} to is the circle of radius $\kappa(s_0)$ in the osculating plane centered at $\bbr(s_0)+\frac{1}{\kappa(s_0)}\un$.
\end{defn}

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.5]{figures_mvc/osc_circl}
	\end{center}
	\caption{The osculating circle for a plane curve (left) and a space curve (right).}
\end{figure}
Thus, we may also interpret the curvature as the radius of the osculating circle. \fixme{Add Exercise 1.42?}

At points where $\kappa(s)=0$, the normal vector (and therefore the osculating plane) is not defined. To proceed with our analysis, we will need the osculating plane, so from now on we will only consider curves for which $\kappa(s) \neq 0$ for all $s \in I$.

\subsection{Arbitrary parametrizations}
As noted previously, in practice it is often too difficult to parametrize a curve by arc length, and we are forced to work with other parametrizations.

Let $\bbr:I \to \R^n$ be a curve with an arbitrary parametrization $t \in I$. One might guess that the curvature. Since the speed $||\bbr'(t)||$ is no longer constant, the acceleration vector $\bbr''(t)$ will have a nonzero component in the direction of the velocity vector $\bbr'(t)$. We might therefore be tempted to define the curvature function $\kappa(t)$ as the magnitude of the component of the acceleration perpendicular to $\bbr'(t)$; that is, to define $\kappa(t):=||\bbr_\perp''(t)||$, where
\begin{align*}
	\bbr''_\perp(t)&=\bbr''(t)-\text{proj}_{\bbr'(t)}\bbr''(t) \\
	&=\bbr''(t)-\frac{\bbr''(t)\cdot \bbr'(t)}{\bbr'(t)\cdot \bbr'(t)}\bbr'(t). 
\end{align*}
 However, this definition is problematic, as the next example shows.

\begin{example}\label{ex:curvature_arb_bad_def}
Consider the parabola which is the graph of $y=x^2$. Describe the parabola as a parametrized curve in the following two  parametrizations,	
\begin{align*}
	\bbr_1(t)&=(t,t^2), \hspace{2.5cm} t \in \R, \\
	\bbr_2(t)&=(2t-2,(2t-2)^2), \hspace{0.5cm} t \in \R.
\end{align*}
In the first parametrization, the origin is the point $\bbr(0)=(0,0)$. Since
\begin{align*}
	\bbr_1'(t)&=(1,2t), \\
	\bbr_1''(t)&=(0,2),
\end{align*}
\begin{align*}
	\bbr''_{1 \ \perp}(0)&=(0,2)-\frac{(0,2)\cdot (1,0)}{(1,0)\cdot (1,0)}(1,0) \\
	&=(0,2),
\end{align*}
and therefore $\kappa(0)=||\bbr''_{1 \ \perp}(0)||=2$.

In the second parametrization, the origin is $\bbr_2(1)=(0,0)$. Since
\begin{align*}
	\bbr_2'(t)&=(2,4(2t-2))=(2,8t-8) \\
	\bbr_2''(t)&=(0,8) \\
\end{align*}
we have
\begin{align*}
	\bbr_{2 \ \perp}''(1)&=(0,8)-\frac{(0,8)\cdot (2,0)}{(2,0) \cdot (2,0)}(2,0) \\
	&=(0,8)
\end{align*}
and therefore
\begin{align*}
	\kappa(1)=||\bbr_{2 \ \perp}''(1)||=8.
\end{align*}
Using our definition of $\kappa(t)$, we have just obtained \emph{different} values of the curvature at the origin of the parabola by using different parametrizations. The curvature should be a geometric property of the curve that does not depend on parametrization, so this definition turns out to be bad. 
\end{example}

To find a satisfactory definition of curvature, we need to study more carefully the dependence of the derivatives of $\bbr(t)$ on parametrization. Let $\bbr:I \to \R^n$ be a regular curve with an arbitrary paramtrization, and let $\tilde{\bbr}=\bbr \circ \varphi$ be a reparametrization of $\bbr$. Then, by the chain rule,
\begin{align*}
	\widetilde{\bbr}'(t)&=\bbr'(\varphi(t))\varphi'(t), \\
	\widetilde{\bbr}''(t)&=\bbr''(\varphi(t))(\varphi'(t))^2+\bbr'(\varphi(t))\varphi''(t), \\
\widetilde{\bbr}''_\perp(t)&=\bbr''_\perp(\varphi(t))(\varphi'(t))^2.
\end{align*}
From these expressions, we see that the quantity
\begin{align}\label{eq:curvature_arb_param}
	\frac{||\bbr''_\perp(t)||}{||\bbr'(t)||^2}
\end{align}
is invariant under reparametrizations. Moreover, when $t=s$ is the arc length, $||\bbr'(s)||=1$ and $\bbr''(s)=\bbr''_\perp(s)$, so the expression in \eqref{eq:curvature_arb_param} agrees with our definition of the curvature function of a unit speed curve in Definition \ref{def:curvature}.

Thus, we arrive at our definition of the curvature function in an arbitrary parametrization.
\begin{defn}[Curvature in an arbitrary parametrization]
	Let $\bbr:I \to \R^n$ be a regular curve with an arbitrary parametrization $t \in I$. We define the \emph{curvature function} $\kappa:I \to [0,\infty)$ for all $t \in I$ by
	\begin{align}\label{eq:curvature_function_defi}
		\kappa(t)=\frac{||\bbr''_\perp(t)||}{||\bbr'(t)||^2}.
	\end{align}
\end{defn}
Rewriting \eqref{eq:curvature_function_defi} as 
\begin{align*}
	||\bbr_\perp''(t)||=\kappa(t)||\bbr'(t)||^2,
\end{align*}
this expression says, in physical terms, that the magnitude of the centripetal acceleration at $t$ depends not only on the curvature, but also on the speed at $t$. This explains the results of Example \ref{ex:curvature_arb_bad_def}.

\begin{defn}[Unit tangent and Unit normal in an arbitrary parametrization]
	Let $\bbr:I \to \R^n$ be a regular curve with an arbitrary parametrization and let $t \in I$ be a point where $\kappa(t) \neq 0$. We define the \emph{unit tangent} and \emph{unit normal vectors} at $t$ to be 
	\begin{align*}
		\ut(t)=\frac{\bbr'(t)}{||\bbr'(t)||}, \hspace{0.5cm} \un(t)=\frac{\bbr''_\perp(t)}{||\bbr''_\perp(t)||}.
	\end{align*} 
\end{defn}

The next proposition shows that we can compute the unit normal vector in terms of the unit tangent vector.

\begin{prop}
Let $\bbr:I \to \R^n$ be a regular curve. For any point where $\kappa(t) \neq 0$, we have
\begin{align*}
	\un(t)=\frac{\ut'(t)}{||\ut'(t)||}.
\end{align*}
\end{prop}

\begin{proof}
	By the quotient rule,
	\begin{align*}
		\ut'(t)=\frac{||\bbr'(t)||\bbr''(t)-\bbr'(t)||\bbr'(t)||'}{||\bbr'(t)||^2}.
	\end{align*}
	Now
	\begin{align*}
		||\bbr'(t)||'&=\frac{d}{dt}(\bbr'(t) \cdot \bbr'(t))^{1/2} \\
		&=\frac{1}{2}(\bbr'(t) \cdot \bbr'(t))^{-1/2}(2\bbr''(t) \cdot \bbr'(t)) \\
		&=\frac{\bbr''(t) \cdot \bbr'(t)}{||\bbr'(t)||} \\
	\end{align*}
	so we have
	\begin{align*}
		\ut'(t)&=\frac{||\bbr'(t)||\bbr''(t)-\bbr'(t)||\bbr'(t)||'}{||\bbr'(t)||^2} \\
		&=\frac{\bbr''(t)}{||\bbr'(t)||}-\frac{\bbr''(t) \cdot \bbr'(t)}{||\bbr'(t)||^3}\bbr'(t) \\
		&=\frac{1}{||\bbr'(t)||}\left(\bbr''(t)-\frac{\bbr''(t) \cdot \bbr'(t)}{||\bbr'(t)||^2}\bbr'(t)\right) \\
		&=\frac{\bbr''_\perp(t)}{||\bbr'(t)||}.
	\end{align*}
	and therefore
	\begin{align*}
		\frac{\ut'(t)}{||\ut'(t)||}&=\frac{\frac{\bbr''_\perp(t)}{||\bbr'(t)||}}{\frac{||\bbr''_\perp(t)||}{||\bbr'(t)||}} \\
		&=\frac{\bbr''_\perp(t)}{||\bbr''_\perp(t)||} \\
		&\equiv \un(t).
	\end{align*}
\end{proof}

\subsection{Plane curves}
Our results so far about curves in $\R^n$ have been valid for all $n$. In this section, we consider the special case $n=2$. This is the only dimension in which the terms ``clockwise" and ``counterclockwise" make sense for describing how a regular curve is turning.

\begin{prop}
The map $R: \R^2 \to \R^2$ defined by $R(x,y)=(-y,x)$ is an isomorphism.
\end{prop}

\begin{proof}
	The map $R$ is the same as multiplication by the matrix 
	\begin{align*}
		\begin{bmatrix}
			0 & -1 \\
			1 & 0
		\end{bmatrix},
	\end{align*}
	which is linear. The kernel of this map is $\{(0,0)\}$, so $R$ is injective. Given any $(x,y) \in \R^2$, we see that $(x,y)=R(y,-x)$, hence $R$ is also surjective. Thus, $R$ is an isomorphism. 
\end{proof}
Geometrically, $R$ rotates each vector $(x,y) \in \R^2$ counterclockwise by $90^\circ$. One can immediately check that $R^2(\bv)\equiv R(R(\bv))=-\bv$ for all $\bv \in \R^2$.

Suppose now that $\bbr:I \to \R^2$ is a unit-speed curve. Then, for all $s \in I$, by Lemma \ref{lem:some_dot_products} $\bbr''(t)$ and $R(\bbr'(t))$ are both orthogonal to $\bbr'(t)$, so they must be parallel. We can therefore write
\begin{align}\label{eq:acc_signed_curvature}
	\bbr''(t)=\kappa_s(t) R(\bbr'(t))
\end{align}
for some scalar $\kappa_s(t) \in \R$. We call $\kappa_s:I \to \R$ the \emph{signed curvature function}. It is negative if the curve is turning clockwise at $t$, and positive if it is turning counterclockwise, as shown below:
\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.5]{figures_mvc/signed_curvature_fcn}
	\end{center}
	\caption{Signed curvature is positive when the path is turning counterclockwise, and negative when turning clockwise.}
\end{figure}
This measurement is called ``signed curvature" because its sign is interpreted as above, while its absolute value equals the curvature:

\begin{prop}
Let $\bbr:I \to \R^2$ be a regular unit-speed plane curve. Then $|\kappa_s(t)|=\kappa(t)$.	
\end{prop}

\begin{proof}
	Since $||R(\bbr'(t))||=||\bbr'(t)||=1$,
	\begin{align*}
		\kappa(t)=||\bbr''(t)||=||\kappa_s(t)R(\bbr'(t))||=|\kappa_s(t)| \ ||R(\bbr'(t))||=|\kappa_s(t)|.
	\end{align*}
\end{proof}

Taking the dot product of \eqref{eq:acc_signed_curvature} with $R(\bbr'(t))$, we obtain
\begin{align*}
	\bbr''(t) \cdot R(\bbr'(t))&=\kappa_s(t) R(\bbr'(t)) \cdot R(\bbr'(t))\\
	&=\kappa_s(t) \bbr'(t) \cdot \bbr'(t) \\
	&=\kappa_s(t) ||\bbr'(t)||^2 \\
	&=\kappa_s(t),
\end{align*}
so we can write $\kappa_s(t)$ as 
\begin{align}
	\kappa_s(t)&=\bbr''(t) \cdot R(\bbr'(t)).
\end{align}

\begin{defn}
Let $\bbr:I \to \R^2$ be a regular plane curve with an arbitrary parametrization. Then we define, for all $t \in I$,
\begin{align}\label{eq:signed_curvature_arb}
	\kappa_s(t)=\frac{\bbr''(t) \cdot R(\frac{\bbr'(t)}{||\bbr'(t)||})}{||\bbr'(t)||^2}=\frac{\bbr''(t) \cdot R(\bbr'(t))}{||\bbr'(t)||^3}.
\end{align}	
\end{defn}
Note that this definition of $\kappa_s(t)$ agrees with our previous definition when $t=s$ is the arc length. This could also be verified by comparing the definition $\kappa(t)=\frac{||\bbr''_\perp(t)||}{||\bbr'(t)||^2}$ to the above formula for $\kappa_s(t)$, noticing that
\begin{align*}
	\bbr''(t) \cdot R(\frac{\bbr'(t)}{||\bbr'(t)||})=\pm ||\bbr''_\perp(t)||.
\end{align*}

\begin{prop}\label{prop:signed_curvature_inv}
The formula in \eqref{eq:signed_curvature_arb} is invariant under orientation-preserving reparametrizations.	
\end{prop}

\begin{proof}
	Let $\widetilde{\bbr}=\bbr \circ \varphi$ be an orientation-preserving reparametrization of $\bbr$ (i.e., $\varphi'(t)>0$ for all $t \in I$). Then
	\begin{align*}
		\widetilde{\bbr}'(t)&=\bbr'(\varphi(t))\varphi'(t), \\
		R(\widetilde{\bbr}(t))&=\varphi'(t)R(\bbr'(\varphi(t))), \\
		\widetilde{\bbr}''(t)&=\bbr''(\varphi(t))(\varphi'(t))^2+\bbr'(\varphi(t))\varphi''(t)
	\end{align*}
	and
	\begin{align*}
		\frac{R(\widetilde{\bbr}'(t))\cdot \widetilde{\bbr}''(t) }{||\widetilde{\bbr}'(t)||^3}&=\frac{\varphi'(t)R(\widetilde{\bbr}'(t)) \cdot \widetilde{\bbr}''(t)(\varphi'(t))^2+\varphi'(t)R(\widetilde{\bbr}'(t)) \cdot \bbr'(\varphi(t))\varphi''(t)}{(\varphi'(t))^3||\widetilde{\bbr}'(t)||^3} \\
		&=\frac{\varphi'(t)R(\widetilde{\bbr}'(t)) \cdot \widetilde{\bbr}''(t)(\varphi'(t))^2+0}{(\varphi'(t))^3||\widetilde{\bbr}'(t)||^3} \\
		&=\frac{\varphi'(t)R(\widetilde{\bbr}'(t)) \cdot \widetilde{\bbr}''(t)(\varphi'(t))^2}{(\varphi'(t))^3||\widetilde{\bbr}'(t)||^3} \\
		&=\frac{(\varphi'(t))^3R(\widetilde{\bbr}'(t)) \cdot \widetilde{\bbr}''(t)}{(\varphi'(t))^3||\widetilde{\bbr}'(t)||^3} \\
		&=\frac{R(\widetilde{\bbr}'(t)) \cdot \widetilde{\bbr}''(t)}{||\widetilde{\bbr}'(t)||^3}. 
	\end{align*}
	\fixme{Where did we use $\varphi'(t)>0$?}
\end{proof}

It follows from Proposition \ref{prop:signed_curvature_inv} that $|\kappa_s(t)|=\kappa(t)$ even for non-unit-speed curves.

\begin{prop}
	Let $\bbr(t)=(x(t),y(t))$ be a regular plane curve. Then the signed curvature function is given by
	\begin{align*}
		\kappa_s(t)=\frac{x'(t)y''(t)-x''(t)y'(t)}{(x'(t)^2+y'(t)^2)^\frac{3}{2}}.
	\end{align*}
\end{prop}

\begin{proof}
	\fixme{Finish...}
\end{proof}

\begin{example}
Consider the plane curve $\bbr(t)=(t,\ln(\cos t))$, $-\frac{\pi}{2}<t<\frac{\pi}{2}$.
Then
\begin{align*}
	\bbr'(t)&=(1,-\tan t), \\
	\bbr''(t)&=(0,-\sec^2 t). \\
\end{align*}	
The unit tangent vector is
\begin{align*}
	\ut(t)&=\frac{\bbr'(t)}{||\bbr'(t)||} \\
	&=\frac{1}{\sec t}(1,-\tan t) \\
	&=(\cos t, -\sin t).
\end{align*}
The unit normal vector is then
\begin{align*}
	\un(t)&=\frac{\ut'(t)}{||\ut'(t)||} \\
	&=(-\sin t,\cos t).
\end{align*}
The signed curvature function is
\begin{align*}
	\kappa_s(t)&=\frac{1\cdot (-\sec ^2 t)-0}{1+\tan^2t} \\
	&=\frac{-\sec ^2 t}{\sec t} \\
	&=-\sec t
\end{align*}
and the curvature function is then
\begin{align*}
	\kappa(t)=|\kappa_s(t)|=|\sec t|=\sec t
\end{align*}
since $\sec t>0$ for all $-\frac{\pi}{2}<t<\frac{\pi}{2}$.
\end{example}

\subsection{Local-global connection}
Recall the following theorem about triangles:

\begin{thm}[Angle-Sum Theorem]
	The sum of the interior angles of a triangle is $180^\circ$.
\end{thm}

This theorem shows how local data (the angle measures) influences the global shape by giving the condition for the three angles to fit together to form a triangle. In this section, we will prove a theorem for plane curves of a similar flavor.

\begin{defn}[Simple closed curve]
	A \emph{closed curve} is a regular curve of the form $\bbr:[a,b] \to \R^n$ such that $\bbr(a)=\bbr(b)$ and all derivatives match:
	\begin{align*}
		\bbr'(a)=\bbr'(b), \hspace{0.5cm} \bbr''(a)=\bbr''(b), \text{ etc.} 
	\end{align*}
	If additionally $\bbr$ is 1-1 on the domain $[a,b)$, then it is called a \emph{simple closed curve}. (See the Figure below.)
\end{defn}

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.5]{figures_mvc/simple_closed_curve}
	\end{center}
	\caption{A simple closed curve closes up smoothly and does not have any self-intersections.}
\end{figure}

\begin{example}
The circle $\bbr(t)=(\cos t, \sin t), t \in [0,2\pi]$ is a simple closed curve.	
\end{example}

In this section we will prove the following theorem:

\begin{thm}[Total Curvature Theorem]
	If $\bbr:[a,b] \to \R^2$ is a unit speed simple closed curve. Then
	\begin{align*}
		\int_a^b\kappa_s(t)dt=\pm 2\pi.
	\end{align*}
	\fixme{Explain the sign.}
\end{thm}

\begin{prop}\label{prop:global_angle_function}
	Let $\bbr:I \to \R^2$ be a unit-speed plane curve. Then there exists a smooth \emph{angle function}, $\theta:I \to \R$, such that for all $t \in I$, we have
	\begin{align}\label{eq:angle_function_for_plane_curve}
		\bv(t)=(\cos\theta(t),\sin\theta(t)).
	\end{align}
	This function is unique up to adding an integer multiple of $2 \pi$.
\end{prop}

\begin{proof} \hspace{15cm}
	\begin{enumerate}
		\item First, note that for each $t_0 \in I$, there exists a neighborhood $U \subseteq I$ containing $t_0$ and a smooth \emph{local} angle function $\theta:U \to \R$ such that 
		\begin{align*}
			\bv(t)=(\cos \theta(t),\sin \theta(t)).
		\end{align*}
		To see this, write $\bv$ in terms of its components as $\bv(t)=(v_x(t),v_y(t))$. Since the curve is regular, $\bv(t) \neq 0$ for all $t \in I$. It follows that, for all $t \in I$, at least one of the component functions is non-zero. Since the component functions $v_i$ ($i=x,y$) are continuous, if $v_i(t_0) \neq 0$, then $v_i(t)$ must be non-zero throughout a neighborhood containing $t_0$. \footnote{Proof: Let $f:\R \to \R$ be continuous and non-zero at some point $x_0$. Let $\epsilon=\frac{|f(x_0)|}{2}$. Then $\epsilon>0$ so by continuity at $x_0$ there exists $\delta>0$ such that $|f(x)-f(x_0)|<\frac{|f(x_0)|}{2}$ whenever $|x-x_0|<\delta$. If there is a point $x$ in the neighborhood $|x-x_0|<\delta$ for which $f(x)=0$, then we have $|0-f(x_0)|=|f(x_0)|<\frac{|f(x_0)|}{2}$, which is a contradiction. Thus, $f(x)$ must be nonzero throughout a neighborhood of $x_0$.} Thus, each $t_0 \in I$ has a neighborhood where at least one of the component functions is non-zero. Explicitly, the following local angle functions are well-defined on each type of interval: \fixme{Add explanation of how to get (or at least verify) these. Maybe add a figure?}
		\begin{itemize}
			\item If $v_x>0$ on $U$, for each $t \in U$ define $\theta:U \to \R$ by \footnote{Since $||\bv(t)||=1$ for all $t \in I$, $\bv(t)$ lies on the unit circle. If $v_x>0$, then we must have $-\frac{\pi}{2}<\theta<\frac{\pi}{2}$ up to an integer multiple of $2\pi$. Basic trigonometry then gives the stated formula for $\theta$. The rest of the stated functions are obtained similarly. The actual neighborhood $U$ on which each local angle function is defined will depend on the functions $v_x(t)$ and $v_y(t)$.}
			\begin{align*}
				\theta(t)&=\tan^{-1}(\frac{v_y}{v_x})
			\end{align*}
			\item If $v_y>0$ on $U$, for each $t \in U$ define $\theta:U \to \R$ by
			\begin{align*}
				\theta(t)&=\cos^{-1}(v_x)
			\end{align*}
			\item If $v_x<0$ on $U$, for each $t \in U$ define $\theta:U \to \R$ by
			\begin{align*}
				\theta(t)&=\pi-\tan^{-1}(\frac{v_y}{v_x})
			\end{align*}
			\item If $v_y<0$ on $U$, for each $t \in U$ define $\theta:U \to \R$ by
			\begin{align*}
				\theta(t)&=2\pi-\cos^{-1}(v_x)
			\end{align*}
		\end{itemize}
These are, of course, far from unique. While this shows each point has a neighborhood on which we can define a local angle function, to prove the theorem we need to define a \emph{global angle function}, which is defined on \emph{all} of $I$.
\item To construct such a function, we will need the following result. Let $\theta$ be a local angle function defined on a neighborhood $U$ of a point $t_0$. Then for all $t \in U$, we have
\begin{align*}
	\bv(t)&=(\cos \theta(t),\sin \theta(t)) \\
	\ba(t)&=\theta'(t)(-\sin \theta(t),\cos \theta(t)) \\
	R(\bv(t))&=(-\sin \theta(t),\cos \theta(t))
\end{align*}					
and therefore
\begin{align*}
	\kappa_s(t)&\equiv R(\bv(t)) \cdot \ba(t)=\theta'(t)(\sin^2 \theta(t)+\cos^2\theta(t))=\theta'(t)
\end{align*}
for all $t \in U$. Suppose we have another function $\psi(t)$ defined on $U$ such that 
\begin{enumerate}
	\item $(\cos \psi(t_0), \sin \psi(t_0))=(\cos \theta(t_0), \sin \theta(t_0))=\bv(t_0)$, and 
	\item $\psi'(t)=\kappa_s(t)$ for all $t \in U$.
\end{enumerate}
Then by (b) we have for all $t \in U$
\begin{align*}
	\psi'(t)-\theta'(t)=(\psi(t)-\theta(t))'=0
\end{align*}
and therefore $\psi(t)=\theta(t)+c$, where $c$ is a constant. It then follows from (a) that $c=2\pi n$ for some $n \in \Z$. Thus, $\psi(t)=\theta(t)+2\pi n$ $(n \in \Z)$ for all $t \in U$.
\item We now construct a global angle function. Let $t_0 \in I$. Choose a neighborhood $V$ of $t_0$ such that a local angle function $\theta(t)$ is defined on $V$, and let $\theta_0=\theta(t_0)$. Define $\Theta:I \to \R$ for all $t \in I$ by
\begin{align*}
	\Theta(t)=\int_{t_0}^t\kappa_s(u)du+\theta_0.
\end{align*}
By the Fundamental Theorem of Calculus, $\Theta'(t)=\kappa_s(t)$ for all $t \in I$. Let 
\begin{align*}
	\hat{I}=\{t \in I: \bv(t)=(\cos \Theta(t),\sin \Theta(t))\}.
\end{align*}
In particular, $t_0 \in \hat{I}$ since $\Theta(t_0)=\theta_0$, and $\bv(t_0)=(\cos \theta_0,\sin\theta_0)$, so $\hat{I} \neq \emptyset$. Suppose then that $t_1$ is any element of $\hat{I}$. Then $\bv(t_1)=(\cos \Theta(t_1),\sin\Theta(t_1))$. By the previous discussion, there exists a neighborhood $U$ of $t_1$ and a local angle function $\theta$ defined on $U$ such that $\bv(t)=(\cos \theta(t),\sin\theta(t))$ for all $t \in U$. Since $\Theta'(t)=\theta'(t)$ for all $t \in U$, and $(\cos \Theta(t_1),\sin \Theta(t_1))=(\cos \theta(t_1),\sin \theta(t_1))=\bv(t_1)$, by the previous discussion $\Theta(t)=\theta(t)+2\pi n$ on $U$, so $(\cos \Theta(t),\sin\Theta(t))=(\cos(\theta(t)+2\pi n),\sin(\theta(t)+2\pi n)=(\cos \theta(t),\sin\theta(t))=\bv(t)$ for all $t \in U$. This shows that each $t \in \hat{I}$ has a neighborhood $U$ contained in $\hat{I}$, and therefore $\hat{I}$ is open in $I$. 

Now suppose $t_1 \in I-\hat{I}$. Then $\bv(t_1) \neq (\cos \Theta(t_1),\sin \Theta(t_1))$. It follows that there is a neighborhood $U_1$ of $t_1$ on which $\bv(t) \neq (\cos \Theta(t),\sin \Theta(t))$ for all $t \in U_1$. To see this, suppose otherwise. Then, given any neighborhood $U$ of $t_1$, there exists $t_2 \in U-\{t_1\}$ such that $\bv(t_2)=(\cos \Theta(t_2),\sin \Theta(t_2))$. Let $U$ be a neighborhood of $t_1$ on which the local angle function $\theta(t)$ is defined. By the same argument as above, we then have $\bv(t)=(\cos \theta(t),\sin \theta(t))=(\cos \Theta(t),\sin \Theta(t))$,  for all $t \in U$, contradicting the fact that $\bv(t_1) \neq (\cos \Theta(t_1),\sin \Theta(t_1))$. This shows that every point of $I-\hat{I}$ has a neighborhood contained in $I-\hat{I}$, so $I-\hat{I}$ is open in $I$ and therefore $\hat{I}$ is closed on $I$. Since $I$ is an interval in $\R$, $I$ is connected and therefore has no nonempty subset that is both open and closed. We conclude that $\hat{I}=I$, proving that $\Theta$ is a global angle function on $I$. \fixme{Need an appendix on basic topological ideas used in the text.}

If $\psi$ is another global angle function, then $\bv(t)=(\cos \Theta(t),\sin \Theta(t))=(\cos \psi(t), \sin \psi(t))$ for all $t \in I$, and therefore $\psi(t)=\Theta(t)+2\pi n$, $n \in \Z$ for all $t \in I$, which shows that $\Theta$ is unique up to adding an integer multiple of $2\pi$.
\end{enumerate}
\end{proof}

\begin{defn}[Rotation index]
	The \emph{rotation index} of a unit-speed closed plane curve $\bbr:[a,b] \to \R^2$  is the integer
	\begin{align*}
		\text{Ind}(\bbr)=\frac{1}{2\pi}(\Theta(b)-\Theta(a))
	\end{align*}
	where $\Theta$ is the global angle function of Proposition \ref{prop:global_angle_function}.
\end{defn}

\begin{exercise}
Let $\bbr:[a,b] \to \R^2$ be a regular (not necessarily unit-speed) closed plane curve.
\begin{enumerate}[(1)]
	\item Prove there exists a smooth function $\Theta:[a,b] \to \R$ such that for all $t \in [a,b]$, the unit tangent vector satisfies
	\begin{align*}
		\ut(t)=(\cos \Theta(t), \sin \Theta(t))
	\end{align*}
	and that the rotation index of $\bbr$ equals $\frac{1}{2\pi}(\Theta(b)-\Theta(a))$.
	\item Prove that the rotation index of $\bbr$ equals 
	\begin{align*}
		\text{Ind}(\bbr)=\frac{1}{2\pi}\int_a^b\kappa_s(t)||\bbr'(t)||dt.
	\end{align*}
\end{enumerate}	
\emph{Hint: For both parts, verify that the formula is valid for unit-speed curves and is unchanged by orientation-preserving reparametrizations.}
\end{exercise}

\begin{example}
	
\end{example}


\subsection{Space Curves}
In this section, we will consider regular curves $\bbr:I \to \R^3$ where $\kappa(t) \neq 0$ for all $t \in I$. In the previous section, we found that the unit tangent vector, unit normal vector, and curvature function are given by
	\begin{align*}
		\ut(t)&=\frac{\bbr'(t)}{||\bbr'(t)||}, \hspace{0.5cm} \un(t)=\frac{\ut'(t)}{||\ut'(t)||}, \\
		\kappa(t)&=\frac{||\bbr''_\perp(t)||}{||\bbr'(t)||^2}.
	\end{align*} 

In $\R^3$, we can use the cross-product to simplify the computation of the curvature function.

\begin{prop}
	Let $\bbr:I \to \R^3$ be a regular space curve. Then for all $t \in I$,
	\begin{align*}
		\kappa(t)=\frac{||\bbr'(t) \times \bbr''(t)||}{||\bbr'(t)||^3}.
	\end{align*}
\end{prop}

\begin{proof}
	Since $||\bbr''_{\perp}(t)||=||\bbr''(t)||\sin \theta$ (where $\theta$ is the angle between $\bbr'(t)$ and $\bbr''(t)$), we have
	\begin{align*}
		\kappa(t)=\frac{||\bbr''_{\perp}(t)||}{||\bbr'(t)||^2}=\frac{||\bbr''(t)||\sin \theta}{||\bbr'(t)||^2}=\frac{||\bbr'(t)|| \ ||\bbr''(t)||}{||\bbr'(t)||^3}=\frac{||\bbr'(t) \times \bbr''(t)||}{||\bbr'(t)||^3}.
	\end{align*}
\end{proof}
 
\begin{example}\label{ex:twisted_cubic}
The space curve $\bbr(t)=(t,t^2,t^3)$, $t \in \R$ is called the \emph{twisted cubic}.
\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.5]{figures_mvc/twisted_cubic}
	\end{center}
\end{figure}
The unit tangent and unit normal vectors are rather tedious to compute by hand. These can easily be computed in \emph{Mathematica} as follows:

\begin{figure}[h]
	\includegraphics[scale=0.5]{figures_mvc/tc_tangent_normal}
\end{figure}	

One can easily verify that these vectors form an orthonormal set:
\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.5]{figures_mvc/tc_orthonormal_set}
	\end{center}
\end{figure}
The curvature function is then given by
\begin{align*}
	\kappa(t)&=\frac{1}{(1+4t^2+9t^4)^{3/2}}||\begin{vmatrix}
		\ii & \jj & \kk \\
		1 & 2t & 3t^2 \\
		0 & 2 & 6t
	\end{vmatrix} || \\
	&=\frac{2||(1,-3t,3t^2)||}{(1+4t^2+9t^4)^{3/2}} \\
	&=\frac{2\sqrt{1+9t^2+9t^4}}{(1+4t^2+9t^4)^{3/2}} \\
	&=2\sqrt{\frac{1+9t^2+9t^4}{(1+4t^2+9t^4)^3}},
\end{align*}
or using \emph{Mathematica}:
\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.5]{figures_mvc/tc_curvature_function}
	\end{center}
\end{figure}
\end{example}

We can also use the cross product to add one more vector to the set $\{\ut(t),\un(t)\}$. 
\begin{defn}[Unit binormal vector]
	The vector
	\begin{align*}
		\ub(t)=\ut(t) \times \un(t)
	\end{align*}
	is called the \emph{unit binormal vector}.
\end{defn}
 
\begin{prop}
The set $\{\ut(t),\un(t),\ub(t)\}$ is an orthonormal basis for $\R^3$.	
\begin{proof}
	We have already seen that $\{\ut(t),\un(t)\}$ is an orthonormal set. It follows immediately from the properties of the cross product \fixme{Reference this in my linear algebra notes.} that $\ub(t)$ is orthogonal to both $\ut(t)$ and $\un(t)$. Also
	\begin{align*}
		||\ub(t)||&=||\ut(t)|| \ ||\un(t)|| \ |\sin\left(\frac{\pi}{2}\right)|=1 \cdot 1 \cdot 1 = 1.
	\end{align*}
	Thus, $\{\ut(t),\un(t),\ub(t)\}$ is an orthonormal basis for $\R^3$.
\end{proof}
\end{prop}

\begin{defn}[Frenet frame]
A basis for $\R^n$ together with a choice of origin is called a \emph{frame}. The orthonormal frame $\{\ut(t),\un(t),\ub(t)\}$ for $\R^3$ (whose origin is understood to be $\bbr(t)$) is called the \emph{Frenet frame}.
\end{defn}

The curvature function of the curve $\bbr$ gave us a quantitative measure of to what extent the trace of the curve fails to be a straight line in a neighborhood of the point $\bbr(t)$. We now want a quantitative measure of the extent to which the curve fails to lie in the osculating plane in a neighborhood of $\bbr(t)$. Similar to the definition of curvature, a good candidate for such a function is $||\bb'(t)||$, which gives the rate at which the osculating plane is tilting at $\bbr(t)$. However, we will instead find it more useful to define a \emph{signed} measurement of the rate at which the osculating plane is tilting.

First, note that $\ub'(t)$ is parallel to $\un(t)$. To see this, note that note that since $\{\ut(t),\un(t),\ub(t)\}$ is an orthonormal basis, we can expand $\ub'$ in this basis as \fixme{Reference this in my linear algebra notes.}
\begin{align*}
	\ub'(t)=(\ub'(t)\cdot \ut(t))\ut(t)+(\ub'(t)\cdot \un(t))\un(t)+(\ub'(t)\cdot \ub(t))\ub(t).
\end{align*}
Since $||\ub(t)||=1$ for all $t \in I$, by part (a) of Lemma \ref{lem:some_dot_products} we have $\ub'(t) \cdot \ub(t)=0$. By part (b) of the same lemma we also have
\begin{align*}
	\ub'(t) \cdot \ut(t)=-\ub(t)\cdot \ut'(t)=-\ub(t)\cdot (||\bt'(t)||\un(t))=-||\bt'(t)||(\ub(t) \cdot \un(t))=0,
\end{align*}
since $\ub(t)$ and $\un(t)$ are orthogonal. Thus, $\ub'(t)=(\ub'(t)\cdot \un(t))\un(t)$.

\begin{defn}[Torsion for unit speed curve]\label{def:torsion_for_unit_speed_curve}
	Let $\bbr:I \to \mathbb{R}^3$ be a regular curve parametrized by arc length $s$, such that $\kappa(s) \neq 0$ for all $s \in I$. The \emph{torsion function} of $\bbr$ is defined by
	\begin{align*}
		\tau(s)=-\ub'(s) \cdot \un(s).
	\end{align*} 
\end{defn}
The minus sign in the definition above is conventional, and many textbooks define torsion without this sign. Before we move on to interpreting this formula, we need a formula valid for a regular curve with arbitrary parametrization.

\begin{prop}
	Let $\bbr:I \to \mathbb{R}^3$ be a regular space curve with an arbitrary parametrization. Then for every $t \in I$ with $\kappa(t) \neq 0$, the expression
	\begin{align}\label{eq:tau_proposed}
		\tau(t)=\frac{-\ub'(t) \cdot \un(t)}{||\bbr'(t)||}
	\end{align}
	is invariant under reparametrizations and agrees with the torsion function $\tau(s)$ of Definition \ref{def:torsion_for_unit_speed_curve}.
\end{prop}

\begin{proof}
	If the curve is parametrized by arc length, then $||\bbr'(t)||=1$ for all $t$ and thus the formula becomes that of Definition \ref{def:torsion_for_unit_speed_curve}.
	
	To see that this formula is independent of parametrization, let us first consider the transformation of the vectors in the Frenet frame change under a reparametrization:
	\begin{align*}
		\widetilde{\ut}(t)&=\frac{\widetilde{\bbr'}(t)}{||\widetilde{\bbr'}(t)||}=\frac{\varphi'(t)\bbr'(\varphi(t))}{||\varphi'(t)\bbr'(\varphi(t))||}=\frac{\varphi'(t)\bbr'(\varphi(t))}{|\varphi'(t)|\||\bbr'(\varphi(t))||}=\text{sgn}(\varphi'(t))\ut(\varphi(t)) \\
		\widetilde{\un}(t)&=\frac{\widetilde{\bbr''}_\perp(t)}{||\widetilde{\bbr''}_\perp(t)||}=\frac{(\varphi'(t))^2\bbr''_\perp(\varphi(t))}{||(\varphi'(t))^2\bbr''_\perp(\varphi(t))||}=\frac{(\varphi'(t))^2\bbr''_\perp(\varphi(t))}{(\varphi'(t))^2||\bbr''_\perp(\varphi(t))||}=\un(\varphi(t)) \\
		\widetilde{\ub}(t)&=\widetilde{\ut}(t) \times \widetilde{\un}(t)=\text{sgn}(\varphi'(t))\ub(\varphi(t))
	\end{align*}
If $\varphi$ is an orientation-preserving reparametrization ($\varphi'(t)>0$), then $\widetilde{\ut}=\ut \circ \varphi$, $\widetilde{\un}=\un \circ \varphi$, $\widetilde{\ub}=\ub \circ \varphi$, and 
\begin{align*}
	\widetilde{\tau}(t)=-\frac{\widetilde{\ub}'(t)\cdot \widetilde{\un}(t)}{||\widetilde{\bbr'}(t)||}=\frac{-\varphi'(t)\ub(\varphi(t))\cdot \un(\varphi(t))}{||\varphi'(t)\bbr'(\varphi(t)||}=\frac{-\ub(\varphi(t))\cdot \un(\varphi(t))}{||\bbr'(\varphi(t)||}=\tau(\varphi(t)).
\end{align*}
If $\varphi$ is an orientation-reversion reparametrization ($\varphi'(t)<0$), then $\widetilde{\ut}=-\ut \circ \varphi$, $\widetilde{\un}=\un \circ \varphi$, $\widetilde{\ub}=-\ub \circ \varphi$, and 
\begin{align*}
	\widetilde{\tau}(t)=-\frac{\widetilde{\ub}'(t)\cdot \widetilde{\un}(t)}{||\widetilde{\bbr'}(t)||}=\frac{\varphi'(t)\ub(\varphi(t))\cdot \un(\varphi(t))}{-\varphi'(t)||\bbr'(\varphi(t)||}=\frac{-\ub(\varphi(t))\cdot \un(\varphi(t))}{||\bbr'(\varphi(t)||}=\tau(\varphi(t)).
\end{align*} 
so the sign changes in the formula cancel, yielding the same conclusion: $\widetilde{\tau}=\tau \circ \varphi$. Thus, the expression in \eqref{eq:tau_proposed} is invariant under reprametrizations. 
\end{proof}

\begin{defn}
	Let $\bbr:I \to \mathbb{R}^3$ be a regular space curve with an arbitrary parametrization. Then for every $t \in I$ with $\kappa(t) \neq 0$, we define the \emph{torsion function} of the curve by the expression
	\begin{align}\label{eq:tau_proposed}
		\tau(t)=\frac{-\ub'(t) \cdot \un(t)}{||\bbr'(t)||}.
	\end{align}	
\end{defn}

\begin{prop}
Let $\bbr:I \to \mathbb{R}^3$ be a regular space curve with $\kappa(t) \neq 0$ for all $t \in I$. Then the trace of $\bbr$ is constrained to a plane if and only if $\tau(t)=0$ for all $t \in I$.	
\end{prop}

\begin{proof}
	Let $\bw=(a,b,c)$ be a fixed vector in $\R^3$ to serve as the normal vector of our plane. First, suppose that the trace of $\bbr$ is constrained to the plane $$P=\{\bx \in \mathbb{R}^3:\bx \cdot \bw=d\}.$$
	 Since the trace of $\bbr$ lies in the plane $P$, $\bbr(t)\cdot \bw=d$ is a constant function of $t$, so its derivatives vanish:
	\begin{align*}
		0&=(\bbr(t)\cdot \bw)'=\bbr'(t)\cdot \bw \\
		0&=(\bbr(t)\cdot \bw)''=\bbr''(t)\cdot \bw.
	\end{align*}
	From this it follows that $\ut(t)$ and $\un(t)$ are both orthogonal to $\bw$, so their cross product must be parallel to $\bw$: $\ub(t)=\pm\frac{\bw}{||\bw||}$. Since $\ub(t)$ is a continuous function of $t$, this sign cannot change abruptly, so it must be constant on $I$. Thus, $\ub$ is constant, so $\tau(t)=0$ for all $t \in I$.
	
	Conversely, suppose that $\tau(t)=0$ for all $t \in I$. This implies that $\ub'(t)=0$ for all $t \in I$, so $\ub(t)=\bw$ (a constant vector) for all $t \in I$. Notice that
	\begin{align*}
		(\bw \cdot \bbr(t))'=\bw\cdot \bbr'(t)=||\bbr'(t)||(\ub(t) \cdot \ut(t))=0,
	\end{align*} 
	since $\ub(t)$ and $\ut(t)$ are orthogonal. This $\bw \cdot \bbr(t)=d$ is a constant function. In other words, the trace of $\bbr$ lies in the plane 
	\begin{align*}
		P=\{\bx \in \mathbb{R}^3:\bx \cdot \bw=d\}.
	\end{align*}
\end{proof}

Thus, roughly, torsion measures the failure of the trace of the curve to remain in a single plane. To formulate this idea more precisely, we must first compute the derivatives of the vectors in the Frenet frame. In the following analysis, we will assume that $\bbr$ is parametrized by arc length.

\begin{prop}\label{prop:frenet_equations}
	Let $\bbr:I \to \mathbb{R}^3$ be a regular curve parametrized by arc length. At every time $s \in I$ with $\kappa(s) \neq 0$, the derivatives of the unit tangent, normal, and binormal vectors are given by the \emph{Frenet equations}:
	\begin{align*}
		\ut'(s)&= \kappa(s) \un(s) \\
		\un'(s)&=-\kappa(s)\ut(s)+\tau(s) \ub(s) \\
		\ub'(s)&=-\tau(s) \un(s).
	\end{align*}
\end{prop}

\begin{proof}
    The first and third of these follow immediately from the definitions of $\kappa$ and $\tau$, since
    \begin{align*}
    	\kappa(s)&=\ut'(s) \cdot \un(s) \\
    	\tau(s)&=-\ub'(s) \cdot \un(s).
    \end{align*}
    
 To show the second, expand $\un'(s)$ in the Frenet frame as 
    \begin{align*}
        \un'(s)&=\underbrace{(\un'(s) \cdot \ut(s))}_{=-\un(s) \cdot \ut'(s)=-\kappa(s)} \ut(s)+\underbrace{(\un'(s) \cdot \un(s))}_{= 0}\un(s)+\underbrace{(\un'(s) \cdot \ub(s))}_{-\un(s) \cdot \ub'(s)=\tau(s)}\ub(s) \\
        &=-\kappa(s)\ut(s)+\tau(s) \ub(s).
    \end{align*}
\end{proof}

We can now describe more precisely how torsion measures the failure of the trace of the curve to remain in a single plane. Assume now that $\bbr:I \to \mathbb{R}^3$ is a unit-speed curve, and that $s \in I$ with $\kappa(s) \neq 0$. We saw above that the trace of a second-order Taylor polynomial for $\bbr$ at $s$ is a parabola in the osculating plane. We will now show that if $\tau(s) \neq 0$, the third-order Taylor polynomial for $\bbr$ at $s$ leaves the osculating plane.

The third-order Taylor polynomial for the displacement vector ${\bf D}(h)\equiv \bbr(s+h)-\bbr(s)$ at $s \in I$ is given by
\begin{align*}
    {\bf D}(h)\equiv \bbr(s+h)-\bbr(s)=h\bbr'(s)+\frac{h^2}{2}\bbr''(s)+\frac{h^3}{6}\bbr'''(s)
\end{align*}
Using Proposition \ref{prop:frenet_equations},
\begin{align*}
    \bbr'(s)&=\ut(s) \\
    \bbr''(s)&=\kappa(s) \un(s) \\
    \bbr'''(s)&=(\kappa(s) \un(s))'=\kappa'(s)\un(s) + \kappa(s) \un'(s) \\
    &= \kappa'(s)\un(s) + \kappa(s)(-\kappa(s)\ut(s)+\tau(s) \ub(s)) \\
    &=\kappa'(s)\un(s)-(\kappa(s))^2\ut(s) +\kappa(s) \tau(s) \ub(s) 
\end{align*}
so the third-order Taylor polynomial of ${\bf D}(h)$ is
\begin{align*}
    {\bf D}(h)&=h\ut(s)+\kappa(s) \frac{h^2}{2}\un(s)+\frac{h^3}{6}(\kappa'(s)\un(s)-(\kappa(s))^2\ut(s) +\kappa(s) \tau(s) \ub(s)) \\
    &=(h-(\kappa(s))^2\frac{h^3}{6})\ut(s)+(\kappa(s)\frac{h^2}{2}+\kappa'(s)\frac{h^3}{6})\un(s)+\kappa(s)\tau(s)\frac{h^3}{6}\ub(s)
\end{align*}
If we choose a coordinate system centered at $\bbr(s)$ where $\ut(s)=(1,0,0),  \un(s)=(0,1,0),$ and $\ub(s)=(0,0,1)$, then  we have 
\begin{align*}
	[{\bf D}(h)]_B=(x(h),y(h),z(h))=\left(h-(\kappa(s))^2\frac{h^3}{6},\kappa(s)\frac{h^2}{2}+\kappa'(s)\frac{h^3}{6},\kappa(s)\tau(s)\frac{h^3}{6}\right).
\end{align*} 
This representation is called the \emph{local canonical form} of $\bbr$, in a neighborhood of $s$. Below, we plot the projections of the trace of $\bbr$, for small $h$, in the $tn$, $tb$, and $nb$ planes. The $tn$ plane is the osculating plane, while the $tb$ and $nb$ planes are called the \emph{rectifying plane} and \emph{normal plane}, respectively.

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.25]{figures_mvc/local_canonical_form}
	\end{center}
	\caption{Trace of a regular space curve in the neighborhood of a point with non-zero curvature and torsion.}
\end{figure}

\begin{figure}[h]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.8\linewidth]{figures_mvc/tn_projection}
  \caption{Projection onto the osculating plane.}
  \label{fig:sub1}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.8\linewidth]{figures_mvc/tb_projection}
  \caption{Projection onto the rectifying plane.}
  \label{fig:sub2}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.8\linewidth]{figures_mvc/bn_projection}
  \caption{Projection onto the normal plane.}
  \label{fig:sub3}
\end{subfigure}
\caption{Projections of a regular space curve in the neighborhood of a point with non-zero curvature and torsion onto the osculating, rectifying, and normal planes.}
\label{fig:test}
\end{figure}

Since $\kappa(s)>0$, the Taylor polynomial for $z(h)$ implies that if $\tau(s)>0$, then $z(h)>0$ for sufficiently small positive $h$. On the other hand, if $\tau(s)<0$, then $z(h)<0$ for sufficiently small positive $h$. Thus \emph{positive torsion} at $s$ implies that the the curve $\bbr$ is passing through the osculating plane at $s$ from below. Negative torsion implies from above. Here ``above" means the direction of $\ub(s)$.

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.4]{figures_mvc/positive_torsion}
	\end{center}
	\caption{Positive torsion implies that the curve passes through the osculating plane from below.}
\end{figure}

To avoid taking the derivative of the cross product, here is another formula for the torsion which is often more computationally useful.

\begin{prop}
	Let $\bbr:I \to \mathbb{R}^3$ be a regular space curve with an arbitrary parametrization. Then for every $t \in I$ with $\kappa(t) \neq 0$, the torsion is given by
	\begin{align}\label{eq:torsion_jerk}
		\tau(t)=\frac{\bbr'(t) \times \bbr''(t)\cdot \bbr'''(t)}{||\bbr'(t) \times \bbr''(t)||^2}.
	\end{align}
In physical terms, the vector $\bbr'''(t)$ (the rate of change of acceleration) is called the \emph{jerk} at time $t$.
\end{prop}

\begin{proof}
	We will prove that this formula holds for a curve parametrized by arc length, and that it is also independent of parametrization, which then implies it holds for a curve with any parametrization.
	
	For a curve parametrized by arc length, $\bbr'(s)=\ut(s)$ and $\bbr''(s)=\kappa(s)\un(s)$, and therefore $\bbr'(s) \times \bbr''(s)=\kappa(s)(\ut(s) \times \un(s))=\kappa(s)\ub(s)$ and $||\bbr'(s) \times \bbr''(s)||=||\kappa(s)\ub(s)||=\kappa(s)$. Plugging into \eqref{eq:torsion_jerk}, we have
	\begin{align*}
		\tau(s)&=\frac{\ub(s) \cdot \bbr'''(s)}{\kappa(s)} \\
		&=\frac{\ub(s) \cdot (\kappa(s) \un(s))'}{\kappa(s)} \\
		&=\frac{\kappa'(s) \ub(s)\cdot \un(s)+\kappa(s)\ub(s)\cdot\un'(s)}{\kappa(s)} \\
		&=\frac{\kappa'(s) \cdot 0+\kappa(s)\ub(s)\cdot\un'(s)}{\kappa(s)} \\
		&=\ub(s) \cdot \un'(s) \\
		&=-\ub'(s) \cdot \un(s)
	\end{align*}
in agreement with Definition \ref{def:torsion_for_unit_speed_curve}.

To check that this formula is independent of parametrization, as we computed previously, if $\widetilde{\bbr}=\bbr \circ \varphi$, then
\begin{align*}
	\widetilde{\bbr}'(t)&=\varphi'(t)\bbr'(\varphi(t)) \\
	\widetilde{\bbr}''(t)&=\varphi''(t)\bbr'(\varphi(t))+(\varphi'(t))^2\bbr''(\varphi(t)) \\
	\widetilde{\bbr}'''(t)&=\varphi'''(t)\bbr'(\varphi(t))+3\varphi'(t)\varphi''(t)\bbr''(\varphi(t))+(\varphi'(t))^3\bbr'''(\varphi(t)).
\end{align*}
Then 
\begin{align*}
	\widetilde{\bbr}'(t)\times \widetilde{\bbr}''(t)&=\varphi'(t)\bbr'(\varphi(t))  \times [\varphi''(t)\bbr'(\varphi(t))+(\varphi'(t))^2\bbr''(\varphi(t))] \\
	&=\varphi'(t)\varphi''(t)\underbrace{\bbr'(\varphi(t))\times \bbr'(\varphi(t))}_{=0}+(\varphi'(t))^3(\bbr'(\varphi(t)) \times \bbr''(\varphi(t))) \\
	&=(\varphi'(t))^3(\bbr'(\varphi(t)) \times \bbr''(\varphi(t))) \\
\end{align*}
and therefore
\begin{align*}
	\widetilde{\tau}(t)&=\frac{(\varphi'(t))^3 (\bbr'(\varphi(t)) \times \bbr''(\varphi(t)))\cdot (\varphi'''(t)\bbr'(\varphi(t))+3\varphi'(t)\varphi''(t)\bbr''(\varphi(t))+(\varphi'(t))^3\bbr'''(\varphi(t)))}{(\varphi'(t))^6||\bbr'(\varphi(t)) \times \bbr''(\varphi(t))||^2}
\end{align*}
Using the cyclic property of the triple product \fixme{Refer to my Linear Algebra notes.}, we have 
\begin{align*}
	\bbr'(t) \times \bbr''(t) \cdot \bbr'(t)=\underbrace{\bbr'(t) \times \bbr'(t)}_{=0} \cdot \bbr''(t)  =0
\end{align*}
and 
\begin{align*}
	\bbr'(t) \times \bbr''(t) \cdot \bbr''(t) =\underbrace{\bbr''(t) \times \bbr''(t)}_{=0} \cdot \bbr'(t) =0
\end{align*}
so the formula becomes
\begin{align*}
	\widetilde{\tau}(t)&=\frac{(\varphi'(t))^6 (\bbr'(\varphi(t)) \times \bbr''(\varphi(t)))\cdot \bbr'''(\varphi(t)))}{(\varphi'(t))^6||\bbr'(\varphi(t)) \times \bbr''(\varphi(t))||^2}\\
	&=\frac{(\bbr'(\varphi(t)) \times \bbr''(\varphi(t)))\cdot \bbr'''(\varphi(t)))}{||\bbr'(\varphi(t)) \times \bbr''(\varphi(t))||^2} \\
	&=\tau(\varphi(t)) \\
\end{align*}
which shows $\tau$ is invariant under reparametrizations.
\end{proof}

\newpage 

\begin{example}
Consider the twisted cubic $\bbr(t)=(t,t^2,t^3)$ of Example	\ref{ex:twisted_cubic}. The unit binormal vector is given by 

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.5]{figures_mvc/tc_unit_binormal}
	\end{center}
\end{figure}

The torsion function is

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.5]{figures_mvc/tc_torsion_function}
	\end{center}
\end{figure}

Notice that the torsion takes its minimal value of 3 at $t=0$, and then strictly decreases as $|t| \to \infty$.
\end{example}

Physically, we can think of a curve in $\R^3$ a being obtained from a straight line by bending (curvature) and twisting (torsion).

\subsection{The Fundamental Theorems of Plane and Space Curves}

\begin{thm}[Fundamental Theorem of the Local Theory of Curves]
	\begin{enumerate}[(1)]
		\item Given a smooth function $\kappa_s(s)$, $s \in I$, then there exists a regular parametrized plane curve $\bbr:I \to \R^2$ such that $s$ is the arc length and $\kappa_s(s)$ is the signed curvature. This curve is unique up to rotations and translations.
		\item Given smooth functions $\kappa(s)>0$ and $\tau(s)$, $s \in I$, there exists a regular parametrized curve $\bbr:I \to \R^3$ such that $s$ is the arc length, $\kappa(s)$ is the curvature, and $\tau(s)$ is the torsion of $\bbr$. This curve is unique up to rotations and translations.
	\end{enumerate}
\end{thm}

The complete proof of this theorem involves the theorem of existence and uniqueness of solutions of ordinary differential equations. However, we can prove the construction of the plane curve in part (1).

\begin{proof}
	(1) Choose any $t_0 \in I$. For this, define the angle function $\Theta:I \to \R$ by
	\begin{align*}
		\Theta(t)=\int_{t_0}^t \kappa_s(u)du+\Theta(t_0)
	\end{align*}
	and the velocity function as $\bv(t)=(\cos \Theta(t),\sin \Theta(t))$. Then define $\bbr:I \to \R^2$ by
	\begin{align*}
		\bbr(t)=\int_{t_0}^t \bv(u)du+\bbr(t_0).
	\end{align*}
	As desired, $\bbr$ is a unit-speed plane curve for which $\Theta$ is an angle function. Its signed curvature function is $\kappa_s=\Theta'$. The initial conditions $\bbr(t_0), \Theta(t_0)$ can be chosen arbitrarily.
	
	For the second statement, let $\bbr,\hat{\bbr}:I \to \R^2$ be two unit-speed plane curves each of whose signed curvature functions equals $\kappa_s$. Each angle function (denoted $\Theta$ and $\hat{\Theta}$, respectively) is an antiderivative of $\kappa_s$; since antiderivatives are unique up to an additive constant, we have $\hat{\Theta}=\Theta+\Theta_0$ for some $\Theta_0 \in \R$. Let $\bv, \hat{\bv}$ denote the velocity functions of the two curves. Then
	\begin{align*}
		\hat{\bv}(t)=(\cos \hat{\Theta}, \sin \hat{\Theta})=(\cos(\Theta(t)+\Theta_0), \sin(\Theta(t)+\Theta_0))=L_A\bv(t)
	\end{align*}
	where $L_A:\R^2 \to \R^2$ is the linear transformation which multiplies $\bv$ by the rotation matrix 
	\begin{align*}
		A=\begin{bmatrix}
			\cos \Theta_0 & -\sin \Theta_0 \\
			\sin \Theta_0 & \cos \Theta_0
		\end{bmatrix}.
	\end{align*}
	\fixme{Show this.} Let $T_{\bf q}:\R \to \R$ denote translation by the fixed vector ${\bf q}$:
	\begin{align*}
		T_{\bf q}\bv=\bv+{\bf q}
	\end{align*}
	and let $f=T_{\bf q} \circ L_A$. Consider the curve $\widetilde{\bbr}=f \circ \bbr$, where ${\bf q} \in \R^2$ has been chosen so that $\widetilde{\bbr}(t_0)=\hat{\bbr}(t_0)$. Since $\widetilde{\bbr}$ and $\hat{\bbr}$ have the same derivative function and the same initial value, the uniqueness of antiderivatives implies that $\widetilde{\bbr}=\hat{\bbr}$. \fixme{Add some details.}
	\end{proof}


\subsection{Summary of formulas}
Let $\bv\equiv \bbr'$, $\ba\equiv \bbr''$, ${\bf j}\equiv \bbr'''$ and drop the dependence on the parameter $t$.
\subsubsection{Plane Curves}
\begin{enumerate}
	\item Unit tangent and unit normal vectors 
	\begin{align*}
		\ut=\frac{\bv}{||\bv||}, \hspace{0.5cm} \un = \frac{\ut'}{||\ut'||}
	\end{align*}
	\item Signed curvature function ($\bbr=(x,y)$)
	\begin{align*}
		\kappa_s=\frac{x'y''-x''y'}{((x')^2+(y')^2)^\frac{3}{2}}.
	\end{align*} 
	\item Curvature function ($\bbr=(x,y)$)
	\begin{align*}
		\kappa=|\kappa_s|=\frac{|x'y''-x''y'|}{((x')^2+(y')^2)^\frac{3}{2}}.
	\end{align*}
\end{enumerate}

\subsubsection{Space Curves}
\begin{enumerate}
	\item Frenet frame
	\begin{align*}
		\ut=\frac{\bv}{||\bv||}, \hspace{0.5cm} \un = \frac{\ut'}{||\ut'||}, \hspace{0.5cm} \ub=\ut \times \un.
	\end{align*}
	\item Curvature function
	\begin{align*}
		\kappa=\frac{||\bv \times \ba||}{||\bv||^3}.
	\end{align*}
	\item Torsion function
	\begin{align*}
		\tau=\frac{\bv \times \ba \cdot {\bf j}}{||\bv \times \ba||^2}.
	\end{align*}
\end{enumerate}

\section{Multivariable Functions}
\subsection{Basic Definitions}
In the last section we studied functions with one input and multiple outputs. In this section, we study functions with multiple input and one output. That is, we study functions of the form
\begin{align*}
	f:U \subseteq \R^n \to \R.
\end{align*}

Examples abound.

\begin{example}
\begin{enumerate}[(a)]
	\item The volume of a right circular cylinder of radius $r$ and height $h$ is a function $V:U \subseteq \R^2 \to \R$ defined by $V(r,h)=\pi r^2h$.
	\item The Euclidean norm on $\R^n$ is a function $\rho:\R^n \to \R$ defined by $\rho(x_1,x_2,\dots,x_n)=\sqrt{x_1^2+x_2^2+\cdots+x_n^2}$.
	\item The ideal gas law is a function giving the pressure in terms of the temperature and volume:
	\begin{align*} 
		p:\R^2 &\to \R\\
		p(T,V)&=\frac{nRT}{V}.
	\end{align*}
\end{enumerate}	
\end{example}
In calculus, one generally defines a function by writing $y=f(x)$, where it is understood that the domain of the function is the largest set for which it is defined. This is common practice for multivariable functions as well, and one writes $z=f(x,y)$ meaning that the value of the function $f$ at $(x,y) \in \R^2$ is $z$. Similarly, one writes $u=f(x,y,z)$, $w=f(x,y,z,u)$, etc., if $f$ depends on more variables.

\begin{example}
Consider the function $f:D \subseteq \R^2 \to \R$ defined by $f(x,y)=\sqrt{y-x^2}$. For the square root to be defined, we must have $y-x^2\geq 0$. Taking the domain $D$ to be the largest set where the function is defined, we have then $D=\{(x,y) \in \R^2:y \geq x^2\}$, which is the shaded region above (and including) the parabola $y=x^2$ shown below. Note that $D$ is closed (since it contains its boundary $y=x^2$) and unbounded. (See Appendix \ref{app:topology} for definitions of these terms.)
\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.5]{figures_mvc/domain_parab}
	\end{center}
	\caption{The domain of the function $z=\sqrt{y-x^2}$.}
\end{figure}
\end{example}

\begin{exercise}
Describe the domain $D$ of the function $f:D \subseteq \R^2 \to \R$ defined by 
\begin{align*}
	f(x,y)=\frac{1}{\sqrt{16-x^2-y^2}}.
\end{align*}	
\end{exercise}

{\color{red}
\begin{solution}
	For the square root to be defined, we must have $16 \geq x^2+y^2$. However, we cannot take $16=x^2+y^2$ since then we divide by zero. Therefore
	\begin{align*}
		D=\{(x,y):x^2+y^2<16\}=B_4(0)
	\end{align*}
	is the open ball of radius 4 centered at $(0,0)$. Note that $D$ is open and bounded.
	\begin{figure}[h]
		\begin{center}
			\includegraphics[scale=0.3]{figures_mvc/dom_ball_4}
		\end{center}
		\caption{The domain of the function $z=\frac{1}{\sqrt{16-x^2-y^2}}$}.
	\end{figure}
\end{solution}}

\begin{exercise}
For each of the following functions, evaluate $f(3,2)$ and find and sketch the domain.
\begin{enumerate}
	\item $f(x,y)=\frac{\sqrt{x+y+1}}{x-1}$
	\item $f(x,y)=x\ln(y^2-x)$
\end{enumerate} 	
\end{exercise}

\begin{figure}[h]
	\begin{center}
	\includegraphics[scale=0.5]{figures_mvc/dom_range_solution}
\end{center}
\end{figure}

\begin{figure}[h]
	\begin{center}
	\includegraphics[scale=0.35]{figures_mvc/dom_range_solution_part_2}
\end{center}
\end{figure}
\subsection{Visualizing Multivariable Functions}
\begin{defn}
	Let $f:U \subset \mathbb{R}^2 \to \mathbb{R}$ be a real-valued function of two variables.  
\begin{enumerate}[(1)]
	\item The \emph{graph} of $f$ is the set $$\Gamma(f)=\{(x,y,z) \subset \mathbb{R}^3:z=f(x,y)\}$$.
	\item A \emph{level curve} of $f$ is the set
	$$L(f)=\{(x,y) \in U \subset \mathbb{R}^2:f(x,y)=\text{constant}\}$$
	\item To each level curve in the domain we associate a \emph{contour line}, which is the intersection of the plane $z=c$ with the surface $z=f(x,y)$. \\
\end{enumerate}
\end{defn}

\begin{figure}[h]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures_mvc/graph_def}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures_mvc/contour_lines_example}
\end{subfigure}
\caption{The graph of a function $z=f(x,y)$ is shown on the left. On the right, contour lines are shown in the domain which are the projections onto the $xy$-plane of the contour lines on the graph.}
\end{figure}

\newpage
\begin{example}
The graph of the function $z=100-x^2-y^2$ is shown below, along with the contour line at $z=75$, and the corresponding level curve.
\begin{figure}[h]
	\begin{center}
	\includegraphics[scale=0.5]{figures_mvc/contour}
\end{center}
\caption{Graph of $z=100-x^2-y^2$. The contour line at $z=75$ and corresponding level curve are shown.}
\end{figure}
	
\end{example}
\begin{example}[Elevation maps]
	On maps, contour lines (really level curves; many people use these terms interchangibly) represent constant elevation.
	\begin{figure}[h]
		\begin{center}
		\includegraphics[scale=0.4]{figures_mvc/mt_greylock}
	\end{center}
	\end{figure}
\end{example}
\newpage 
\begin{example}
Consider the function $f:\mathbb{R}^2 \to \mathbb{R}$ defined by $f(x,y)=y^2$. For any fixed value $x_0$ of $x$, a cross section of the graph is the parabola $z=y^2$ in the $zy$ plane at $x_0$. Since $f(x,y)$ is independent of $x$, the graph has a translational symmetry in the $x$ direction. The graph and level curves can be plotted in \emph{Mathematica} using the commands shown below.

	\begin{figure}[h]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures_mvc/half_pipe_ex}
  \caption{The graph of the function $z=y^2$.}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures_mvc/half_pipe_contour}
  \caption{Level curves of the function $z=y^2$.}
\end{subfigure}
\caption{The graph and level curves of the function $z=y^2$.}
\end{figure}
\end{example}

\begin{exercise}
Sketch the graph and level curves of the function $f:\mathbb{R}^2 \to \mathbb{R}$ defined by $f(x,y)=x^2+y^2$. 	
\end{exercise}

{\color{red}
\begin{solution}
		\begin{figure}[h]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures_mvc/paraboloid}
  \caption{The graph of the function $z=x^2+y^2$.}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=\linewidth]{figures_mvc/paraboloid_contour}
  \caption{Level curves of the function $z=x^2+y^2$.}
\end{subfigure}
\caption{The graph and level curves of the function $z=x^2+y^2$.}
\end{figure}
\end{solution}}
If $f:U \subset \mathbb{R}^3 \to \mathbb{R}$ is a function of three variables, its graph $\{(x,y,z,f(x,y,z)\}$ is a subset of $\mathbb{R}^4$, and therefore is impossible to visualize. Instead, we visualize the function by its three-dimensional \emph{level surfaces}.

\begin{defn}[Level surfaces]
A \emph{level surface} of $f$ is the set
\begin{align*}
	L(f)=\{(x,y,z) \in U \subset \mathbb{R}^3:f(x,y,z)=\text{constant}\}
\end{align*}	
\end{defn}
\newpage
\begin{example}
The level surfaces of the function $f:\R^3 \to \R$ defined by $f(x,y,z)=x^2+y^2+z^2$ are concentric spheres. These can be plotted in \emph{Mathematica} using the command shown below:
\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.4]{figures_mvc/concentric_spheres_contour}
	\end{center}
	\caption{Level surfaces of $f(x,y,z)=x^2+y^2+z^2$.}
\end{figure}
\end{example}
\newpage 
\begin{exercise}
Plot the level surfaces of the function $f:\R^3 \to \R$ defined by $f(x,y,z)=z$.	
\end{exercise}

{\color{red}
\begin{solution}
	\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.4]{figures_mvc/planes_level}
	\end{center}
	\caption{Level surfaces of $f(x,y,z)=z$.}
\end{figure}
\end{solution}}

\begin{exercise}
Plot the level surfaces of the function $f:\R^3 \to \R$ defined by $f(x,y,z)=x+z$.	
\end{exercise}
{\color{red}
\begin{solution}
	\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.4]{figures_mvc/level_surf_x_p_z}
	\end{center}
	\caption{Level surfaces of $f(x,y,z)=x+z$.}
\end{figure}
\end{solution}}

\subsection{Limits}
Let's compare the behavior of the functions
\begin{align*}
	f(x,y)=\frac{\sin{(x^2+y^2)}}{x^2+y^2} \hspace{0.5cm} \text{ and } \hspace{0.5cm} g(x,y)=\frac{x^2-y^2}{x^2+y^2}
\end{align*}
as $(x,y) \to (0,0)$. Note that neither function is defined at $(0,0)$:

\begin{figure}[h]
\begin{center}
\includegraphics[scale=0.5]{figures_mvc/tables_f_g}
\end{center}	
\end{figure}
It looks like $\lim_{(x,y) \to (0,0)}f(x,y)=1$ (since the values of the function approach 1 from all directions) while $\lim_{(x,y) \to (0,0)}g(x,y)$ does not exist (since the values of the function near $(0,0)$ do not approach any fixed value).

\begin{defn}[Limit]\label{def:limit}
	Let $f:U-\{\bx_0\} \subset \mathbb{R}^n \to \mathbb{R}$, and $L \in \mathbb{R}$. We say that $f(\bx) \to L$ as $\bx \to \bx_0$ if for every $\epsilon > 0$ there exists a corresponding $\delta>0$ such that
\begin{align*}
	0<||\bx-\bx_0||<\delta \implies |f(\bx)-L|<\epsilon.
\end{align*}
In this case $L$ is called the \emph{limit} of $f$ as $\bx$ approaches $\bx_0$, and  we write $\lim_{\bx \to \bx_0}f(\bx)=L$.
\end{defn}
This definition says that the distance between $f(\bx)$ and $L$ can be made arbitrarily small by making the distance between $\bx$ and  $\bx_0$ sufficiently small. \footnote{Two points $x_1,x_2$ are said to be \emph{arbitrarily close} if, for \emph{every} $\epsilon>0$, $d(x_1,x_2)<\epsilon$. A point $x_1$ is said to be \emph{sufficiently close} to $x_2$ if there exists \emph{some} (fixed) $\delta>0$ such that $d(x_1,x_2)<\delta$.}

\begin{figure}[h]
	\begin{center}
	\includegraphics[scale=0.4]{figures_mvc/limit_def}
\end{center}
\caption{A function $f(\bx)$ has limit $L$ as $\bx \to \bx_0$ if $f(\bx)$ can be made arbitrarily close to $L$ by taking $\bx$ sufficiently close to $\bx_0$.}
\end{figure}

\newpage

As in single-variable calculus, another illustration of the definition of a limit can be given in terms of its graph: For any $\epsilon>0$, we can find $\delta>0$ such that if $\bx \in B_\delta(\bx_0)$ and $\bx \neq \bx_0$, then $f(x)$ lies between the horizontal planes $z=L-\epsilon$ and $z=L+\epsilon$.

	\begin{figure}[h]
		\begin{center}
	\includegraphics[scale=0.7]{figures_mvc/limit_def_graph}
	\end{center}
	\caption{A function $f$ has limit $L$ as $\bx \to \bx_0$ if the graph can be bounded between two arbitrarily close planes whenever for all $\bx$ sufficiently close to $\bx_0$.}
	\end{figure}
	
For functions of a single variable, when we let $x \to a$, there are only two directions of approach: from the left or from the right. Recall that if $\lim_{x \to a^-}f(x) \neq \lim_{x \to a^+}f(x)$, then $\lim_{x \to a}f(x)$ does not exist. For functions of two variables, we can let $(x,y)$ approach $(a,b)$ from an infinite number of directions, as long as $(x,y)$ stays within the domain of $f$.
	
\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.5]{figures_mvc/approach}
	\end{center}
	\caption{Various paths in the domain of a function $f:\R^2 \to \R$ along which we can approach a point $(a,b)$.}
\end{figure}	
	
	
Note that the definition of a limit only depends on the \emph{distance} from $(x,y)$ and $(a,b)$. It does \emph{not} refer to the direction of the approach. Therefore, if the limit exists, then $f(x,y)$ must approach the same limit no matter how $(x,y)$ approaches $(a,b)$. Thus, if we can find two different paths of approach along which the function $f(x,y)$ has different limits, then it follows that $\lim_{(x,y) \to (a,b)}f(x,y)$ does not exist.

\begin{example}
Consider $\lim_{(x,y) \to (0,0)}\frac{x^2-y^2}{x^2+y^2}$. Consider approaching $(0,0)$ along the $x$-axis, that is, along the curve $\bbr(t)=(t,0)$. Then
\begin{align*}
	\lim_{(x(t),y(t)) \to (0,0)}\frac{x(t)^2-y(t)^2}{x(t)^2+y(t)^2}=\lim_{t \to 0}\frac{t^2-0}{t^2+0}=\lim_{t \to 0}\frac{t^2}{t^2}=\lim_{t \to 0}1=1.
\end{align*}
Approaching $(0,0)$ along the $y$-axis, i.e., along the path $\bbr(t)=(0,t)$, we find
	\begin{align*}
	\lim_{(x(t),y(t)) \to (0,0)}\frac{x(t)^2-y(t)^2}{x(t)^2+y(t)^2}=\lim_{t \to 0}\frac{0-t^2}{0+t^2}=\lim_{t \to 0}\frac{-t^2}{t^2}=\lim_{t \to 0}(-1)=-1.
\end{align*}
We have found two paths along which $\lim_{(x,y) \to (0,0)}\frac{x^2-y^2}{x^2+y^2}$ has different values, so $\lim_{(x,y) \to (0,0)}\frac{x^2-y^2}{x^2+y^2}$ does not exist.
\end{example}

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.5]{figures_mvc/no_limit_ex}
	\end{center}
	\caption{The function $f(x,y)=\frac{x^2-y^2}{x^2+y^2}$ has no limit as $(x,y) \to (0,0)$.}
\end{figure}

\begin{example}
	Consider $\lim_{(x,y) \to (0,0)}\frac{xy}{x^2+y^2}$. Approaching $(0,0)$ along the $x$-axis gives
	\begin{align*}
		\lim_{x \to 0} \frac{x \cdot 0}{x^2+0}=\lim_{x \to 0} \frac{0}{x^2}=0.
	\end{align*}
	Approaching $(0,0)$ along the $y$-axis gives
	\begin{align*}
		\lim_{y \to 0} \frac{0 \cdot y}{0+y^2}=\lim_{y \to 0} \frac{0}{y^2}=0.
	\end{align*}
While these limits agree, this is \emph{not} sufficient to conclude that $\lim_{(x,y) \to (0,0)}\frac{xy}{x^2+y^2}=0$, since we must show that we obtain the same limit along \emph{every} path approaching $(0,0)$. Indeed, if we approach $(0,0)$ along the line $y=x$, we obtain
\begin{align*}
	\lim_{x \to 0}\frac{x^2}{x^2+x^2}=\lim_{x \to 0}\frac{x^2}{2x^2}=\lim_{x \to 0}\frac{1}{2}=\frac{1}{2}.
\end{align*}
Thus, $\lim_{(x,y) \to (0,0)}\frac{xy}{x^2+y^2}$ does not exist.
\end{example}

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.5]{figures_mvc/xy_not_suff}
	\end{center}
	\caption{The function $f(x,y)=\frac{xy}{x^2+y^2}$ has no limit as $(x,y) \to (0,0)$.}
\end{figure}
\newpage 
The previous example showed that it is not sufficient to compute the limit of a multivariable function by restricting the function to paths in the domain. We now show how to use Definition \ref{def:limit} to show that a limit \emph{does} exist.

\begin{thm}\label{thm:simple_limits}
Let $a,b,c$ be fixed real numbers. Then
\begin{enumerate}[(a)]
	\item $\lim_{(x,y) \to (a,b)} c=c$.
	\item $\lim_{(x,y) \to (a,b)} x = a$.
	\item $\lim_{(x,y) \to (a,b)} y = b$.
\end{enumerate}	
\end{thm}

\begin{proof}\hspace{15cm}
	\begin{enumerate}[(a)]
		\item Let $\epsilon>0$. Since $|c-c|=0$, by taking $\delta$ to be any positive real number, then \newline $0<\sqrt{(x-a)^2+(y-b)^2}<\delta$ implies $|f(x,y)-f(a,b)|=|c-c|=0<\epsilon$. This proves that $\lim_{(x,y) \to (a,b)} c=c$.
		\item Let $\epsilon>0$. We have $|f(x,y)-f(a,b)|=|x-a|$. Since 
		\begin{align*}
			|x-a|=\sqrt{(x-a)^2} \leq \sqrt{(x-a)^2+(y-b)^2},
		\end{align*}
		by taking $\delta=\epsilon$, $0<\sqrt{(x-a)^2+(y-b)^2}<\delta$ implies that $|f(x,y)-f(a,b)|=|x-a|<\epsilon$. This proves that $\lim_{(x,y) \to (a,b)} x = a$.
		\item The proof is essentially the same as that of part (b) and is left as an exercise.
	\end{enumerate}
\end{proof}

\begin{exercise}
Prove part (c) of Proposition \ref{prop:simple_limits}. 	
\end{exercise}

{\color{red}
\begin{solution}
	Let $\epsilon>0$. We have $|f(x,y)-f(a,b)|=|y-b|$. Since 
		\begin{align*}
			|y-b|=\sqrt{(y-b)^2} \leq \sqrt{(x-a)^2+(y-b)^2},
		\end{align*}
		by taking $\delta=\epsilon$, $0<\sqrt{(x-a)^2+(y-b)^2}<\delta$ implies that $|f(x,y)-f(a,b)|=|y-b|<\epsilon$. This proves that $\lim_{(x,y) \to (a,b)} y = b$.
\end{solution}}

The next theorem shows that all of the limit properties of single-variable functions carry over to multivariable functions.

\begin{thm}[Limit laws for multivariable functions]\label{thm:limit_laws_for_multivariable_functions}
Suppose $f(x,y)$ and $g(x,y)$ are defined on the same open set containing $(x_0,y_0)$, and that 
\begin{align*}
	\lim_{(x,y) \to (x_0,y_0)}f(x,y)=L \hspace{0.5cm} \text{ and } \hspace{0.5cm} \lim_{(x,y) \to (x_0,y_0)}g(x,y)=M.
\end{align*}
Then
	\begin{enumerate}[(i)]
		\item $\lim_{(x,y) \to (x_0,y_0)} cf(x,y)=cL$ for any $c \in \R$;
		\item $\lim_{(x,y) \to (x_0,y_0)}(f(x,y)+ g(x,y))=L+M$;
		\item $\lim_{(x,y) \to (x_0,y_0)}(f(x,y)g(x,y))=LM$;
		\item $\lim_{(x,y) \to (x_0,y_0)}=\frac{f(x,y)}{g(x,y)}=\frac{L}{M}$ whenever $M \neq 0$.
	\end{enumerate}
\end{thm}

\begin{pf}
The proofs of these are identical to the proofs of the corresponding properties in Theorem \ref{thm:limit_laws_for_single-variable_functions}, with the metric $d_\R(x,y)=|x-y|$ on $\R$ replaced by the metric $d_{\R^2}(\bx,\by)=||\bx-\by||$ on $\R^2$. \footnote{In fact, these properties hold for maps between any metric spaces. For a function $f:X \to Y$ between metric spaces, the definition of $\lim_{x \to x_0}f(x)=L$ becomes: for every $\epsilon>0$ there exists $\delta>0$ such that $d_Y(f(x),L)<\epsilon$ whenever $0<d_X(x,x_0)<\delta$. Since the proofs of the limit properties only depend on properties shared by every metric (e.g., the triangle inequality), the proofs are exactly the same, with the Euclidean metrics on $\R^2, \R$ replaced by the metrics on $X$ and $Y$.}   
\end{pf}

\begin{example}
To evaluate $\lim_{(x,y) \to (1,2)}(x^2y^3-x^3y^2+3x+2y)$ using Theorems \ref{thm:limit_laws_for_multivariable_functions} and \ref{thm:simple_limits}, we have
\begin{align*}
	&\lim_{(x,y) \to (1,2)}(x^2y^3-x^3y^2+3x+2y)=\lim_{(x,y) \to (1,2)}(x^2y^3)+\lim_{(x,y) \to (1,2)}(-x^3y^2)+\lim_{(x,y) \to (1,2)}(3x+2y) \\
	&=\lim_{(x,y) \to (1,2)}x^2\cdot \lim_{(x,y) \to (1,2)}y^3 - \lim_{(x,y) \to (1,2)} x^3\cdot \lim_{(x,y) \to (1,2)} y^2+3\lim_{(x,y) \to (1,2)} x+2\lim_{(x,y) \to (1,2)}y \\
	&=(\lim_{(x,y) \to (1,2)}x)^2\cdot (\lim_{(x,y) \to (1,2)}y)^3 - (\lim_{(x,y) \to (1,2)} x)^3\cdot (\lim_{(x,y) \to (1,2)} y)^2+3\lim_{(x,y) \to (1,2)} x+2\lim_{(x,y) \to (1,2)}y \\ 
	&=(1)^2(2)^3-(1)^3(2)^2+3(1)+2(2) \\
	&=8-4+3+4 \\
	&=11.
\end{align*} 	
\end{example}

\begin{defn}[Continuous function]
 A function $f$ of two variables is \emph{continuous at} $(a,b)$ if
\begin{align*}
	\lim_{(x,y) \to (a,b)}f(x,y)=f(a,b).
\end{align*}
The function $f$ is \emph{continuous on} $D$ if $f$ is continuous at every point $(a,b)$ in $D$.	
\end{defn}
As in single-variable calculus, continuous functions map nearby points in $D$ to nearby points in $\mathbb{R}$, so a surface that is the graph of a continuous function has no holes or breaks.

Using the limit properties, we find that sums, products, and quotients of continuous functions are continuous on their domains. Similarly, compositions of continuous functions are continuous.  

It follows from Theorem \ref{thm:simple_limits} that $f(x,y)=x, g(x,y)=y,$ and $h(x,y)=c$ are continuous. Since any polynomial, e.g.,
\begin{align*}
	f(x,y)=x^4+5x^3y^2+6xy^4-7y+6
\end{align*}
can be built out of these by multiplication and addition, all polynomials are continuous on $\mathbb{R}^2$. Likewise, any rational function is continuous on its domain because it is a quotient of continuous functions. E.g.,
\begin{align*}
	g(x,y)=\frac{2xy+1}{x^2+y^2}.
\end{align*}

\begin{example}
The function $f(x,y)=\frac{x^2-y^2}{x^2+y^2}$ is continuous everywhere except at $(0,0)$.	
\end{example}

\begin{exercise}
Where is the function
\begin{align*}
	g(x,y)=\begin{cases}
		\frac{x^4-x^2y^2}{x+y}, &\text{ if } (x,y) \neq (0,0), \\
		0, &\text{ if } (x,y)=(0,0).
	\end{cases}
\end{align*}	
continuous?
\end{exercise}

{\color{red}
\begin{solution}
	Since a rational function is continuous everywhere it is defined, $g(x,y)$ is continuous for all $(x,y) \neq (0,0)$. Since for $(x,y) \neq (0,0)$
	\begin{align*}
		\frac{x^4-x^2y^2}{x+y}=\frac{x^2(x^2-y^2)}{x+y}=\frac{x^2(x+y)(x-y)}{x+y}=x^2(x-y),
	\end{align*}
	we have 
	\begin{align*}
		\lim_{(x,y) \to (0,0)}\frac{x^4-x^2y^2}{x+y}=\lim_{(x,y) \to (0,0)}x^2(x-y)=0.
	\end{align*}
	Thus, $g(x,y)$ is continuous everywhere.
\end{solution}}
\newpage

\subsection{Partial Derivatives}
\subsubsection{Motivation}
\begin{example}[Heat index]\hspace{15cm}
\begin{figure}[h]
	\begin{center}
		\includegraphics[width=\textwidth]{figures_mvc/h_i_1}
	\end{center}
\end{figure}
	
\begin{figure}[h]
	\begin{center}
	\includegraphics[scale=0.45]{figures_mvc/heat_index}
	\end{center}
\end{figure}

\begin{figure}[h]
	\begin{center}
		\includegraphics[width=\textwidth]{figures_mvc/h_i_2}
	\end{center}
\end{figure}

\newpage

\begin{figure}[h]
	\begin{center}
		\includegraphics[width=\textwidth]{figures_mvc/h_i_4}
	\end{center}
\end{figure}
By averaging these values we get the estimate $G'(70) \approx 0.9$. This says that, when the temperature is $96^\circ$ F and the relative humidity is $70\%$, the heat index rises about $0.9^\circ$ F for every percent the relative humidity rises.
\end{example} 
In general, if $f(x,y)$ is a function of two variables $x$ and $y$, and we consider the values of the function obtained by varying $x$ (say) while keeping $y$ fixed to a constant value $y=y_0$, then we are really considering a function of a \emph{single} variable $g(x)=f(x,y_0)$. Then if $g(x)$ is differentiable at $x=x_0$, we call $g'(x)$ a \emph{partial derivative} of $f(x,y)$. We now define this formally.

\newpage 
\subsubsection{Definition of Partial Derivatives}
\begin{defn}[Partial derivative]
	Let $f:U \subset \R^2 \to \R$ be defined on an open subset of $\R^2$ containing the point $(x_0,y_0)$. \footnote{Since $U$ is open, there exists a neighborhood of $(x_0,y_0)$ contained in $U$. Thus, if $h$ is sufficiently close to zero, then all points of the form $(x_0+h,y_0)$ will be in $U$, so this definition makes sense.} Then the real number
	\begin{align*}
		\frac{\partial f}{\partial x}(x_0,y_0)&=\lim_{h \to 0}\frac{f(x+h,y)-f(x,y)}{h} \\
	\end{align*}
	is called the \emph{partial derivative of $f$ with respect to $x$ at the point $(x_0,y_0)$}, provided this limit exists. Similarly, the real number
	\begin{align*}
		\frac{\partial f}{\partial y}(x_0,y_0)&=\lim_{h \to 0}\frac{f(x,y+h)-f(x,y)}{h}
	\end{align*}
	is called the \emph{partial derivative of $f$ with respect to $y$ at the point $(x_0,y_0)$}, provided this limit exists. If $\frac{\partial f}{\partial x}$ and $\frac{\partial f}{\partial y}$ are defined at all points of $U$, then they are functions on $U$.
\end{defn}

\begin{remark}
Note that $\frac{\partial f}{\partial x}$ is not a quotient, but a \emph{limit} of a quotient. Thus, the symbols ``$\partial f$" or ``$\partial x$" do not have independent meaning. Similar remarks apply to $\frac{\partial f}{\partial y}$. While this is the most common notation for the partial derivatives (and the one we will use almost exclusively), other notations are also frequently used.
\end{remark}
\begin{figure}[h]
	\begin{center}
	\includegraphics[scale=0.5]{figures_mvc/p_d_notation}
\end{center}
\caption{Notations for partial derivatives.}
\end{figure}
To compute the partial derivative of a function $f(x,y)$ with respect to $x$, one simply treats $y$ as a constant and differentiates $f(x,y)$ with respect to $x$. To compute the partial derivative with respect to $y$, treat $x$ as a constant and differentiate $f(x,y)$ with respect to $y$.

\begin{example}
If $f(x,y)=x^3+x^2y^3-2y^2$, then
\begin{align*}
	\frac{\partial f}{\partial x}&=3x^2+2xy^3 \\
	\frac{\partial f}{\partial y}&=3x^2y^2-4y.
\end{align*}	
\end{example}
\newpage

\subsubsection{Interpretation of Partial Derivatives}

\begin{figure}[h]
	\begin{center}
		\includegraphics[width=\textwidth]{figures_mvc/pd_1}
	\end{center}
\end{figure}

\begin{figure}[h]
	\begin{center}
		\includegraphics[width=\textwidth]{figures_mvc/pd_2}
	\end{center}
\end{figure}

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.5]{figures_mvc/pd_3}
	\end{center}
\end{figure}
\newpage 
\begin{exercise}
If $f(x,y)=\sin\left(\frac{x}{1+y}\right)$, calculate $\frac{\partial f}{\partial x}$ and $\frac{\partial f}{\partial y}$.
\end{exercise}

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.5]{figures_mvc/pd_ex_3_soln}
	\end{center}
\end{figure}

\fixme{More Examples?}

\fixme{Implicit differentiation here?}
\newpage 
\subsubsection{Functions of More than Two Variables}
\begin{figure}[h]
	\begin{center}
		\includegraphics[width=\textwidth]{figures_mvc/more_var_pd}
	\end{center}
\end{figure}
That is, we hold all the variables other than $x_i$ constant and differentiate $f$ with respect to $x_i$.

\begin{exercise}
Compute $\frac{\partial f}{\partial x}, \frac{\partial f}{\partial y}$, and  $\frac{\partial f}{\partial z}$ if $f(x,y,z)=e^{xy}\ln z$. 	
\end{exercise}

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.5]{figures_mvc/pd3vex}
	\end{center}
\end{figure}
\newpage 

\section{Differentiability}
If $f:U \subseteq \R$ is differentiable at $x_0 \in U$, then the limit
\begin{align}\label{eq:old_derivative}
	f'(x_0)=\lim_{h \to 0}\frac{f(x_0+h)-f(x_0)}{h}
\end{align}
exists. The existence of this limit implies that $f(x)$ is well-approximated by its tangent line
\begin{align*}
	f(x)=f(x_0)+f'(x_0)(x-x_0)
\end{align*}
for $x$ in a neighborhood of $x_0$. Recall also that a differentiable function is automatically continuous, since if $f$ is differentiable at $x_0$, then 
\begin{align*}
	\lim_{h \to 0}(f(x_0+h)-f(x_0))&=\lim_{h \to 0}\frac{h}{h}(f(x_0+h)-f(x_0)) \\
	&=\lim_{h \to 0}\left(h \cdot \frac{f(x_0+h)-f(x_0)}{h}\right) \\
	&=\lim_{h \to 0}h \cdot \lim_{h \to 0}\frac{f(x_0+h)-f(x_0)}{h} \\
	&=\lim_{h \to 0}h f'(x_0) \\
	&=0 \cdot f'(x_0) \\
	&=0.
\end{align*}

However, the next example shows that a multivariable function can be discontinuous at a point where the partial derivatives exist.

\begin{example}\label{ex:p_d_but_disc}
	Let
	\begin{align*}
		f(x,y)=\begin{cases}
			0 \text{ if } xy \neq 0, \\
			1 \text{ if } xy=0
		\end{cases}
	\end{align*}
Since $\lim_{(x,y) \to (0,0)}f(x,y)$ is 1 along the x-axis and $0$ along the line $y=x$, the limit does not exist and therefore $f(x,y)$ is discontinuous at $(0,0)$. However,
	\begin{align*}
		D_xf(0,0)&=\lim_{h \to 0}\frac{f(h,0)-f(0,0)}{h}=\lim_{h \to 0}\frac{1-1}{h}=0 \\
		D_yf(0,0)&=\lim_{h \to 0}\frac{f(0,h)-f(0,0)}{h}=\lim_{h \to 0}\frac{1-1}{h}=0 \\
	\end{align*}
so the partial derivatives both exist at $(0,0)$. 
\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.4]{figures_mvc/p_d_but_disc}
	\end{center}
	\caption{Graph of the function $f(x,y)$ in Example \ref{ex:p_d_but_disc}}
\end{figure}
\end{example}
The reason for this is that continuity at $(a,b)$ requires that $\lim_{(x,y) \to (a,b)}f(x,y)=f(a,b)$ when the limit is taken along \emph{any} path passing through $(a,b)$. The partial derivatives, on the other hand, only depend on what is happening along lines through $(a,b)$ parallel to the $x$ and $y$ axes, and therefore they failed to detect the discontinuity in the previous example. This suggests we need a stronger condition in our definition of differentiability for multivariable functions than the existence of the partial derivatives if we want differentiable multivariable functions to behave similarly to differentiable single variable functions.

To see what definition to take, it is useful to view the definition of differentiability of a single-variable function from another perspective. We do this as follows. First, let $\Delta f(h)\equiv f(x+h)-f(x)$, where we view $\Delta f:\R \to \R$ as a function of $h$ with $x$ held fixed, which gives the change in $f$ when we change $x$ to $x+h$. We then rearrange \eqref{eq:old_derivative} as 
\begin{align*}
	\lim_{h \to 0}\left[\frac{\Delta f(h)}{h}\right]-f'(x)&=0 \\
	\lim_{h \to 0}\left[\frac{\Delta f(h)}{h}-f'(x)\right]&=0 \\
	\lim_{h \to 0}\left[\frac{\Delta f(h)}{h}-\frac{f'(x)h}{h}\right]&=0 \\
	\lim_{h \to 0}\left[\frac{\Delta f(h)-f'(x)h}{h}\right]&=0 \\
\end{align*} 
If we let $r(h) \equiv \Delta f(h)-f'(x)h$, Then existence of the limit in equation \eqref{eq:old_derivative} implies that 
\begin{align}
	\Delta f(h)=f'(x)h+r(h)
\end{align}
where $\lim_{h \to 0}\frac{r(h)}{h}=0$. That is, for all points in a sufficiently small neighborhood of $x$,
\begin{align}
	\Delta f(h) \approx f'(x)h
\end{align}
which is a \emph{linear} function of $h$. 
\begin{defn}
If $f$ is differentiable at $x$, we call the linear function 
\begin{align*}
	df_x:\R \to \R
\end{align*}	
defined by $df_x(h)=f'(x)h$ the \emph{differential of $f$ at $x$}.
\end{defn}
Thus existence of the limit in \eqref{eq:old_derivative} is equivalent to the statement that there exists a \emph{linear} function (the differential of $f$ at $x$) that approximates the change of $f$ near $x$, up to an error term which can be made arbitrarily small by taking points sufficiently close to $x$.

\begin{defn}\label{def:differentiable_mv_function}
Let $f:U \subseteq \R^n \to \R$ be a multivariable function defined on an open subset $U$ of $\R^n$ and let $\Delta f:\R^n \to \R$ be defined by $\Delta f(\bh)=f(\bx + \bh)-f(\bx)$. We say that $f$ is \emph{differentiable} at $\bx \in U$ if there exists a linear function $T:\R^n \to \R$ such that  
\begin{align*}
	\Delta f(\bh)=T(\bh)+r(\bh)
\end{align*}	
where $r(\bh)$ is a ``small" error term, in the sense that $\lim_{\bh \to \zv}\frac{|r(\bh)|}{||\bh||}=0$. If $T$ exists, we denote it by $df_\bx$ and call it the \emph{differential of $f$ at $\bx$}. 

Writing this out, this says that $f$ is differentiable at $\bx$ if for every $\epsilon>0$, there exists a linear function $df_\bx:\R^n \to \R$ and a number $\delta>0$ such that 
\begin{align*}
	|f(\bx+\bh)-f(\bx)-df_\bx(\bh)|<\epsilon ||\bh||
\end{align*}
whenever $||\bh||<\delta$.
\end{defn}
We see immediately that if the differential of $f$ at $\bx$ exists, it is unique.

\begin{prop}[Uniqueness of the differential]\label{prop:uniqueness_of_the_differential}
	If $T,T':\R^n \to \R$ are two linear maps which satisfy Definition \ref{def:differentiable_mv_function}, then $T'=T$.
\end{prop}

\begin{proof}
	Suppose $T,T':\R^n \to \R$ are linear maps such that 
	\begin{align*}
		f(\bx+\bh)&=f(\bx)+T(\bh)+r(\bh), \\
		f(\bx+\bh)&=f(\bx)+T'(\bh)+r'(\bh)
	\end{align*}
	with
	\begin{align*}
		\lim_{\bh \to \zv}\frac{|r(\bh)|}{||\bh||}=\lim_{\bh \to \zv}\frac{|r'(\bh)|}{||\bh||}=0.
	\end{align*}
	Then, since $T,T'$ are linear,
	\begin{align*}
		|(T-T')(\bh)|&=|T(\bh)-T'(\bh)| \\
		&=|T(\bh)-T'(\bh)+f(\bx+\bh)-f(\bx)-(f(\bx+\bh)-f(\bx))| \\
		&=|T(\bh)-(f(\bx+\bh)-f(\bx))+f(\bx+\bh)-f(\bx)-T'(\bh)| \\
		&\leq |T(\bh)-(f(\bx+\bh)-f(\bx))|+|f(\bx+\bh)-f(\bx)-T'(\bh)| \\
		&= |f(\bx+\bh)-f(\bx)-T(\bh)|+|f(\bx+\bh)-f(\bx)-T'(\bh)| \\
		&=|r(\bh)|+|r'(\bh)|
	\end{align*}
	and therefore
\begin{align*}
	\frac{|(T-T')(\bh)|}{||\bh||}\leq \frac{|r(\bh)|}{||\bh||}+ \frac{|r'(\bh)|}{||\bh||}.
\end{align*}
	Since 
\begin{align*}
		\lim_{\bh \to \zv}\frac{|r(\bh)|}{||\bh||}=\lim_{\bh \to \zv}\frac{|r'(\bh)|}{||\bh||}=0,
	\end{align*}	
given $\epsilon>0$ there exist positive real numbers $\delta_1,\delta_2$ such that 
	\begin{align*}
		\frac{|r(\bh)|}{||\bh||}<\frac{\epsilon}{2}
	\end{align*}
	whenever $||\bh||<\delta_1$ and 
	\begin{align*}
		\frac{|r'(\bh)|}{||\bh||}<\frac{\epsilon}{2}
	\end{align*}
	whenever $||\bh||<\delta_2$. By choosing $\delta=\min\{\delta_1,\delta_2\}$, we have
	\begin{align*}
		\frac{|(T-T')(\bh)|}{||\bh||}\leq \frac{|r(\bh)|}{||\bh||}+ \frac{|r'(\bh)|}{||\bh||}<\frac{\epsilon}{2}+\frac{\epsilon}{2}
	\end{align*}
	whenever $||\bh||<\delta$, and therefore
	\begin{align*}
		\lim_{\bh \to \zv}\frac{|(T-T')(\bh)|}{||\bh||}=0.
	\end{align*}
Since this limit holds as $\bh \to \zv$ along any path, for any fixed $\bh \neq \zv$ we must have
\begin{align*}
		\lim_{\bh \to \zv}\frac{|(T-T')(t\bh)|}{||t\bh||}=0.
	\end{align*}
Since $T-T'$ is linear, this becomes
\begin{align*}
		0&=\lim_{t \to 0}\frac{|(T-T')(t\bh)|}{||t\bh||}\\
		&=\lim_{t \to 0}\frac{|t(T-T')(\bh)|}{||t\bh||}\\
		&=\lim_{t \to 0}\frac{|t|\ |(T-T')(\bh)|}{|t| \ ||\bh||}\\
		&= \lim_{t \to 0}\frac{|(T-T')(\bh)|}{||\bh||}\\
		&=\frac{|(T-T')(\bh)|}{||\bh||},
	\end{align*}
		which implies that $(T-T')(\bh)=0$ and therefore $\bh \in \ker (T-T')$. Since $\bh$ was an arbitrary nonzero vector, this means that $\ker(T-T')=\R^2$, so $T-T'$ is the zero map, and therefore $T=T'$.
\end{proof}

From Definition \ref{def:differentiable_mv_function}, we see that if $f:U \subseteq \R^n \to \R$ is a linear function, then $f$ is differentiable at each point $\bx \in U$ and $df_\bx = f$.

\begin{prop}\label{prop:linear_f_equals_diff}
If $f:U \subseteq \R^n \to \R$ is linear, then for each $\bx \in U$, $df_\bx=f$.	
\end{prop}

\begin{proof}
		Since $f$ is linear,
	\begin{align*}
		\lim_{\bh \to {\bf 0}}\frac{|f(\bx+\bh)-f(\bx)-f(\bh)|}{||\bh||}&=\lim_{\bh \to {\bf 0}}\frac{|f(\bx)+f(\bh)-f(\bx)-f(\bh)|}{||\bh||} \\
		&=\lim_{\bh \to {\bf 0}}\frac{0}{||\bh||} \\
		&=0.
	\end{align*}
Thus, $df_\bx=f(\bx)$.
\end{proof}

\begin{thm}[A differentiable function is continuous]
	If $f:U\subset \mathbb{R}^n \to \mathbb{R}$ is differentiable at $\bx \in U$, then it is continuous at $\bx \in U$.
\end{thm}

\begin{proof}
	Let $\epsilon>0$. Then
	\begin{align*}
		|f(\bx+\bh)-f(\bx)|&=|df_\bx(\bh)+r(\bh)| \\
		&\leq |df_\bx(\bh)|+|r(\bh)|.
	\end{align*}
Choose $\delta_0>0$ such that $|r(\bh)|<\epsilon ||\bh||$ whenever $||\bh||<\delta_0$. Then
\begin{align*}
	|f(\bx+\bh)-f(\bx)|&<|df_\bx(\bh)|+\epsilon ||\bh||.
\end{align*}
By ???, $|df_\bx(\bh)|\leq ||df_\bx|| \ ||\bh||$, so 
\begin{align*}
	|f(\bx+\bh)-f(\bx)|&<||df_\bx|| \ ||\bh||+\epsilon ||\bh|| \\
&=(||df_\bx|| +\epsilon)||\bh||.
\end{align*}
Let $\delta=\min\{\delta_0,\frac{\epsilon}{||df_\bx|| +\epsilon}\}$. Then by taking $||\bh||<\delta$, we have
\begin{align*}
	|f(\bx+\bh)-f(\bx)|&<(||df_\bx|| +\epsilon)||\bh|| \\
&<(||df_\bx|| +\epsilon)\frac{\epsilon}{(||df_\bx|| +\epsilon)} \\
&=\epsilon,
\end{align*}
which shows that $\lim_{\bh \to \zv} (f(\bx+\bh)-f(\bx))=0$. Hence, $f$ is continuous.
\end{proof}

In the next section, we show how to compute the differential of a differentiable function.

\subsection{Directional Derivatives}
Our next task is to show how to compute $df_\bx(\bv)$ for any $\bv \in \R^n$. We now show that this computation can be reduced to the derivative of a single-variable function. 

\begin{thm}[Computation of the differential]\label{thm:computation_of_the_differential}
Let $f:U \subseteq \R^n \to \R$ be differentiable at $\bx \in U$ and let $\bbr: I\subseteq \R \to U$ be the straight-line path $\bbr(t)=\bx+t\bv$ passing through $\bx$ in the direction of $\bv$ at $t=0$. Then the single-variable function $f \circ \bbr :I \subseteq \R \to \R$ is the single-variable function given by $f(\bbr(t))$ is differentiable and 
\begin{align*}
	df_\bx(\bv)=\frac{d}{dt}f(\bx+t\bv)|_{t=0}.
\end{align*}	
\end{thm}

\begin{proof}
	Since $f$ is differentiable at $\bx$, for every $\epsilon>0$ there exists $\delta>0$ such that $||\bh||<\delta$ implies
	\begin{align*}
		|f(\bx+\bh)-f(\bx)-df_\bx(\bh)|&<\epsilon ||\bh||.
	\end{align*}
	Let $\bv$ be a fixed nonzero vector and choose $t \in \R$ sufficiently small so that $||t \bv||<\delta$. Then 
	\begin{align*}
		|f(\bx+t\bv)-f(\bx)-df_\bx(t\bv)|&<\epsilon ||t\bv||.
	\end{align*} 
	Since $df_\bx$ is linear, this implies
	\begin{align*}
				|f(\bx+t\bv)-f(\bx)-t df_\bx(\bv)|&<\epsilon |t| \ ||\bv||.
	\end{align*}
	Dividing through by $|t|$, we have
	\begin{align*}
		\left|\frac{f(\bx+t\bv)-f(\bx)}{t}-df_\bx(\bv)\right|&<\epsilon||\bv||.
	\end{align*}
	Since the quantity on the left can be made smaller than any positive number by taking $t$ sufficiently small, it must be that
	\begin{align*}
		\lim_{t \to 0}\frac{f(\bx+t\bv)-f(\bx)}{t}\equiv \frac{d}{dt}f(\bx+t\bv)|_{t=0}=df_\bx(\bv).
	\end{align*}
\end{proof}

\begin{defn}[Directional derivative]\label{def:dd}
The real number	$\frac{d}{dt}f(\bx+t\bv)|_{t=0}$ is called a \emph{directional derivative} of $f$, and is often denoted $D_\bv f(\bx)$. 
\end{defn}

\begin{remark}
	Strictly speaking, in Definition \ref{def:dd} we are misusing the word ``direction", since if $\bw=c\bv$ with $c>0$, then $\bw$ and $\bv$ point in the same direction but Theorem \ref{thm:computation_of_the_differential} shows that $D_\bw f(\bx)=df_\bx(\bw)=df_\bx(c\bv)=cD_\bv(\bx)$. Thus, when we speak of directional derivatives we will always take $\bv$ in Definition \ref{thm:computation_of_the_differential} to be a unit vector.
\end{remark}

\begin{cor}\label{cor:diff_imp_dd}
If $f:U \subseteq \R^n \to \R$ is differentiable at $\bx$, then all of its directional derivatives exist at $\bx$. In particular, all the partial derivatives of $f$ exist at $\bx$.	
\end{cor}

\begin{proof}
	By taking $\bv=e_i$ to be the $i$th standard basis vector for $\R^n$, by Theorem \ref{thm:computation_of_the_differential},
	\begin{align*}
		df_\bx(e_i)&=\lim_{t \to 0}\frac{f(\bx+te_i)-f(\bx)}{t}\\
		&=\lim_{t \to 0}\frac{f(x_1,\dots,x_i+t,\dots,x_n)-f(x_1,\dots,x_i,\dots,x_n)}{t}\\
		&\equiv \frac{\partial f}{\partial x_i}(x_1,\dots,x_n).
	\end{align*}
\end{proof}

Since $df_\bx:\R^n \to \R$ is a linear map, it can be represented by an $1 \times n$ matrix i.e., a row vector. Note that $df_\bx(e_i)=\frac{\partial f}{\partial x_i}(\bx)$ is the $i$th column of the matrix representing $df_\bx$ with respect to the standard bases. Thus, the standard matrix of $df_\bx$ is 
\begin{align*}
	[df_\bx]=\begin{bmatrix}
		\frac{\partial f}{\partial x_1}(\bx) & \frac{\partial f}{\partial x_2}(\bx) & \cdots & \frac{\partial f}{\partial x_n}(\bx)
	\end{bmatrix}.
\end{align*}

If $f:\R^2 \to \R$ is differentiable at $\bx$, the equation of the \emph{tangent plane} to the graph of $f$ at $(\bx,f(\bx))$ is 
\begin{align*}
	f(x,y)&=f(x_0,y_0)+T(x-x_0,y-y_0) \\
	&=f(x_0,y_0)+\begin{bmatrix}
		\frac{\partial f(x_0,y_0)}{\partial x} & \frac{\partial f(x_0,y_0)}{\partial y} 
	\end{bmatrix}\begin{bmatrix}
		x-x_0 \\ y-y_0
	\end{bmatrix} \\
	&=f(x_0,y_0)+\frac{\partial f(x_0,y_0)}{\partial x}(x-x_0)+\frac{\partial f(x_0,y_0)}{\partial y}(y-y_0).
\end{align*}

The converse to Corollary \ref{cor:diff_imp_dd} is \emph{false}, as the next example shows.

\begin{example}
	A function $f:\R^n \to \R$ is said to be \emph{homogeneous} if $f(c\bx)=cf(\bx)$ for all $c \in \R$ and $\bx \in \R^n$. If $f$ is homogeneous, then for any nonzero $\bv \in \R^n$ we have
	\begin{align*}
		D_\bv(0)&=\lim_{t \to 0}\frac{f(0+t\bv)-f(0)}{t}\\
		&=\lim_{t \to 0}\frac{f(t\bv)}{t}\\
		&=\lim_{t \to 0}\frac{tf(\bv)}{t}\\
		&=\lim_{t \to 0}f(\bv)\\
		&=f(\bv),
	\end{align*}
	which shows that all the directional derivatives of a homogeneous function exist at 0 at $D_\bv f(0)=f(\bv)$. If $f$ is also differentiable at $0$, then
	\begin{align*}
		df_0(\bv)=D_\bv(0)=f(\bv),
	\end{align*}
thus $f=df_0$, so $f$ is linear by Proposition \ref{prop:linear_f_equals_diff}. Therefore, if $f$ is any nonlinear homogeneous function, then all of its directional derivatives will exist, but $f$ will not be differentiable. For instance, define $f:\R^2 \to \R$ by
\begin{align*}
	f(x,y)=\begin{cases}
		\frac{x^3}{x^2+y^2}, &\text{ if } (x,y)
 \neq (0,0) \\
 0, &\text{ if } (x,y)=(0,0).
 	\end{cases}
\end{align*} 
Then $f(tx,ty)=tf(x,y)$, so $f$ is homogeneous, but not linear.
\end{example}

The converse to Corollary \ref{cor:diff_imp_dd} \emph{does} hold if we add the condition that the partial derivatives are \emph{continuous}:

\begin{thm}
	Let $U$ be an open subset of $\mathbb{R}^n$ and let $f:U \to \mathbb{R}$. Then, if each of the partial derivatives $\frac{\partial f}{\partial x_i}$ exists and is continuous on $U$, then $f$ is differentiable on $U$.
\end{thm}

\begin{proof}
To cut down on writing, we will prove this for the case of $n=2$. The proof for $n>2$ is exactly the same. We need to show that, for any $(x,y) \in U$ and $\epsilon > 0$, there exists a $\delta > 0$ such that
\begin{align*}
	|f(x+h_1,y+h_2)-f(x,y)-df_{(x,y)}({\bf h})|<\epsilon||{\bf h}||
\end{align*}
whenever $||{\bf h}||\equiv \sqrt{h_1^2+h_2^2}< \delta$.  
\begin{align*}
	&|f(x+h_1,y+h_2)-f(x,y)-df_{(x,y)}({\bf h})|\\
	&=|f(x+h_1,y+h_2)-f(x,y)-\frac{\partial f}{\partial x}(x,y)h_1-\frac{\partial f}{\partial y}(x,y)h_2| \\
	&=|f(x+h_1,y+h_2)-f(x,y+h_2)+f(x,y+h_2)-f(x,y)-\frac{\partial f}{\partial x}(x,y)h_1-\frac{\partial f}{\partial y}(x,y)h_2| \\
\end{align*}
By the Mean Value Theorem, there exists $u_1 \in (x,x+h_1)$ and $u_2 \in (y,y+h_2)$ such that
\begin{align*}
	f(x+h_1,y+h_2)-f(x,y+h_2)&=\frac{\partial f}{\partial x}(u_1,y+h_2)h_1 \\
	f(x,y+h_2)-f(x,y)&=\frac{\partial f}{\partial y}(x,u_2)h_2
\end{align*}
so the above is equal to
\begin{align*}
	&|(\frac{\partial f}{\partial x}(u_1,y+h_2)-\frac{\partial f}{\partial x}(x,y))h_1+(\frac{\partial f}{\partial y}(x,u_2)-\frac{\partial f}{\partial y}(x,y))h_2|\\
	 \leq &|(\frac{\partial f}{\partial x}(u_1,y+h_2)-\frac{\partial f}{\partial x}(x,y), \frac{\partial f}{\partial y}(x,u_2)-\frac{\partial f}{\partial y}(x,y))| \ ||{\bf h}|| \\
	 \leq &(|\frac{\partial f}{\partial x}(u_1,y+h_2)-\frac{\partial f}{\partial x}(x,y)|+|\frac{\partial f}{\partial y}(x,u_2)-\frac{\partial f}{\partial y}(x,y)|)||{\bf h}||
\end{align*}
where in the second line we have used the Cauchy-Schwarz inequality \footnote{The Cauchy-Schwarz inequality states that $|df_{(x,h)}\cdot {\bf h}|\leq |df_{(x,h)}| \ ||{\bf h}||$.} and in the third line the fact that $\sqrt{x^2+y^2}\leq |x|+|y|$. Since the partial derivatives are continuous, and since $u_1$ and $u_2$ lie between $x$ and $x+h_1$ and $y$ and $y+h_2$, respectively, there exists a $\delta_1$ such that the first absolute value in the parenthesis is less than $\epsilon/2$ whenever $||{\bf h}||<\delta_1$ and a $\delta_2$ such that the second absolute value in the parenthesis is less than $\epsilon/2$ whenever $||{\bf h}||<\delta_2$. Thus, by taking $||{\bf h}||<\delta=\text{min}\{\delta_1,\delta_2\}$, the entire parenthesis is less than $\epsilon$.
\end{proof}



\subsection{Explicit computation of the differential}
To compute the differential explicitly, we observe that it obeys the usual rules of differentiation.

\begin{prop}
Let $f_1,f_2$ be differentiable at $\bx$. Then
\begin{enumerate}[(1)]
	\item $d$ is linear: $d(cf_1+f_2)=cdf_1+df_2$.
	\item $d$ obeys the Leibnitz rule: $d(f_1 \cdot f_2)=df_1 \cdot f_2+f_1 \cdot df_2$.
\end{enumerate}	
\end{prop}

\begin{proof}
	\begin{enumerate}[(1)]
		\item For any $\bv \in \R^n$, we have
		\begin{align*}
			d(cf_1+f_2)(\bv)=D_\bv(cf_1+f_2)(\bx)=c D_\bv f_1(\bx)+D_\bv f_2(\bx)=cdf_1(\bv)+df_2(\bv)
		\end{align*}
		and therefore $d(cf_1+f_2)=cdf_1+df_2$.
		\item For any $\bv \in \R^n$, we have
		\begin{align*}
			d(f_1 \cdot f_2)(\bv)=D_\bv(f_1(\bv) \cdot f_2(\bv))=(D_\bv f_1(\bx))f_2+f_1(D_\bv f_2(\bx))=df_1(\bv)\cdot f_2(\bv)+f_1(\bv)df_2(\bv)
		\end{align*}
		and therefore $d(f_1 \cdot f_2)=df_1 \cdot f_2+f_1 \cdot df_2$.
	\end{enumerate}
\end{proof}

\begin{thm}[Chain rule]
	Let $\bbr:I \to \R^2$ and $f:U \subseteq \R^2 \to \R$, where $I$ is an interval in $\R$ and $U$ is an open subset of $\R^2$ containing the trance of the curve $\bbr$. If $\bbr$ is differentiable at $t$ and $f$ is differentiable at $\bbr(t)$, then $f \circ \bbr:I \to \R$ is differentiable at $t$ and
	\begin{align*}
		d(f \circ \bbr)_{t}=df_{\bbr(t)} \circ d\bbr_t.
	\end{align*}
\end{thm}

\fixme{Draw a picture.}

\begin{proof}
	Since $\bbr$ is differentiable at $t$ and $f$ is differentiable at $\bbr(t)$, given $\epsilon_1,\epsilon_2>0$ there exist $\delta_1,\delta_2>0$ such that if $|k|<\delta_1$ and $||\bh||<\delta_2$, then $t+k \in I$, $\bbr(t)+\bh \in U$ and 
	\begin{align}\label{eq:chain_1}
		||\bbr(t+k)-\bbr(t)-d\bbr_t(k)|| &\leq \epsilon_1|k|, \\ \label{eq:chain_2}
		|f(\bbr(t)+\bh)-f(\bbr(t))-df_{\bbr(t)}(\bh)|&\leq \epsilon_2||\bh||.
	\end{align}
Set $\delta=\min\{\delta_1,\frac{\delta_2}{\epsilon_1+||d\bbr_t||}\}$. Let $k \in \R$ with $|k|<\delta$ and set $\bh=\bbr(t+k)-\bbr(t)$. Then \eqref{eq:chain_1} implies
\begin{align*}
	||\bh-d\bbr_t(k)|| \leq \epsilon_1|k|.
\end{align*}
By the triangle inequality, we then have
\begin{align*}
	||\bh||&=||\bh-d\bbr_t(k)+d\bbr_t(k)|| \\
	&\leq ||\bh-d\bbr_t(k)||+||d\bbr_t(k)|| \\
	&\leq \epsilon_1 |k|+||d\bbr_t|| |k| \\
	&=(\epsilon_1+||d\bbr_t||)|k| \\
	& < (\epsilon_1+||d\bbr_t||) \frac{\delta_2}{(\epsilon_1+||d\bbr_t||) } \\
	&=\delta_2
\end{align*}
and therefore by \eqref{eq:chain_2}
\begin{align*}
	&|f(\bbr(t+k))-f(\bbr(t))-df_{\bbr(t)}(d\bbr_t(k))|=|f(\bbr(t+k)-\bbr(t)+\bbr(t))-f(\bbr(t))-df_{\bbr(t)}(d\bbr_t(k))| \\
	=&|f(\bbr(t)+\bh)-f(\bbr(t))-df_{\bbr(t)}(d\bbr_t(k))| \\
	=&|f(\bbr(t)+\bh)-f(\bbr(t))-df_{\bbr(t)}(\bh)+df_{\bbr(t)}(\bh)-df_{\bbr(t)}(d\bbr_t(k))| \\
	\leq & |f(\bbr(t)+\bh)-f(\bbr(t))-df_{\bbr(t)}(\bh)|+|df_{\bbr(t)}(\bh)-df_{\bbr(t)}(d\bbr_t(k))| \\
	=& |f(\bbr(t)+\bh)-f(\bbr(t))-df_{\bbr(t)}(\bh)|+|df_{\bbr(t)}(\bh-d\bbr_t(k))| \\
	\leq & \epsilon_2||\bh||+||df_{\bbr(t)}||\epsilon_1|k| \\
	\leq &\epsilon_2(\epsilon_1+||d\bbr_t||)|k|+\epsilon_1||df_{\bbr(t)}|| \ |k| \\
	&=(\epsilon_2(\epsilon_1+||d\bbr_t||)+\epsilon_1||df_{\bbr(t)}||)|k|
\end{align*}
Thus, given any $\epsilon>0$, we can find $\delta_1,\delta_2>0$ such that \eqref{eq:chain_1} and \eqref{eq:chain_2} hold for 
\begin{align*}
	\epsilon_1&=\frac{1}{2}\frac{\epsilon}{||df_{\bbr(t)}||} \\
	\epsilon_2&=\frac{1}{2}\frac{\epsilon}{\epsilon_1+||d\bbr_t||}.
\end{align*}
Defining $\delta$ as before, by taking $|k|<\delta$ we therefore have
\begin{align*}
	|f(\bbr(t+k))-f(\bbr(t))-df_{\bbr(t)}(d\bbr_t(k))|&\leq \epsilon|k|.
\end{align*}
This proves that $f \circ \bbr$ is differentiable at $t$ with differential $df_{\bbr(t)} \circ d\bbr_t$.
\end{proof}

Since the matrix representing a composition of linear maps is the product of the matrices representing each linear map \fixme{Refer to my Linear Algebra notes}, the standard matrix of $d(f \circ \bbr)_{t}$ is
\begin{align*}
	[d(f \circ \bbr)_{t}]&=\begin{bmatrix}
		\frac{\partial f}{\partial x} & \frac{\partial f}{\partial y} 
	\end{bmatrix} \begin{bmatrix}
		\frac{dx}{dt} \\ \frac{dx}{dt}
	\end{bmatrix} \\
	&=\frac{\partial f}{\partial x}\frac{dx}{dt}+\frac{\partial f}{\partial y}\frac{dy}{dt},
\end{align*}
evaluated at $(x(t),y(t))$.

\begin{example}
Let $f(x,y)=x^2y+3xy^4$ and $\bbr(t)=(x(t),y(t))=(\sin 2t, \cos t)$. If $F(t)=f(x(t),y(t))$, then
\begin{align*}
	\frac{dF}{dt}&=\frac{\partial f}{\partial x}\frac{dx}{dt}+\frac{\partial f}{\partial y}\frac{dy}{dt} \\
	&=(2xy+3y^4)2\cos(2t)+(x^2+12xy^3)(-\sin t)|_{(x,y)=(\sin 2t, \cos t)} \\
	&=(2\sin(2t)\cos(t)+3\cos^4(t))2\cos(2t)-(\sin^2(2t)+12\sin(2t)\cos^3(t))\sin(t) \\
	&=4\sin(2t)\cos(2t)\cos(t)+6\cos^4(t)\cos(2t)-\sin^2(2t)\sin(t)-12\sin(2t)\cos^3(t)\sin(t).
\end{align*}	
\end{example}

\begin{exercise}
Find $(f \circ \bbr)'(t)$ for each function.
\begin{enumerate}[(1)]
	\item $f(x,y)=x^2+y^2+xy$, $\bbr(t)=(\sin t,e^t)$.
	\item $f(x,y)=\cos(x+4y)$, $\bbr(t)=(5t^4,t^{-1})$.
\end{enumerate}	
\end{exercise}


\begin{thm}
If $U$ is connected, $f$ differentiable, and $df_p=0$ for all $p$, then $f$ is constant.	
\end{thm}

\fixme{Does this fit in somewhere? If so, discuss and prove this.}


\subsection{Implicit Differentiation}
\fixme{Add.}



\subsection{Higher Partial Derivatives}
\begin{figure}[h]
	\begin{center}
		\includegraphics[width=\textwidth]{figures_mvc/higher_d}
	\end{center}
\end{figure}

\begin{exercise}\label{ex:mixed_partials_equality}
Compute the second partial derivatives of 
\begin{align*}
	f(x,y)=x^3+x^2y^3-2y^2.
\end{align*}	
\end{exercise}

\begin{figure}[h]
	\begin{center}
		\includegraphics[scale=0.5]{figures_mvc/higher_d_ex}
	\end{center}
\end{figure}

Notice for the function in Exercise \ref{ex:mixed_partials_equality} that $\frac{\partial f}{\partial x \partial y}=\frac{\partial f}{\partial y \partial x}$. This is no coincidence.

\fixme{Finish.}

\section{Optimization}
Infinitesimal to local to global. Example: if $df_p$ zero at every point of $U$ and $U$ connected then $f$ is constant on $U$


\appendix
\section{Justification of the Arc Length Formula}\label{app:arc_length}
\begin{prop}
The arc length formula 
\begin{align}
	s=\int_a^b||\bbr'(t)||dt.
\end{align}
can be obtained as the limit of a polygonal approximation of the curve.
\end{prop}

\begin{figure}[h]
	\begin{center}
	\includegraphics[scale=0.5]{figures_mvc/polygonal_approx}
\end{center}
\caption{A polygonal approximation of a regular curve.}
\end{figure}

\begin{pf}
\fixme{This proof references an idea here and there which are most likely unfamiliar. Attempts to give a rough explanation are given, but may not be entirely satisfactory.} Let $\bbr:I \to \R^n$ be a parametrized curve and let $[a,b] \subseteq I$. Let $a\equiv t_0<t_1<t_2	<\cdots<t_n\equiv b$ be a partition of $[a,b]$ where, for simplicity, we take each interval $t_i-t_{i-1}$ to have equal width $\Delta t\equiv \frac{b-a}{n}$. Approximate the length of curve between $\bbr(t_{i-1})$ and $\bbr(t_i)$ by a straight line. We then define the arc length $s$ between $\bbr(a)$ and $\bbr(b)$ by
\begin{align*}
	s&\equiv \lim_{n \to \infty}\sum_{i=1}^n||\bbr(t_i)-\bbr(t_{i-1})|| \\
	&=\equiv \lim_{n \to \infty}\sum_{i=1}^n\sqrt{(x(t_i)-x(t_{i-1}))^2+(y(t_i)-y(t_{i-1}))^2}.
\end{align*}
Since the coordinate functions $x(t)$ and $y(t)$ are continuous on $[a,b]$ and differentiable on $(a,b)$, by the Mean Value Theorem there exist $t_i^*$ and $t_i^{**}$ in $(a,b)$ such that
\begin{align*}
	x(t_i)-x(t_{i-1})&=x'(t_i^*)(t_i-t_{i-1}) \\
	&=x'(t_i^*)\Delta t \\
	y(t_i)-y(t_{i-1})&=y'(t_i^{**})(t_i-t_{i-1}) \\
	&=y'(t_i^{**})\Delta t
\end{align*}
and therefore
\begin{align*}
	s&=\lim_{n \to \infty}\sum_{i=1}^n\sqrt{(x'(t_i^*))^2+(y'(t_i^{**}))^2}\Delta t.
\end{align*}
If $t_i^*$ were equal to $t_i^{**}$ for all $i=1,\cdots,n$, then this would be a Riemann sum for $\int_a^b||\bbr'(t)||dt$. However, in general they are not equal, so we will instead show that the difference between this expression and the Riemann sum
\begin{align*}
\int_a^b||\bbr'(t)||dt\equiv\lim_{n \to \infty}\sum_{i=1}^n\sqrt{(x'(t_i^*))^2+(y'(t_i^*))^2}\Delta t	
\end{align*}
 goes to zero as $n \to \infty$. \footnote{Intuitively, this should make sense, since $t_i^*$ and $t_i^{**}$ both lie within $[t_{i-1},t_i]$ and by shrinking $\Delta t$, each of these subintervals also shrinks and therefore we should be able to make the points $t_i^*$ and $t_i^{**}$ become arbitrarily close to each other by making $\Delta t$ arbitrarily small.} First, note that since $\bbr$ is, in particular, continuously differentiable on each closed interval $[t_{i-1},t_i]$, the functions $x'$ and $y'$ are uniformly continuous on $[t_{i-1},t_i]$. \footnote{The proof of this involves the notion of ``compactness", the explanation of which would take us beyond the scope of this course. A function is said to be \emph{uniformly continuous} if for every $\epsilon>0$ there exists $\delta>0$ such that for any point $t \in [t_{i-1},t_i]$, $|t'-t|<\delta$ implies $||f(t)-f(t')||<\epsilon$; that is, the \emph{same} $\delta$ works for every point $t \in [t_{i-1},t_i]$. This is not true when a function is continuous but not uniformly continuous, since in that case $\delta$ depends on both $\epsilon$ \emph{and} $t$.} Thus, given any $\epsilon >0$ there exists a $\delta > 0$ such that $|t_i^*-t_i^{**}|< \delta$ implies $|y'(t_i^*)-y'(t_i^{**})|<\epsilon$. Since $|t_i^*-t_i^{**}|<t_i-t_{i-1}=\Delta t$, if we take $\Delta t < \delta$, then we will have $|y'(t_i^*)-y'(t_i^{**})|<\epsilon$. Note that this is possible since, given any $\delta > 0$, by the Archimedean property of the real numbers we can find a positive integer $n$ such that $\Delta t =\frac{b-a}{n}<\delta$. Assuming now that we have chosen $\Delta t<\delta$, we then have
\begin{align*}
	&\left|\sqrt{(x'(t_i^*))^2+(y'(t_i^{*}))^2}-\sqrt{(x'(t_i^*))^2+(y'(t_i^{**}))^2}\right|\\
	=& \left|\sqrt{(x'(t_i^*))^2+(y'(t_i^{*}))^2}-\sqrt{(x'(t_i^*))^2+(y'(t_i^{**}))^2+(y'(t_i^{*}))^2-(y'(t_i^{*}))^2}\right| \\
	=& \left|\sqrt{(x'(t_i^*))^2+(y'(t_i^{*}))^2}-\sqrt{(x'(t_i^*))^2+(y'(t_i^{*}))^2+(y'(t_i^{**}))^2-(y'(t_i^{*}))^2}\right|.
\end{align*}
Now $(y'(t_i^{**}))^2-(y'(t_i^{*}))^2 \leq |(y'(t_i^{**}))^2-(y'(t_i^{*}))^2|$, so, by the triangle inequality,
\begin{align*}
	\sqrt{(x'(t_i^*))^2+(y'(t_i^{*}))^2+(y'(t_i^{**}))^2-(y'(t_i^{*}))^2} &\leq \sqrt{(x'(t_i^*))^2+(y'(t_i^{*}))^2+|(y'(t_i^{**}))^2-(y'(t_i^{*}))^2|} \\
	&\leq \sqrt{(x'(t_i^*))^2+(y'(t_i^{*}))^2}+\sqrt{|(y'(t_i^{**}))^2-(y'(t_i^{*}))^2|} 
\end{align*}
and therefore
\begin{align*}
	&\left|\sqrt{(x'(t_i^*))^2+(y'(t_i^{*}))^2}-\sqrt{(x'(t_i^*))^2+(y'(t_i^{**}))^2}\right|\\
	=& \left|\sqrt{(x'(t_i^*))^2+(y'(t_i^{*}))^2}-\sqrt{(x'(t_i^*))^2+(y'(t_i^{*}))^2+(y'(t_i^{**}))^2-(y'(t_i^{*}))^2}\right| \\
	& \leq \left|\sqrt{(x'(t_i^*))^2+(y'(t_i^{*}))^2}-\left(\sqrt{(x'(t_i^*))^2+(y'(t_i^{*}))^2}+\sqrt{|(y'(t_i^{**}))^2-(y'(t_i^{*}))^2|}\right)\right| \\
	&=\left|-\sqrt{|(y'(t_i^{**}))^2-(y'(t_i^{*}))^2|}\right| \\
	&=\sqrt{|(y'(t_i^{**}))^2-(y'(t_i^{*}))^2|} \\
	&=\sqrt{|(y'(t_i^{**})+(y'(t_i^{*}))(y'(t_i^{**})-(y'(t_i^{*}))|} \\
	&=\sqrt{|(y'(t_i^{**})+(y'(t_i^{*}))|}\sqrt{|(y'(t_i^{**})-(y'(t_i^{*}))|} \\
\end{align*}
Since $y'$ is continuous and $[a,b]$ a closed interval, $y'([a,b])$ is bounded by some $M>0$, so \footnote{Here we have used the facts that the image of a compact set under a continuous mapping is compact, and that a compact set is bounded.}
\begin{align*}
	&=\sqrt{|(y'(t_i^{**})+(y'(t_i^{*}))|}\sqrt{|(y'(t_i^{**})-(y'(t_i^{*}))|} \\
	&\leq \sqrt{2M}\sqrt{|(y'(t_i^{**})-(y'(t_i^{*}))|},
\end{align*}
so by choosing $\Delta t<\delta$ such that $|(y'(t_i^{**})-(y'(t_i^{*}))|<\frac{\epsilon^2}{4M^2(b-a)^2}$, then 
\begin{align*}
	&\left|\sqrt{(x'(t_i^*))^2+(y'(t_i^{*}))^2}-\sqrt{(x'(t_i^*))^2+(y'(t_i^{**}))^2}\right|\\
	&\leq \sqrt{2M}\sqrt{|(y'(t_i^{**})-(y'(t_i^{*}))|} \\
	&< \sqrt{2M}\sqrt{\frac{\epsilon^2}{4M^2(b-a)^2}} \\
	&=\frac{\epsilon}{b-a}
\end{align*}
and therefore
\begin{align*}
	&\left|\sum_{i=1}^n\sqrt{(x'(t_i^*))^2+(y'(t_i^{*}))^2}\Delta t-\sum_{i=1}^n\sqrt{(x'(t_i^*))^2+(y'(t_i^{**}))^2}\Delta t\right| \\
	=&\left|\sum_{i=1}^n\left(\sqrt{(x'(t_i^*))^2+(y'(t_i^{*}))^2}-\sqrt{(x'(t_i^*))^2+(y'(t_i^{**}))^2}\right)\right|\Delta t \\
	&\leq \sum_{i=1}^n\left|\sqrt{(x'(t_i^*))^2+(y'(t_i^{*}))^2}-\sqrt{(x'(t_i^*))^2+(y'(t_i^{**}))^2}\right|\Delta t \\
	&<n\frac{\epsilon}{b-a} \Delta t \\
	&=n\frac{\epsilon}{b-a}\frac{(b-a)}{n} \\
	&=\epsilon.
\end{align*}
\end{pf}
\newpage 

\section{Topology of $\R^n$}\label{app:topology}
A \emph{topology} is a structure on a set which allows us to define the notion of continuity. In this appendix, we collect some basic definitions used throughout the rest of the notes.
\subsection{Normed Linear Spaces}
\begin{defn}[Normed linear space]
	Let $V$ be a real vector space. A \emph{norm} on $V$ is a function
	\begin{align*}
		\rho:V \to \R^{\geq 0}
	\end{align*}
	such that for all $\xi,\eta \in V$ and $c \in \R$ we have
	\begin{enumerate}
		\item $\rho(\xi)=0$ if and only if $\xi=0$,
		\item $\rho(c\xi)=|c|\rho(\xi)$,
		\item $\rho(\xi+\eta) \leq \rho(\xi)+\rho(\eta)$.
	\end{enumerate}
	The pair $(V,\rho)$ is called a \emph{normed linear space}. 
	
	Property (3) is called the \emph{triangle inequality}. We often use the notation $||\xi||=\rho(\xi)$ for the norm.
\end{defn}

\begin{example}
For $V=\R^n$, define $\rho:\R^n \to \R^{\geq 0}$ by $\rho(\bx)=\sqrt{\sum_{i=1}^n x_i^2}$. This norm on $\R^n$ is called the \emph{Euclidean norm} and the normed linear space $(\R^n,\rho)$ is called \emph{Euclidean space}.	
\end{example}

\begin{exercise}
Prove that the Euclidean norm on $\R^n$ is a norm.	
\end{exercise}

\fixme{Def of equivalent norms.}

\fixme{All norms on a finite dimensional normed linear space are equivalent.}

\begin{defn}[Continuous linear maps]
	Let $V,W$ be normed linear spaces. A linear map $T:V \to W$ is \emph{bounded} if there exists $C>0$ such that 
	\begin{align*}
		||T\bv||_W \leq C||\bv||_V, \hspace{0.5 cm} \text{ for all } \bv \in V.
	\end{align*}
\end{defn}

\fixme{Define operator norm on $\Hom(V,W)$.}

\begin{prop}[Equivalent definition of a bounded linear maps]
	Let $T:V \to W$ be a bounded linear map, and let $S(V)\equiv \{\bv \in V:||\bv||_V=1\} \subseteq V$ be the unit sphere in $V$.  Then $T$ is bounded if and only if $T(S(V)) \subseteq W$ is bounded. 
\end{prop}

\begin{proof}
	Suppose $T$ is bounded and suppose $\bv \in S(V)$. Then $||\bv||_V=1$ and therefore
	\begin{align*}
		||T\bv||_W \leq C||\bv||_V=C. 
	\end{align*} 
	Thus, $T(S(V))$ is bounded.
	
	Conversely, suppose $T(S(V))$ is bounded. For any $\bv \in V$, $\frac{\bv}{||\bv||_V} \in S(V)$ and by assumption there exists $C>0$ such that 
	\begin{align*}
		||T\frac{\bv}{||\bv||_V}||_W=\frac{1}{||\bv||_V}||T\bv||_V \leq C
	\end{align*} 
	and therefore
	\begin{align*}
		||T\bv||_W \leq C||\bv||_V.
	\end{align*}
	Hence, $T$ is bounded.
\end{proof}


\subsection{Metric Spaces}
\begin{defn}[Metric space]
	A metric space $(X,d)$ is a set $X$ together with a function
	\begin{align*}
		d:X \times X \to \R^{\geq 0}
	\end{align*}
	such that for all $x,y,z \in X$ we have
	\begin{enumerate}
		\item $d(x,y)=0$ if and only if $x=y$,
		\item $d(x,y)=d(y,x)$,
		\item $d(x,y) \leq d(x,z)+d(z,y)$.
	\end{enumerate}
	Again, property (3) is called the \emph{triangle inequality}.
\end{defn}

\begin{prop}
	Let $(V,\rho)$ be a normed linear space. Then $V$ inherits a metric $d_\rho:V \times V \to \R^{\geq 0}$ defined by
	\begin{align*}
		d_\rho(\xi,\eta)=\rho(\xi-\eta), \hspace{0.5cm} \xi,\eta \in V.
	\end{align*}
	
\end{prop}

\begin{pf}
	\begin{enumerate}
		\item $d_\rho(\xi,\eta)=\rho(\eta-\xi)=0$ if and only if $\eta-\xi=0$ if and only if $\eta=\xi$.
		\item $d_\rho(\eta,\xi)=\rho(\xi-\eta)=\rho(-1(\eta-\xi))=|-1|\rho(\eta-\xi)=\rho(\eta-\xi)=d_\rho(\xi,\eta)$.
		\item $d_\rho(\xi,\eta)=\rho(\eta-\xi)=\rho(\eta-\alpha+\alpha-\xi) \leq \rho(\eta-\alpha)+\rho(\alpha-\xi)=d_\rho(\alpha,\eta)+d_\rho(\xi,\alpha)$.
	\end{enumerate}
\end{pf}

\begin{example}
The metric $d:\R^n \times \R^n \to \R^{\geq 0}$ defined by
\begin{align*}
	||\bx-\by||=\sqrt{\sum_{i=1}^n(x_i-y_i)^2}
\end{align*}
(called the \emph{Euclidean metric}) gives $(\R^n,d)$ the structure of a metric space.
\end{example}

\begin{defn}[Open ball]
	Let $r>0$. The subset
	\begin{align*}
		B_r(\bx_0):=\{\bx \in \R^n:d(\bx,\bx_0)<r\}
	\end{align*}
	is called the \emph{open ball of radius $r$ centered at $\bx_0$}.
\end{defn}

\begin{example}
\begin{enumerate}[(1)]
	\item If $n=1$, then $B_r(x_0)$ is the open interval $(x_0-r,x_0+r)$.
	\item If $n=2$, then $B_r(\bx_0)$ is the open disc of radius $r$ centered at $\bx_0$.
\end{enumerate}	
\end{example}

\begin{defn}[Interior and boundary points]
Let $U$ be a subset of $\R^n$ and let $\bx_0 \in U$.
	\begin{enumerate}[(1)]
		\item The point $\bx_0$ is an \emph{interior point} of $U$ if there exists $r>0$ such that $B_r(\bx_0) \subseteq U$. The \emph{interior of} $U$ is the set of interior points of $U$.
		\item The point $\bx_0$ is a \emph{boundary point} of $U$ if for every $r>0$, $B_r(\bx_0)$ contains a point of $U$ as well as a point of $\R^n-U$. The boundary point itself need not belong to $U$. The \emph{boundary of $U$} is the set of boundary points of $U$.
	\end{enumerate}
\end{defn}

\begin{figure}[h]
\centering
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.4\linewidth]{figures_mvc/interior_point}
  \subcaption{Interior point.}
\end{subfigure}%
\begin{subfigure}{.5\textwidth}
  \centering
  \includegraphics[width=.4\linewidth]{figures_mvc/boundary_point}
  \subcaption{Boundary point.}
\end{subfigure}
\end{figure}

\begin{defn}[Open and closed sets]
	\begin{enumerate}[(1)]
		\item A subset $U \subseteq \R^n$ is \emph{open} if it consists entirely of interior points.
		\item A subset $U \subseteq \R^n$ is \emph{closed} if it contains all its boundary points. \fixme{Update: A subset $U \subseteq \R^n$ is \emph{closed} if it contains all its limit points.}
	\end{enumerate}
\end{defn}

\begin{example}
Every open ball is an open set.	
\end{example}

\begin{proof}
	Let $\bx \in B_r(\bx_0)$. Then $h=r-d(\bx,\bx_0)>0$. Let $\by \in B_h(\bx)$. Then $d(\by,\bx)<h$. It then follows from the triangle inequality that
	\begin{align*}
		d(\bx_0,\by) &\leq d(\bx_0,\bx)+d(\bx,\by) \\
		&<r-h+h=r,
	\end{align*}
	which shows that $\by \in B_r(\bx_0)$, and therefore $B_h(\bx) \subseteq B_r(\bx_0)$. Thus, $B_r(\bx_0)$ is open.
\end{proof}

\begin{defn}[Neighborhood]
	A \emph{neighborhood} of a point $\bx \in \R^n$ is an open set containing $\bx$.
\end{defn}



\begin{remark}
Note that a set can be neither open nor closed, or can be both open and closed.	
\end{remark}

\begin{example}
\begin{enumerate}[(a)]
	\item $\R^n$ is open since for any point $\bx \in \R^n$ we can find an open ball centered at $\bx$ contained in $\R^n$. The boundary of $\R^n$ is empty, so $\R^n$ trivially contains all of its boundary points. Thus, $\R^n$ is also closed. 
	\item The half-open interval $(0,1] \subseteq \R$ is neither open nor closed.
\end{enumerate}	
\end{example}

\begin{defn}[Limit points and isolated points]
	Let $U$ be a subset of $\R^n$.
	\begin{enumerate}[(a)]
		\item A point $\bx$ is a \emph{limit point} of the set $U$ if every neighborhood of $\bx$ contains a point of $U$ different from $\bx$.
		\item If $\bx \in U$ and $\bx$ is not a limit point of $U$, then $\bx$ is called an \emph{isolated point} of $U$.
	\end{enumerate}
\end{defn}

\begin{thm}
	If $\bx$ is a limit point of a set $U$, then every neighborhood of $\bx$ contains infinitely many points of $U$.	
\end{thm}

\begin{pf}
(By contradiction) Suppose $V$ is a neighborhood of $\bx$ which contains only finitely many points of $U$. Let $\bx_1,\dots,\bx_n$ be the points of $V \cap U$ which are distinct from $\bx$, and let $r=\min\{d(\bx,\bx_i)\}_{i=1}^n$. Since the minimum of a finite set of positive numbers is positive, $r>0$. Then the neighborhood $B_r(\bx)$ contains no point of $U$ distinct from $\bx$, which is a contradiction since $\bx$ is a limit point of $U$.
\end{pf}

\begin{cor}
A finite point set has no limit points.	
\end{cor}

\begin{example}
Consider the set $U=\{\frac{1}{n}\}_{n=1}^\infty \subseteq \R$. By the Archimedian property of the real numbers \footnote{\fixme{Explain this.}}, given any $\epsilon>0$ there exists $n \in \N$ such that $\frac{1}{n}<\epsilon$. Thus, $0$ is a limit point of $U$, since every open ball $B_\epsilon(0)$ contains a point of $U$. Note however that every element of $U$ itself is an isolated point of $U$ since, for any $\frac{1}{n} \in U$, the open ball $B_{d(\frac{1}{n},\frac{1}{n+1})}(\frac{1}{n})$ contains only $\frac{1}{n}$. This illustrates the difference between a set having a limit point and containing a limit point. 	
\end{example}

\begin{thm}
A set $U$ is open if and only if its complement is closed.	
\end{thm}

\begin{pf}
Suppose $U^c\equiv\R^n-U$ is closed. Let $\bx \in U$. Then $\bx \notin U^c$ and $\bx$ is not a limit point of $U^c$. Hence there exists a neighborhood $N$ of $\bx$ such that $U^c \cap N$ is empty, that is, $N \subseteq U$. Thus $\bx$ is an interior point of $U$, so $U$ is open.

Conversely, suppose that $U$ is open. Let $\bx$ be a limit point of $U^c$. Then every neighborhood of $\bx$ contains a point of $U^c$, so that $\bx$ is not an interior point of $U$. Since $U$ is open, this means that $\bx \in U^c$. It follows that $U^c$ is closed.
\end{pf}

\begin{cor}
A set $V$ is closed if and only if its complement if open.	
\end{cor}

\fixme{Need to define relative open sets in order to define a connected subset of $\R^n$.}

\begin{defn}[Bounded sets]
	A subset $U \subseteq \R^n$ is \emph{bounded} if it is contained in some ball of finite radius. If $U$ is not bounded, then we say it is \emph{unbounded}.
\end{defn}

\begin{example}
\begin{enumerate}
	\item An open ball is bounded.
	\item A line is unbounded.
\end{enumerate}	
\end{example}

\subsection{Continuous maps}
\begin{defn}[Lipschitz continuity]
	Let $(X,d_X)$ and $(Y,d_Y)$ be metric spaces. A function $f:X \to Y$ is \emph{Lipschitz continuous} if there exists a positive real number $K$ such that 
	\begin{align*}
		d_Y(f(x_1)-f(x_2))\leq K d_X(x_1-x_2)
	\end{align*}
	for all $x_1,x_2 \in X$. The real number $K$ is said to be a \emph{Lipschitz constant} for the function $f$. 
\end{defn}

\begin{lem}
If $f$ is Lipschitz continuous, then it is uniformly continuous.	
\end{lem}

\begin{proof}
	Given $\epsilon>0$, choose $\delta=\frac{\epsilon}{K}$. Then
	\begin{align*}
		d_Y(f(x_1)-f(x_2))\leq K \frac{\epsilon}{K}=\epsilon
	\end{align*}
	whenever $d_X(x_1,x_2)<\delta$.
\end{proof}


\begin{thm}
Let $T:V \to W$ be a linear map between normed linear spaces. The following are equivalent:
\begin{enumerate}[(i)]
	\item $T$ is bounded
	\item $T$ is uniformly continuous
	\item $T$ is continuous at $0 \in V$
\end{enumerate}	
\end{thm}

\begin{proof}
	To see that (i) implies (ii), if $T$ is bounded then
	\begin{align*}
		||T(\bv-\bw)||_W=||T\bv-T\bw||_W \leq C||\bv-\bw||_V,
	\end{align*}
	which says that $T$ is Lipschitz continuous, and therefore is uniformly continuous. To see that (ii) implies (iii), just take $\bw=0$ above. To prove that (iii) implies (i), if $T$ is not bounded then choose $\bv_n \in V$ such that $||\bv_n||_V=1$ and $||T\bv_n||_W>n$. Then $\bw_n\equiv \bv_n/n$ satisfies $\lim_{n \to \infty}\bw_n=0$ but $||T\bw_n||_W>1$, so the sequence $(T\bw_n)$ does not converge to $0 \in W$. Hence, $T$ is not continuous at $0 \in V$.
\end{proof}

\begin{thm}\label{thm:every_linear_map_on_a_fd_nls_is_bdd}
Let $V,W$ be normed linear spaces and assume $V$ is finite dimensional. Then any linear map $T:V \to W$ is bounded.	
\end{thm}

\begin{proof}
	\fixme{Finish.}
\end{proof}

\section{Affine Space}\label{app:affine_space}
In our discussion of differentiability, it will be helpful to view points and vectors as distinct. This leads to the notion of an affine space over a vector space.
\begin{defn}[Affine space]\label{def:affine_space}
	Let $V$ be a vector space. An \emph{affine space} $A$ over $V$ is a set $A$ together with a map
	\begin{align}\label{eq:action_of_v_on_a}
		\psi:V \times A &\to A \\
		\psi(\bv,p)&=p+\bv
	\end{align}
	with the following properties: \footnote{Recall that a vector space consists of the data $(V,0,+,\cdot)$, that is, a set $V$, a distinguished vector in $V$ (the zero vector), together with operations of vector addition and scalar multiplication. In particular, the vector space axioms tell us that $(V,0,+)$ is an \emph{abelian group}. A map \eqref{eq:action_of_v_on_a} satisfying properties 1-3 is said to be a \emph{simply transitive action} of the abelian group $(V,0,+)$ on $A$.}
	\begin{enumerate}
		\item $p+\zv=p$ for all $p \in A$.
		\item $p+(\bv+\bw)=(p+\bv)+\bw$ for all $p \in A, \bv,\bw \in V$.
		\item For every $p_1,p_2 \in A$, there exists a unique $\bv \in V$ such that $p_2=p_1+\bv$. Since $\bv$ is uniquely determined by $p_1$ and $p_2$, we write $\bv=p_2-p_1$. 
	\end{enumerate}
\end{defn}
Elements of $A$ are called \emph{points}; elements of $V$ are called \emph{vectors}. While we have not been very careful about the distinction between points and vectors so far, they play very different roles. For example, we might model time by an affine space $A$ over a one-dimensional vector space $V$. Points of $A$ represent instants of time, whereas elements of $V$ represent intervals of time. Notice that it makes sense to add intervals of time, say 3 hours $+$ 4 hours $=$ 7 hours, whereas 3:00 PM $+$ 4:00 PM does not make good sense. Then again, that the difference 4:00 PM $-$ 3:00 PM (the same day) is the time interval 1 hour is part of our intuition about time. Similarly, in a flat model of the Earth we do not try to make sense of the sum of Chicago and New York, but their difference as a displacement vector does make sense.

\begin{prop}\label{prop:canonical_affine_space}
	Every vector space $V$ is an affine space over itself.
\end{prop}

\begin{proof}
	Take $A=V$ and define 
	\begin{align*}
		\psi:V \times V &\to V \\
		\psi(\bv,\bw)&=\bv+\bw
	\end{align*}
	to be vector addition. Then
	\begin{enumerate}
		\item $\bv+\zv=\bw$ for all $\bv \in V$ by definition of the zero vector.
		\item $\bu+(\bv+\bw)=(\bu+\bv)+\bw$ for all $\bu,\bv,\bw \in V$ by associativity of vector addition.
		\item For any $\bv, \bw \in V$, we have
		\begin{align*}
			\bw &=\zv+\bw \\
			&=(\bv-\bv)+\bw \\
			&=\bv+(\bw-\bv).
		\end{align*}
		To see that $\bw-\bv$ is the unique vector with this property, suppose that 
		\begin{align*}
			\bw=\bv+\bu
		\end{align*}
		for some vector $\bu \in V$. Then
		\begin{align*}
			\bv+(\bw-\bv)&=\bv+\bu.
		\end{align*}
		Adding $-\bv$ to both sides gives
		\begin{align*}
		-\bv+(\bv+(\bw-\bv))&=-\bv+(\bv+\bu) \\
		(-\bv+\bv)+(\bw-\bv)&=(-\bv+\bv)+\bu \\
		\zv+(\bw-\bv)&=\zv+\bu \\
		\bw-\bv&=\bu \\
		\end{align*}
		which shows that $\bw-\bv$ is unique.
	\end{enumerate}
\end{proof}

The affine space in Proposition \ref{prop:canonical_affine_space} is called the \emph{canonical affine space over $V$}. Loosely, one says that one obtains this affine space from $V$ by ``forgetting the zero vector".

\begin{defn}[Affine map]\label{def:affine_map}
	Let $A$ be an affine space over a vector space $V$ and $B$ be an affine space over a vector space $W$. A function $f:A \to B$ is an \emph{affine map} if there exists a linear map $T:V \to W$ such that
	\begin{align*}
		f(p+\bv)=f(p)+T\bv
	\end{align*}
	for all $p \in A, \bv \in V$. The linear map $T$ is called the \emph{differential} of $f$, and we write $T=df$.
\end{defn}

\begin{prop}[Uniqueness of the differential]\label{prop:uniqueness_of_the_differential}
	Let $f:A \to B$ be an affine map. Then the differential of $f$ is unique.
\end{prop}

\begin{proof}
	Suppose there exist linear maps $T,T':V \to V$ such that 
	\begin{align*}
		f(p+\bv)=f(p)+T\bv \hspace{0.5cm}\text{ and } \hspace{0.5cm} f(p+\bv)=f(p)+T'\bv.
	\end{align*}
	Then
	\begin{align*}
		f(p)+T\bv=f(p)+T'\bv.
	\end{align*}
Since $T\bv \in W$, $-T\bv \in W$, so we can act with $-T\bv$ on both sides of this equation to obtain
\begin{align*}
	(f(p)+T\bv)-T\bv &=(f(p)+T'\bv)-T\bv.
\end{align*}
By properties 1 and 2 of Definition \ref{def:affine_space}, 
\begin{align*}
	(f(p)+T\bv)-T\bv &=(f(p)+T'\bv)-T\bv \\
	f(p)+(T\bv-T\bv) &=f(p)+(T'\bv-T\bv) \\
	f(p)+\zv &=f(p)+(T'\bv-T\bv) \\
	f(p)&=f(p)+(T'\bv-T\bv). 
\end{align*}
	By property 3 of Definition \ref{def:affine_space}, $\bu=\zv$ is the unique vector such that $f(p)=f(p)+\bu$, so we must have
	\begin{align*}
		T'\bv-T\bv=(T'-T)\bv=\zv,
	\end{align*}
	which says that $\bv \in \ker (T'-T)$. Since  $\bv$ was an arbitrary vector in $V$, we have $\ker (T'-T)=V$, so $T'-T$ is the zero map, and therefore $T'=T$.
\end{proof}

\begin{defn}[Affine isomorphism]
	Let $A$ and $B$ be affine spaces over vector spaces $V$ and $W$, respectively. A bijective affine map $f:A \to B$ is said to be an \emph{affine isomorphism}.
\end{defn}

\begin{prop}
Let $f:A \to B$ and $g:B \to C$ be affine maps. Then $g \circ f:A \to C$ is an affine map.	
\end{prop}

\begin{pf}
	If
	\begin{align*}
		f(p+\bv)&=f(p)+df(\bv), \\
		g(p+\bv)&=g(p)+dg(\bv), 
	\end{align*}
	then
	\begin{align*}
		g(f(p+\bv))&=g(f(p)+df(\bv)) \\
		&=g(f(p))+dg(df(\bv)) \\
		&=(g \circ f)(p)+(dg \circ df)(\bv),
	\end{align*}
	so $g \circ f$ is an affine map whose differential is $dg \circ df$.
\end{pf}

\fixme{Add more if we end up using it.}



\end{document}
